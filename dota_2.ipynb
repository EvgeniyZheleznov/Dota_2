{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тех. задание.\n",
    "Задача проекта - построить модель бинарной классификации исхода матча в игре Dota 2.  \n",
    "В Dota 2 участвуют две команды: Radiant и Dire. Нужно оценить вероятность победы команды Radiant.  \n",
    "Для оценки будем применять метрику ROC-AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import lightgbm as  lgb\n",
    "from catboost import CatBoostClassifier\n",
    "import statsmodels as sm\n",
    "import time\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Настройка параметров pandas для отображения всех столбцов\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Настройка параметров pandas для отображения всех строк\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Создание подключения к базе данных PostgreSQL\n",
    "engine = create_engine('postgresql+psycopg2://student:uvBbBm8gn@158.160.146.146/dota_2')\n",
    "\n",
    "\n",
    "# SQL запрос\n",
    "query_combined = text(f'''SELECT  * FROM train_features''')\n",
    "query_combined_target = text('''SELECT * FROM train_targets''')\n",
    "query_combined_test = text(f'''SELECT * FROM test_features''')\n",
    "\n",
    "# Выполнение запроса и получение DataFrame\n",
    "df_features = pd.read_sql(query_combined, engine)\n",
    "df_target = pd.read_sql(query_combined_target, engine)\n",
    "df_test = pd.read_sql(query_combined_test, engine, index_col='match_id_hash')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33723 entries, 0 to 33722\n",
      "Columns: 246 entries, match_id_hash to d5_sen_placed\n",
      "dtypes: float64(30), int64(215), object(1)\n",
      "memory usage: 63.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id_hash</th>\n",
       "      <th>game_time</th>\n",
       "      <th>radiant_win</th>\n",
       "      <th>duration</th>\n",
       "      <th>time_remaining</th>\n",
       "      <th>next_roshan_team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a400b8f29dece5f4d266f49f1ae2e98a</td>\n",
       "      <td>155</td>\n",
       "      <td>False</td>\n",
       "      <td>992</td>\n",
       "      <td>837</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b9c57c450ce74a2af79c9ce96fac144d</td>\n",
       "      <td>658</td>\n",
       "      <td>True</td>\n",
       "      <td>1154</td>\n",
       "      <td>496</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6db558535151ea18ca70a6892197db41</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>1503</td>\n",
       "      <td>1482</td>\n",
       "      <td>Radiant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46a0ddce8f7ed2a8d9bd5edcbb925682</td>\n",
       "      <td>576</td>\n",
       "      <td>True</td>\n",
       "      <td>1952</td>\n",
       "      <td>1376</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b1b35ff97723d9b7ade1c9c3cf48f770</td>\n",
       "      <td>453</td>\n",
       "      <td>False</td>\n",
       "      <td>2001</td>\n",
       "      <td>1548</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      match_id_hash  game_time  radiant_win  duration  \\\n",
       "0  a400b8f29dece5f4d266f49f1ae2e98a        155        False       992   \n",
       "1  b9c57c450ce74a2af79c9ce96fac144d        658         True      1154   \n",
       "2  6db558535151ea18ca70a6892197db41         21         True      1503   \n",
       "3  46a0ddce8f7ed2a8d9bd5edcbb925682        576         True      1952   \n",
       "4  b1b35ff97723d9b7ade1c9c3cf48f770        453        False      2001   \n",
       "\n",
       "   time_remaining next_roshan_team  \n",
       "0             837             None  \n",
       "1             496             None  \n",
       "2            1482          Radiant  \n",
       "3            1376             None  \n",
       "4            1548             None  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во строк в train: 33723\n",
      "Кол-во колонок train: 246\n"
     ]
    }
   ],
   "source": [
    "# смотрим оснвные данные датасета и пропуски\n",
    "print(f'Кол-во строк в train: {df_features.shape[0]}')\n",
    "print(f'Кол-во колонок train: {df_features.shape[1]}')\n",
    "for col in df_features.columns:\n",
    "    if df_features[col].isnull().any():\n",
    "        print(col, df_features[col].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id_hash</th>\n",
       "      <th>game_time</th>\n",
       "      <th>game_mode</th>\n",
       "      <th>lobby_type</th>\n",
       "      <th>objectives_len</th>\n",
       "      <th>chat_len</th>\n",
       "      <th>r1_hero_id</th>\n",
       "      <th>r1_kills</th>\n",
       "      <th>r1_deaths</th>\n",
       "      <th>r1_assists</th>\n",
       "      <th>r1_denies</th>\n",
       "      <th>r1_gold</th>\n",
       "      <th>r1_lh</th>\n",
       "      <th>r1_xp</th>\n",
       "      <th>r1_health</th>\n",
       "      <th>r1_max_health</th>\n",
       "      <th>r1_max_mana</th>\n",
       "      <th>r1_level</th>\n",
       "      <th>r1_x</th>\n",
       "      <th>r1_y</th>\n",
       "      <th>r1_stuns</th>\n",
       "      <th>r1_creeps_stacked</th>\n",
       "      <th>r1_camps_stacked</th>\n",
       "      <th>r1_rune_pickups</th>\n",
       "      <th>r1_firstblood_claimed</th>\n",
       "      <th>r1_teamfight_participation</th>\n",
       "      <th>r1_towers_killed</th>\n",
       "      <th>r1_roshans_killed</th>\n",
       "      <th>r1_obs_placed</th>\n",
       "      <th>r1_sen_placed</th>\n",
       "      <th>r2_hero_id</th>\n",
       "      <th>r2_kills</th>\n",
       "      <th>r2_deaths</th>\n",
       "      <th>r2_assists</th>\n",
       "      <th>r2_denies</th>\n",
       "      <th>r2_gold</th>\n",
       "      <th>r2_lh</th>\n",
       "      <th>r2_xp</th>\n",
       "      <th>r2_health</th>\n",
       "      <th>r2_max_health</th>\n",
       "      <th>r2_max_mana</th>\n",
       "      <th>r2_level</th>\n",
       "      <th>r2_x</th>\n",
       "      <th>r2_y</th>\n",
       "      <th>r2_stuns</th>\n",
       "      <th>r2_creeps_stacked</th>\n",
       "      <th>r2_camps_stacked</th>\n",
       "      <th>r2_rune_pickups</th>\n",
       "      <th>r2_firstblood_claimed</th>\n",
       "      <th>r2_teamfight_participation</th>\n",
       "      <th>r2_towers_killed</th>\n",
       "      <th>r2_roshans_killed</th>\n",
       "      <th>r2_obs_placed</th>\n",
       "      <th>r2_sen_placed</th>\n",
       "      <th>r3_hero_id</th>\n",
       "      <th>r3_kills</th>\n",
       "      <th>r3_deaths</th>\n",
       "      <th>r3_assists</th>\n",
       "      <th>r3_denies</th>\n",
       "      <th>r3_gold</th>\n",
       "      <th>r3_lh</th>\n",
       "      <th>r3_xp</th>\n",
       "      <th>r3_health</th>\n",
       "      <th>r3_max_health</th>\n",
       "      <th>r3_max_mana</th>\n",
       "      <th>r3_level</th>\n",
       "      <th>r3_x</th>\n",
       "      <th>r3_y</th>\n",
       "      <th>r3_stuns</th>\n",
       "      <th>r3_creeps_stacked</th>\n",
       "      <th>r3_camps_stacked</th>\n",
       "      <th>r3_rune_pickups</th>\n",
       "      <th>r3_firstblood_claimed</th>\n",
       "      <th>r3_teamfight_participation</th>\n",
       "      <th>r3_towers_killed</th>\n",
       "      <th>r3_roshans_killed</th>\n",
       "      <th>r3_obs_placed</th>\n",
       "      <th>r3_sen_placed</th>\n",
       "      <th>r4_hero_id</th>\n",
       "      <th>r4_kills</th>\n",
       "      <th>r4_deaths</th>\n",
       "      <th>r4_assists</th>\n",
       "      <th>r4_denies</th>\n",
       "      <th>r4_gold</th>\n",
       "      <th>r4_lh</th>\n",
       "      <th>r4_xp</th>\n",
       "      <th>r4_health</th>\n",
       "      <th>r4_max_health</th>\n",
       "      <th>r4_max_mana</th>\n",
       "      <th>r4_level</th>\n",
       "      <th>r4_x</th>\n",
       "      <th>r4_y</th>\n",
       "      <th>r4_stuns</th>\n",
       "      <th>r4_creeps_stacked</th>\n",
       "      <th>r4_camps_stacked</th>\n",
       "      <th>r4_rune_pickups</th>\n",
       "      <th>r4_firstblood_claimed</th>\n",
       "      <th>r4_teamfight_participation</th>\n",
       "      <th>r4_towers_killed</th>\n",
       "      <th>r4_roshans_killed</th>\n",
       "      <th>r4_obs_placed</th>\n",
       "      <th>r4_sen_placed</th>\n",
       "      <th>r5_hero_id</th>\n",
       "      <th>r5_kills</th>\n",
       "      <th>r5_deaths</th>\n",
       "      <th>r5_assists</th>\n",
       "      <th>r5_denies</th>\n",
       "      <th>r5_gold</th>\n",
       "      <th>r5_lh</th>\n",
       "      <th>r5_xp</th>\n",
       "      <th>r5_health</th>\n",
       "      <th>r5_max_health</th>\n",
       "      <th>r5_max_mana</th>\n",
       "      <th>r5_level</th>\n",
       "      <th>r5_x</th>\n",
       "      <th>r5_y</th>\n",
       "      <th>r5_stuns</th>\n",
       "      <th>r5_creeps_stacked</th>\n",
       "      <th>r5_camps_stacked</th>\n",
       "      <th>r5_rune_pickups</th>\n",
       "      <th>r5_firstblood_claimed</th>\n",
       "      <th>r5_teamfight_participation</th>\n",
       "      <th>r5_towers_killed</th>\n",
       "      <th>r5_roshans_killed</th>\n",
       "      <th>r5_obs_placed</th>\n",
       "      <th>r5_sen_placed</th>\n",
       "      <th>d1_hero_id</th>\n",
       "      <th>d1_kills</th>\n",
       "      <th>d1_deaths</th>\n",
       "      <th>d1_assists</th>\n",
       "      <th>d1_denies</th>\n",
       "      <th>d1_gold</th>\n",
       "      <th>d1_lh</th>\n",
       "      <th>d1_xp</th>\n",
       "      <th>d1_health</th>\n",
       "      <th>d1_max_health</th>\n",
       "      <th>d1_max_mana</th>\n",
       "      <th>d1_level</th>\n",
       "      <th>d1_x</th>\n",
       "      <th>d1_y</th>\n",
       "      <th>d1_stuns</th>\n",
       "      <th>d1_creeps_stacked</th>\n",
       "      <th>d1_camps_stacked</th>\n",
       "      <th>d1_rune_pickups</th>\n",
       "      <th>d1_firstblood_claimed</th>\n",
       "      <th>d1_teamfight_participation</th>\n",
       "      <th>d1_towers_killed</th>\n",
       "      <th>d1_roshans_killed</th>\n",
       "      <th>d1_obs_placed</th>\n",
       "      <th>d1_sen_placed</th>\n",
       "      <th>d2_hero_id</th>\n",
       "      <th>d2_kills</th>\n",
       "      <th>d2_deaths</th>\n",
       "      <th>d2_assists</th>\n",
       "      <th>d2_denies</th>\n",
       "      <th>d2_gold</th>\n",
       "      <th>d2_lh</th>\n",
       "      <th>d2_xp</th>\n",
       "      <th>d2_health</th>\n",
       "      <th>d2_max_health</th>\n",
       "      <th>d2_max_mana</th>\n",
       "      <th>d2_level</th>\n",
       "      <th>d2_x</th>\n",
       "      <th>d2_y</th>\n",
       "      <th>d2_stuns</th>\n",
       "      <th>d2_creeps_stacked</th>\n",
       "      <th>d2_camps_stacked</th>\n",
       "      <th>d2_rune_pickups</th>\n",
       "      <th>d2_firstblood_claimed</th>\n",
       "      <th>d2_teamfight_participation</th>\n",
       "      <th>d2_towers_killed</th>\n",
       "      <th>d2_roshans_killed</th>\n",
       "      <th>d2_obs_placed</th>\n",
       "      <th>d2_sen_placed</th>\n",
       "      <th>d3_hero_id</th>\n",
       "      <th>d3_kills</th>\n",
       "      <th>d3_deaths</th>\n",
       "      <th>d3_assists</th>\n",
       "      <th>d3_denies</th>\n",
       "      <th>d3_gold</th>\n",
       "      <th>d3_lh</th>\n",
       "      <th>d3_xp</th>\n",
       "      <th>d3_health</th>\n",
       "      <th>d3_max_health</th>\n",
       "      <th>d3_max_mana</th>\n",
       "      <th>d3_level</th>\n",
       "      <th>d3_x</th>\n",
       "      <th>d3_y</th>\n",
       "      <th>d3_stuns</th>\n",
       "      <th>d3_creeps_stacked</th>\n",
       "      <th>d3_camps_stacked</th>\n",
       "      <th>d3_rune_pickups</th>\n",
       "      <th>d3_firstblood_claimed</th>\n",
       "      <th>d3_teamfight_participation</th>\n",
       "      <th>d3_towers_killed</th>\n",
       "      <th>d3_roshans_killed</th>\n",
       "      <th>d3_obs_placed</th>\n",
       "      <th>d3_sen_placed</th>\n",
       "      <th>d4_hero_id</th>\n",
       "      <th>d4_kills</th>\n",
       "      <th>d4_deaths</th>\n",
       "      <th>d4_assists</th>\n",
       "      <th>d4_denies</th>\n",
       "      <th>d4_gold</th>\n",
       "      <th>d4_lh</th>\n",
       "      <th>d4_xp</th>\n",
       "      <th>d4_health</th>\n",
       "      <th>d4_max_health</th>\n",
       "      <th>d4_max_mana</th>\n",
       "      <th>d4_level</th>\n",
       "      <th>d4_x</th>\n",
       "      <th>d4_y</th>\n",
       "      <th>d4_stuns</th>\n",
       "      <th>d4_creeps_stacked</th>\n",
       "      <th>d4_camps_stacked</th>\n",
       "      <th>d4_rune_pickups</th>\n",
       "      <th>d4_firstblood_claimed</th>\n",
       "      <th>d4_teamfight_participation</th>\n",
       "      <th>d4_towers_killed</th>\n",
       "      <th>d4_roshans_killed</th>\n",
       "      <th>d4_obs_placed</th>\n",
       "      <th>d4_sen_placed</th>\n",
       "      <th>d5_hero_id</th>\n",
       "      <th>d5_kills</th>\n",
       "      <th>d5_deaths</th>\n",
       "      <th>d5_assists</th>\n",
       "      <th>d5_denies</th>\n",
       "      <th>d5_gold</th>\n",
       "      <th>d5_lh</th>\n",
       "      <th>d5_xp</th>\n",
       "      <th>d5_health</th>\n",
       "      <th>d5_max_health</th>\n",
       "      <th>d5_max_mana</th>\n",
       "      <th>d5_level</th>\n",
       "      <th>d5_x</th>\n",
       "      <th>d5_y</th>\n",
       "      <th>d5_stuns</th>\n",
       "      <th>d5_creeps_stacked</th>\n",
       "      <th>d5_camps_stacked</th>\n",
       "      <th>d5_rune_pickups</th>\n",
       "      <th>d5_firstblood_claimed</th>\n",
       "      <th>d5_teamfight_participation</th>\n",
       "      <th>d5_towers_killed</th>\n",
       "      <th>d5_roshans_killed</th>\n",
       "      <th>d5_obs_placed</th>\n",
       "      <th>d5_sen_placed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>205e85408fa923b744523db4655f7cf7</td>\n",
       "      <td>337</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>983</td>\n",
       "      <td>0</td>\n",
       "      <td>726</td>\n",
       "      <td>749</td>\n",
       "      <td>920</td>\n",
       "      <td>302.93777</td>\n",
       "      <td>3</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>9.697543</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1450</td>\n",
       "      <td>18</td>\n",
       "      <td>2487</td>\n",
       "      <td>697</td>\n",
       "      <td>820</td>\n",
       "      <td>554.93805</td>\n",
       "      <td>6</td>\n",
       "      <td>116</td>\n",
       "      <td>122</td>\n",
       "      <td>0.866406</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1795</td>\n",
       "      <td>20</td>\n",
       "      <td>1696</td>\n",
       "      <td>973</td>\n",
       "      <td>980</td>\n",
       "      <td>386.93787</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>164</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1399</td>\n",
       "      <td>12</td>\n",
       "      <td>1134</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>338.93784</td>\n",
       "      <td>4</td>\n",
       "      <td>174</td>\n",
       "      <td>86</td>\n",
       "      <td>5.865247</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>968</td>\n",
       "      <td>2</td>\n",
       "      <td>956</td>\n",
       "      <td>524</td>\n",
       "      <td>600</td>\n",
       "      <td>386.93787</td>\n",
       "      <td>3</td>\n",
       "      <td>168</td>\n",
       "      <td>92</td>\n",
       "      <td>9.264421</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "      <td>27</td>\n",
       "      <td>1363</td>\n",
       "      <td>960</td>\n",
       "      <td>960</td>\n",
       "      <td>314.93780</td>\n",
       "      <td>4</td>\n",
       "      <td>176</td>\n",
       "      <td>88</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1395</td>\n",
       "      <td>19</td>\n",
       "      <td>1116</td>\n",
       "      <td>646</td>\n",
       "      <td>780</td>\n",
       "      <td>338.93784</td>\n",
       "      <td>4</td>\n",
       "      <td>86</td>\n",
       "      <td>172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>745</td>\n",
       "      <td>0</td>\n",
       "      <td>878</td>\n",
       "      <td>572</td>\n",
       "      <td>620</td>\n",
       "      <td>386.93787</td>\n",
       "      <td>3</td>\n",
       "      <td>176</td>\n",
       "      <td>98</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1532</td>\n",
       "      <td>14</td>\n",
       "      <td>2146</td>\n",
       "      <td>475</td>\n",
       "      <td>680</td>\n",
       "      <td>398.93787</td>\n",
       "      <td>5</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>693</td>\n",
       "      <td>4</td>\n",
       "      <td>1141</td>\n",
       "      <td>800</td>\n",
       "      <td>820</td>\n",
       "      <td>398.93787</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>170</td>\n",
       "      <td>8.064658</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f92514f84257d27d74e8f5e423ba1417</td>\n",
       "      <td>491</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2431</td>\n",
       "      <td>35</td>\n",
       "      <td>2823</td>\n",
       "      <td>594</td>\n",
       "      <td>880</td>\n",
       "      <td>434.93793</td>\n",
       "      <td>6</td>\n",
       "      <td>126</td>\n",
       "      <td>128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1552</td>\n",
       "      <td>6</td>\n",
       "      <td>1236</td>\n",
       "      <td>245</td>\n",
       "      <td>700</td>\n",
       "      <td>314.93780</td>\n",
       "      <td>4</td>\n",
       "      <td>138</td>\n",
       "      <td>142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2582</td>\n",
       "      <td>22</td>\n",
       "      <td>2710</td>\n",
       "      <td>701</td>\n",
       "      <td>820</td>\n",
       "      <td>446.93793</td>\n",
       "      <td>6</td>\n",
       "      <td>174</td>\n",
       "      <td>94</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1501</td>\n",
       "      <td>2</td>\n",
       "      <td>1799</td>\n",
       "      <td>842</td>\n",
       "      <td>1020</td>\n",
       "      <td>338.93784</td>\n",
       "      <td>5</td>\n",
       "      <td>138</td>\n",
       "      <td>136</td>\n",
       "      <td>1.099731</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3941</td>\n",
       "      <td>28</td>\n",
       "      <td>1687</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>470.93796</td>\n",
       "      <td>5</td>\n",
       "      <td>88</td>\n",
       "      <td>144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>2548</td>\n",
       "      <td>40</td>\n",
       "      <td>3508</td>\n",
       "      <td>1260</td>\n",
       "      <td>1260</td>\n",
       "      <td>374.93787</td>\n",
       "      <td>7</td>\n",
       "      <td>176</td>\n",
       "      <td>96</td>\n",
       "      <td>6.731657</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1709</td>\n",
       "      <td>20</td>\n",
       "      <td>3685</td>\n",
       "      <td>620</td>\n",
       "      <td>1000</td>\n",
       "      <td>1117.93860</td>\n",
       "      <td>8</td>\n",
       "      <td>140</td>\n",
       "      <td>138</td>\n",
       "      <td>19.961782</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2550</td>\n",
       "      <td>40</td>\n",
       "      <td>2206</td>\n",
       "      <td>824</td>\n",
       "      <td>1120</td>\n",
       "      <td>338.93784</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>160</td>\n",
       "      <td>6.731668</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>865</td>\n",
       "      <td>2</td>\n",
       "      <td>1488</td>\n",
       "      <td>720</td>\n",
       "      <td>720</td>\n",
       "      <td>506.93800</td>\n",
       "      <td>4</td>\n",
       "      <td>92</td>\n",
       "      <td>156</td>\n",
       "      <td>5.398687</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2262</td>\n",
       "      <td>61</td>\n",
       "      <td>2130</td>\n",
       "      <td>880</td>\n",
       "      <td>880</td>\n",
       "      <td>374.93787</td>\n",
       "      <td>5</td>\n",
       "      <td>106</td>\n",
       "      <td>158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>af89bd6b4829e1d02ce991815fd006d3</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>660</td>\n",
       "      <td>660</td>\n",
       "      <td>290.93777</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "      <td>338.93784</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>78</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "      <td>350.93784</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>720</td>\n",
       "      <td>720</td>\n",
       "      <td>254.93774</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>520</td>\n",
       "      <td>314.93780</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "      <td>242.93773</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>278.93777</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "      <td>362.93784</td>\n",
       "      <td>1</td>\n",
       "      <td>134</td>\n",
       "      <td>132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>560</td>\n",
       "      <td>560</td>\n",
       "      <td>290.93777</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>660</td>\n",
       "      <td>660</td>\n",
       "      <td>266.93774</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a9ca6226f3d750c056302d3c46e03f06</td>\n",
       "      <td>1450</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "      <td>63</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>14058</td>\n",
       "      <td>163</td>\n",
       "      <td>13648</td>\n",
       "      <td>1660</td>\n",
       "      <td>1660</td>\n",
       "      <td>806.93830</td>\n",
       "      <td>17</td>\n",
       "      <td>174</td>\n",
       "      <td>154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>6856</td>\n",
       "      <td>9</td>\n",
       "      <td>6006</td>\n",
       "      <td>884</td>\n",
       "      <td>940</td>\n",
       "      <td>960.93840</td>\n",
       "      <td>11</td>\n",
       "      <td>160</td>\n",
       "      <td>156</td>\n",
       "      <td>3.532471</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8905</td>\n",
       "      <td>49</td>\n",
       "      <td>8623</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>770.93823</td>\n",
       "      <td>13</td>\n",
       "      <td>132</td>\n",
       "      <td>130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>11295</td>\n",
       "      <td>112</td>\n",
       "      <td>13158</td>\n",
       "      <td>1453</td>\n",
       "      <td>1655</td>\n",
       "      <td>1365.93880</td>\n",
       "      <td>17</td>\n",
       "      <td>170</td>\n",
       "      <td>148</td>\n",
       "      <td>24.493260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>15182</td>\n",
       "      <td>197</td>\n",
       "      <td>12495</td>\n",
       "      <td>1920</td>\n",
       "      <td>1920</td>\n",
       "      <td>626.93810</td>\n",
       "      <td>16</td>\n",
       "      <td>160</td>\n",
       "      <td>164</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7232</td>\n",
       "      <td>25</td>\n",
       "      <td>9005</td>\n",
       "      <td>1020</td>\n",
       "      <td>1020</td>\n",
       "      <td>434.93793</td>\n",
       "      <td>14</td>\n",
       "      <td>182</td>\n",
       "      <td>176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4337</td>\n",
       "      <td>31</td>\n",
       "      <td>3583</td>\n",
       "      <td>0</td>\n",
       "      <td>960</td>\n",
       "      <td>398.93787</td>\n",
       "      <td>7</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>3.032593</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8679</td>\n",
       "      <td>125</td>\n",
       "      <td>8517</td>\n",
       "      <td>0</td>\n",
       "      <td>1040</td>\n",
       "      <td>506.93800</td>\n",
       "      <td>13</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5851</td>\n",
       "      <td>25</td>\n",
       "      <td>4765</td>\n",
       "      <td>0</td>\n",
       "      <td>1260</td>\n",
       "      <td>386.93787</td>\n",
       "      <td>9</td>\n",
       "      <td>158</td>\n",
       "      <td>156</td>\n",
       "      <td>4.398926</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>17309</td>\n",
       "      <td>57</td>\n",
       "      <td>13462</td>\n",
       "      <td>1671</td>\n",
       "      <td>1815</td>\n",
       "      <td>1743.93920</td>\n",
       "      <td>17</td>\n",
       "      <td>180</td>\n",
       "      <td>92</td>\n",
       "      <td>3.499793</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2e81f5ba5ffe5422009b5de286066428</td>\n",
       "      <td>442</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2865</td>\n",
       "      <td>43</td>\n",
       "      <td>2003</td>\n",
       "      <td>860</td>\n",
       "      <td>860</td>\n",
       "      <td>362.93784</td>\n",
       "      <td>5</td>\n",
       "      <td>176</td>\n",
       "      <td>112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>818</td>\n",
       "      <td>0</td>\n",
       "      <td>547</td>\n",
       "      <td>580</td>\n",
       "      <td>580</td>\n",
       "      <td>290.93777</td>\n",
       "      <td>2</td>\n",
       "      <td>84</td>\n",
       "      <td>140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>2528</td>\n",
       "      <td>26</td>\n",
       "      <td>2958</td>\n",
       "      <td>352</td>\n",
       "      <td>760</td>\n",
       "      <td>780.93823</td>\n",
       "      <td>7</td>\n",
       "      <td>104</td>\n",
       "      <td>138</td>\n",
       "      <td>5.531995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>977</td>\n",
       "      <td>1</td>\n",
       "      <td>966</td>\n",
       "      <td>608</td>\n",
       "      <td>620</td>\n",
       "      <td>386.93787</td>\n",
       "      <td>3</td>\n",
       "      <td>166</td>\n",
       "      <td>92</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1517</td>\n",
       "      <td>2</td>\n",
       "      <td>1480</td>\n",
       "      <td>598</td>\n",
       "      <td>640</td>\n",
       "      <td>278.93777</td>\n",
       "      <td>4</td>\n",
       "      <td>178</td>\n",
       "      <td>118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>3189</td>\n",
       "      <td>54</td>\n",
       "      <td>3158</td>\n",
       "      <td>789</td>\n",
       "      <td>800</td>\n",
       "      <td>470.93796</td>\n",
       "      <td>7</td>\n",
       "      <td>78</td>\n",
       "      <td>146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1302</td>\n",
       "      <td>6</td>\n",
       "      <td>1000</td>\n",
       "      <td>860</td>\n",
       "      <td>860</td>\n",
       "      <td>386.93787</td>\n",
       "      <td>3</td>\n",
       "      <td>180</td>\n",
       "      <td>156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1773</td>\n",
       "      <td>19</td>\n",
       "      <td>2003</td>\n",
       "      <td>475</td>\n",
       "      <td>780</td>\n",
       "      <td>566.93805</td>\n",
       "      <td>5</td>\n",
       "      <td>182</td>\n",
       "      <td>174</td>\n",
       "      <td>1.299640</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1374</td>\n",
       "      <td>1</td>\n",
       "      <td>893</td>\n",
       "      <td>365</td>\n",
       "      <td>640</td>\n",
       "      <td>422.93790</td>\n",
       "      <td>3</td>\n",
       "      <td>74</td>\n",
       "      <td>160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1795</td>\n",
       "      <td>3</td>\n",
       "      <td>908</td>\n",
       "      <td>832</td>\n",
       "      <td>840</td>\n",
       "      <td>278.93777</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>0.566528</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      match_id_hash  game_time  game_mode  lobby_type  \\\n",
       "0  205e85408fa923b744523db4655f7cf7        337         22           7   \n",
       "1  f92514f84257d27d74e8f5e423ba1417        491         22           7   \n",
       "2  af89bd6b4829e1d02ce991815fd006d3         18         22           7   \n",
       "3  a9ca6226f3d750c056302d3c46e03f06       1450         22           0   \n",
       "4  2e81f5ba5ffe5422009b5de286066428        442         22           7   \n",
       "\n",
       "   objectives_len  chat_len  r1_hero_id  r1_kills  r1_deaths  r1_assists  \\\n",
       "0               1         2          71         1          0           1   \n",
       "1               1         1          94         0          0           0   \n",
       "2               0         0         100         0          0           0   \n",
       "3              13        39          63         5          2           5   \n",
       "4               1         1           8         1          1           0   \n",
       "\n",
       "   r1_denies  r1_gold  r1_lh  r1_xp  r1_health  r1_max_health  r1_max_mana  \\\n",
       "0          0      983      0    726        749            920    302.93777   \n",
       "1          6     2431     35   2823        594            880    434.93793   \n",
       "2          0      147      0      0        660            660    290.93777   \n",
       "3         17    14058    163  13648       1660           1660    806.93830   \n",
       "4         23     2865     43   2003        860            860    362.93784   \n",
       "\n",
       "   r1_level  r1_x  r1_y  r1_stuns  r1_creeps_stacked  r1_camps_stacked  \\\n",
       "0         3    74    74  9.697543                  0                 0   \n",
       "1         6   126   128  0.000000                  0                 0   \n",
       "2         1    78   132  0.000000                  0                 0   \n",
       "3        17   174   154  0.000000                  0                 0   \n",
       "4         5   176   112  0.000000                  0                 0   \n",
       "\n",
       "   r1_rune_pickups  r1_firstblood_claimed  r1_teamfight_participation  \\\n",
       "0                5                      0                    0.333333   \n",
       "1                0                      0                    0.000000   \n",
       "2                0                      0                    0.000000   \n",
       "3               10                      0                    0.476190   \n",
       "4                2                      0                    0.200000   \n",
       "\n",
       "   r1_towers_killed  r1_roshans_killed  r1_obs_placed  r1_sen_placed  \\\n",
       "0                 0                  0              1              0   \n",
       "1                 0                  0              0              0   \n",
       "2                 0                  0              1              0   \n",
       "3                 1                  0              1              0   \n",
       "4                 0                  0              0              0   \n",
       "\n",
       "   r2_hero_id  r2_kills  r2_deaths  r2_assists  r2_denies  r2_gold  r2_lh  \\\n",
       "0          74         0          1           1          6     1450     18   \n",
       "1          32         0          0           4          1     1552      6   \n",
       "2         114         0          0           0          0      147      0   \n",
       "3          68         2          1          12          2     6856      9   \n",
       "4         120         0          2           0          0      818      0   \n",
       "\n",
       "   r2_xp  r2_health  r2_max_health  r2_max_mana  r2_level  r2_x  r2_y  \\\n",
       "0   2487        697            820    554.93805         6   116   122   \n",
       "1   1236        245            700    314.93780         4   138   142   \n",
       "2      0        600            600    338.93784         1   148    78   \n",
       "3   6006        884            940    960.93840        11   160   156   \n",
       "4    547        580            580    290.93777         2    84   140   \n",
       "\n",
       "   r2_stuns  r2_creeps_stacked  r2_camps_stacked  r2_rune_pickups  \\\n",
       "0  0.866406                  0                 0                0   \n",
       "1  0.000000                  0                 0                4   \n",
       "2  0.000000                  0                 0                2   \n",
       "3  3.532471                  0                 0                6   \n",
       "4  0.000000                  0                 0                1   \n",
       "\n",
       "   r2_firstblood_claimed  r2_teamfight_participation  r2_towers_killed  \\\n",
       "0                      0                    0.333333                 0   \n",
       "1                      0                    0.666667                 0   \n",
       "2                      0                    0.000000                 0   \n",
       "3                      0                    0.666667                 0   \n",
       "4                      0                    0.000000                 0   \n",
       "\n",
       "   r2_roshans_killed  r2_obs_placed  r2_sen_placed  r3_hero_id  r3_kills  \\\n",
       "0                  0              0              0          29         0   \n",
       "1                  0              0              0          12         3   \n",
       "2                  0              0              0          11         0   \n",
       "3                  0              3              0          40         2   \n",
       "4                  0              0              0         119         3   \n",
       "\n",
       "   r3_deaths  r3_assists  r3_denies  r3_gold  r3_lh  r3_xp  r3_health  \\\n",
       "0          0           1          3     1795     20   1696        973   \n",
       "1          0           0          1     2582     22   2710        701   \n",
       "2          0           0          0      147      0      0        600   \n",
       "3          5           8          1     8905     49   8623       1460   \n",
       "4          0           0         22     2528     26   2958        352   \n",
       "\n",
       "   r3_max_health  r3_max_mana  r3_level  r3_x  r3_y  r3_stuns  \\\n",
       "0            980    386.93787         5    76   164  0.000000   \n",
       "1            820    446.93793         6   174    94  0.000000   \n",
       "2            600    350.93784         1   116   114  0.000000   \n",
       "3           1460    770.93823        13   132   130  0.000000   \n",
       "4            760    780.93823         7   104   138  5.531995   \n",
       "\n",
       "   r3_creeps_stacked  r3_camps_stacked  r3_rune_pickups  \\\n",
       "0                  0                 0                3   \n",
       "1                  0                 0                2   \n",
       "2                  0                 0                0   \n",
       "3                  0                 0               11   \n",
       "4                  0                 0                2   \n",
       "\n",
       "   r3_firstblood_claimed  r3_teamfight_participation  r3_towers_killed  \\\n",
       "0                      0                    0.333333                 0   \n",
       "1                      1                    0.500000                 0   \n",
       "2                      0                    0.000000                 0   \n",
       "3                      0                    0.476190                 1   \n",
       "4                      0                    0.600000                 0   \n",
       "\n",
       "   r3_roshans_killed  r3_obs_placed  r3_sen_placed  r4_hero_id  r4_kills  \\\n",
       "0                  0              0              0          42         1   \n",
       "1                  0              0              0          14         1   \n",
       "2                  0              0              0          69         0   \n",
       "3                  0              1              6          74         3   \n",
       "4                  0              1              0          91         0   \n",
       "\n",
       "   r4_deaths  r4_assists  r4_denies  r4_gold  r4_lh  r4_xp  r4_health  \\\n",
       "0          0           0          1     1399     12   1134        800   \n",
       "1          0           4          2     1501      2   1799        842   \n",
       "2          0           0          0      147      0      0        720   \n",
       "3          1           9         13    11295    112  13158       1453   \n",
       "4          1           3          2      977      1    966        608   \n",
       "\n",
       "   r4_max_health  r4_max_mana  r4_level  r4_x  r4_y   r4_stuns  \\\n",
       "0            800    338.93784         4   174    86   5.865247   \n",
       "1           1020    338.93784         5   138   136   1.099731   \n",
       "2            720    254.93774         1    78   136   0.000000   \n",
       "3           1655   1365.93880        17   170   148  24.493260   \n",
       "4            620    386.93787         3   166    92   0.000000   \n",
       "\n",
       "   r4_creeps_stacked  r4_camps_stacked  r4_rune_pickups  \\\n",
       "0                  0                 0                1   \n",
       "1                  0                 0                1   \n",
       "2                  0                 0                1   \n",
       "3                  0                 0                2   \n",
       "4                  0                 0                1   \n",
       "\n",
       "   r4_firstblood_claimed  r4_teamfight_participation  r4_towers_killed  \\\n",
       "0                      0                    0.333333                 0   \n",
       "1                      0                    0.833333                 0   \n",
       "2                      0                    0.000000                 0   \n",
       "3                      0                    0.571429                 2   \n",
       "4                      0                    0.600000                 0   \n",
       "\n",
       "   r4_roshans_killed  r4_obs_placed  r4_sen_placed  r5_hero_id  r5_kills  \\\n",
       "0                  0              0              0          26         1   \n",
       "1                  0              0              1          73         2   \n",
       "2                  0              0              0          26         0   \n",
       "3                  0              0              0           4         9   \n",
       "4                  0              1              0          32         1   \n",
       "\n",
       "   r5_deaths  r5_assists  r5_denies  r5_gold  r5_lh  r5_xp  r5_health  \\\n",
       "0          1           1          5      968      2    956        524   \n",
       "1          0           0          0     3941     28   1687       1000   \n",
       "2          0           0          0      147      0      0        520   \n",
       "3          3           4         35    15182    197  12495       1920   \n",
       "4          1           3          0     1517      2   1480        598   \n",
       "\n",
       "   r5_max_health  r5_max_mana  r5_level  r5_x  r5_y  r5_stuns  \\\n",
       "0            600    386.93787         3   168    92  9.264421   \n",
       "1           1000    470.93796         5    88   144  0.000000   \n",
       "2            520    314.93780         1   156    90  0.000000   \n",
       "3           1920    626.93810        16   160   164  0.000000   \n",
       "4            640    278.93777         4   178   118  0.000000   \n",
       "\n",
       "   r5_creeps_stacked  r5_camps_stacked  r5_rune_pickups  \\\n",
       "0                  0                 0                1   \n",
       "1                  0                 0                6   \n",
       "2                  0                 0                0   \n",
       "3                  0                 0                3   \n",
       "4                  0                 0                4   \n",
       "\n",
       "   r5_firstblood_claimed  r5_teamfight_participation  r5_towers_killed  \\\n",
       "0                      0                    0.666667                 0   \n",
       "1                      0                    0.333333                 0   \n",
       "2                      0                    0.000000                 0   \n",
       "3                      1                    0.619048                 2   \n",
       "4                      0                    0.800000                 0   \n",
       "\n",
       "   r5_roshans_killed  r5_obs_placed  r5_sen_placed  d1_hero_id  d1_kills  \\\n",
       "0                  0              1              0          49         1   \n",
       "1                  0              0              0          81         0   \n",
       "2                  0              1              0           8         0   \n",
       "3                  0              0              0          32         3   \n",
       "4                  0              0              1         109         0   \n",
       "\n",
       "   d1_deaths  d1_assists  d1_denies  d1_gold  d1_lh  d1_xp  d1_health  \\\n",
       "0          0           0          9     2013     27   1363        960   \n",
       "1          3           0         22     2548     40   3508       1260   \n",
       "2          0           0          0       67      0      0        600   \n",
       "3          2           4          6     7232     25   9005       1020   \n",
       "4          0           0         39     3189     54   3158        789   \n",
       "\n",
       "   d1_max_health  d1_max_mana  d1_level  d1_x  d1_y  d1_stuns  \\\n",
       "0            960    314.93780         4   176    88  0.000000   \n",
       "1           1260    374.93787         7   176    96  6.731657   \n",
       "2            600    242.93773         1   110   174  0.000000   \n",
       "3           1020    434.93793        14   182   176  0.000000   \n",
       "4            800    470.93796         7    78   146  0.000000   \n",
       "\n",
       "   d1_creeps_stacked  d1_camps_stacked  d1_rune_pickups  \\\n",
       "0                  0                 0                1   \n",
       "1                  0                 0                0   \n",
       "2                  0                 0                1   \n",
       "3                  0                 0                3   \n",
       "4                  0                 0                1   \n",
       "\n",
       "   d1_firstblood_claimed  d1_teamfight_participation  d1_towers_killed  \\\n",
       "0                      1                    0.500000                 0   \n",
       "1                      0                    0.000000                 0   \n",
       "2                      0                    0.000000                 0   \n",
       "3                      0                    0.583333                 0   \n",
       "4                      0                    0.000000                 0   \n",
       "\n",
       "   d1_roshans_killed  d1_obs_placed  d1_sen_placed  d2_hero_id  d2_kills  \\\n",
       "0                  0              0              0          44         0   \n",
       "1                  0              0              0          76         0   \n",
       "2                  0              0              0          44         0   \n",
       "3                  0              0              2          38         1   \n",
       "4                  0              0              0         104         1   \n",
       "\n",
       "   d2_deaths  d2_assists  d2_denies  d2_gold  d2_lh  d2_xp  d2_health  \\\n",
       "0          1           0          0     1395     19   1116        646   \n",
       "1          0           0         16     1709     20   3685        620   \n",
       "2          0           0          0       67      0      0        640   \n",
       "3          6           2          3     4337     31   3583          0   \n",
       "4          3           2          2     1302      6   1000        860   \n",
       "\n",
       "   d2_max_health  d2_max_mana  d2_level  d2_x  d2_y   d2_stuns  \\\n",
       "0            780    338.93784         4    86   172   0.000000   \n",
       "1           1000   1117.93860         8   140   138  19.961782   \n",
       "2            640    278.93777         1   120   114   0.000000   \n",
       "3            960    398.93787         7   156   156   3.032593   \n",
       "4            860    386.93787         3   180   156   0.000000   \n",
       "\n",
       "   d2_creeps_stacked  d2_camps_stacked  d2_rune_pickups  \\\n",
       "0                  0                 0                0   \n",
       "1                  0                 0                0   \n",
       "2                  0                 0                0   \n",
       "3                  0                 0                2   \n",
       "4                  0                 0                1   \n",
       "\n",
       "   d2_firstblood_claimed  d2_teamfight_participation  d2_towers_killed  \\\n",
       "0                      0                        0.00                 0   \n",
       "1                      0                        0.00                 0   \n",
       "2                      0                        0.00                 0   \n",
       "3                      0                        0.25                 0   \n",
       "4                      0                        0.60                 0   \n",
       "\n",
       "   d2_roshans_killed  d2_obs_placed  d2_sen_placed  d3_hero_id  d3_kills  \\\n",
       "0                  0              0              0          91         0   \n",
       "1                  0              0              1          18         0   \n",
       "2                  0              0              0          74         0   \n",
       "3                  0              0              0          93         2   \n",
       "4                  0              0              0          74         1   \n",
       "\n",
       "   d3_deaths  d3_assists  d3_denies  d3_gold  d3_lh  d3_xp  d3_health  \\\n",
       "0          2           1          1      745      0    878        572   \n",
       "1          2           0         15     2550     40   2206        824   \n",
       "2          0           0          0       67      0      0        600   \n",
       "3          6           2          3     8679    125   8517          0   \n",
       "4          1           0          7     1773     19   2003        475   \n",
       "\n",
       "   d3_max_health  d3_max_mana  d3_level  d3_x  d3_y  d3_stuns  \\\n",
       "0            620    386.93787         3   176    98  0.000000   \n",
       "1           1120    338.93784         5    78   160  6.731668   \n",
       "2            600    362.93784         1   134   132  0.000000   \n",
       "3           1040    506.93800        13   154   154  0.000000   \n",
       "4            780    566.93805         5   182   174  1.299640   \n",
       "\n",
       "   d3_creeps_stacked  d3_camps_stacked  d3_rune_pickups  \\\n",
       "0                  0                 0                2   \n",
       "1                  0                 0                1   \n",
       "2                  0                 0                0   \n",
       "3                  3                 1                3   \n",
       "4                  0                 0                0   \n",
       "\n",
       "   d3_firstblood_claimed  d3_teamfight_participation  d3_towers_killed  \\\n",
       "0                      0                    0.500000                 0   \n",
       "1                      0                    0.000000                 0   \n",
       "2                      0                    0.000000                 0   \n",
       "3                      0                    0.333333                 0   \n",
       "4                      0                    0.200000                 0   \n",
       "\n",
       "   d3_roshans_killed  d3_obs_placed  d3_sen_placed  d4_hero_id  d4_kills  \\\n",
       "0                  0              1              0          35         1   \n",
       "1                  0              0              0          86         0   \n",
       "2                  0              0              0          31         0   \n",
       "3                  0              0              0          14         1   \n",
       "4                  0              0              1          43         1   \n",
       "\n",
       "   d4_deaths  d4_assists  d4_denies  d4_gold  d4_lh  d4_xp  d4_health  \\\n",
       "0          0           0          2     1532     14   2146        475   \n",
       "1          1           0          0      865      2   1488        720   \n",
       "2          0           0          0       67      0     69        560   \n",
       "3          6           4          1     5851     25   4765          0   \n",
       "4          0           1          2     1374      1    893        365   \n",
       "\n",
       "   d4_max_health  d4_max_mana  d4_level  d4_x  d4_y  d4_stuns  \\\n",
       "0            680    398.93787         5   124   124  0.000000   \n",
       "1            720    506.93800         4    92   156  5.398687   \n",
       "2            560    290.93777         1   110   174  0.000000   \n",
       "3           1260    386.93787         9   158   156  4.398926   \n",
       "4            640    422.93790         3    74   160  0.000000   \n",
       "\n",
       "   d4_creeps_stacked  d4_camps_stacked  d4_rune_pickups  \\\n",
       "0                  0                 0                1   \n",
       "1                  0                 0                0   \n",
       "2                  0                 0                0   \n",
       "3                  0                 0                6   \n",
       "4                  8                 3                6   \n",
       "\n",
       "   d4_firstblood_claimed  d4_teamfight_participation  d4_towers_killed  \\\n",
       "0                      0                    0.500000                 0   \n",
       "1                      0                    0.000000                 0   \n",
       "2                      0                    0.000000                 0   \n",
       "3                      0                    0.416667                 0   \n",
       "4                      0                    0.400000                 0   \n",
       "\n",
       "   d4_roshans_killed  d4_obs_placed  d4_sen_placed  d5_hero_id  d5_kills  \\\n",
       "0                  0              0              0         103         0   \n",
       "1                  0              3              1          42         0   \n",
       "2                  0              0              0          57         0   \n",
       "3                  0              0              0          22         4   \n",
       "4                  0              1              0          14         2   \n",
       "\n",
       "   d5_deaths  d5_assists  d5_denies  d5_gold  d5_lh  d5_xp  d5_health  \\\n",
       "0          0           0          1      693      4   1141        800   \n",
       "1          0           0          0     2262     61   2130        880   \n",
       "2          0           0          0       67      0      0        660   \n",
       "3          2           3          2    17309     57  13462       1671   \n",
       "4          2           1          0     1795      3    908        832   \n",
       "\n",
       "   d5_max_health  d5_max_mana  d5_level  d5_x  d5_y  d5_stuns  \\\n",
       "0            820    398.93787         4    80   170  8.064658   \n",
       "1            880    374.93787         5   106   158  0.000000   \n",
       "2            660    266.93774         1   178   122  0.000000   \n",
       "3           1815   1743.93920        17   180    92  3.499793   \n",
       "4            840    278.93777         3   130   130  0.566528   \n",
       "\n",
       "   d5_creeps_stacked  d5_camps_stacked  d5_rune_pickups  \\\n",
       "0                  0                 0                0   \n",
       "1                  0                 0                2   \n",
       "2                  0                 0                0   \n",
       "3                  3                 1               10   \n",
       "4                  3                 1                1   \n",
       "\n",
       "   d5_firstblood_claimed  d5_teamfight_participation  d5_towers_killed  \\\n",
       "0                      0                    0.000000                 0   \n",
       "1                      0                    0.000000                 0   \n",
       "2                      0                    0.000000                 0   \n",
       "3                      0                    0.583333                 0   \n",
       "4                      1                    0.600000                 0   \n",
       "\n",
       "   d5_roshans_killed  d5_obs_placed  d5_sen_placed  \n",
       "0                  0              1              0  \n",
       "1                  0              0              0  \n",
       "2                  0              0              0  \n",
       "3                  0              0              0  \n",
       "4                  0              1              1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_time</th>\n",
       "      <th>game_mode</th>\n",
       "      <th>lobby_type</th>\n",
       "      <th>objectives_len</th>\n",
       "      <th>chat_len</th>\n",
       "      <th>r1_hero_id</th>\n",
       "      <th>r1_kills</th>\n",
       "      <th>r1_deaths</th>\n",
       "      <th>r1_assists</th>\n",
       "      <th>r1_denies</th>\n",
       "      <th>r1_gold</th>\n",
       "      <th>r1_lh</th>\n",
       "      <th>r1_xp</th>\n",
       "      <th>r1_health</th>\n",
       "      <th>r1_max_health</th>\n",
       "      <th>r1_max_mana</th>\n",
       "      <th>r1_level</th>\n",
       "      <th>r1_x</th>\n",
       "      <th>r1_y</th>\n",
       "      <th>r1_stuns</th>\n",
       "      <th>r1_creeps_stacked</th>\n",
       "      <th>r1_camps_stacked</th>\n",
       "      <th>r1_rune_pickups</th>\n",
       "      <th>r1_firstblood_claimed</th>\n",
       "      <th>r1_teamfight_participation</th>\n",
       "      <th>r1_towers_killed</th>\n",
       "      <th>r1_roshans_killed</th>\n",
       "      <th>r1_obs_placed</th>\n",
       "      <th>r1_sen_placed</th>\n",
       "      <th>r2_hero_id</th>\n",
       "      <th>r2_kills</th>\n",
       "      <th>r2_deaths</th>\n",
       "      <th>r2_assists</th>\n",
       "      <th>r2_denies</th>\n",
       "      <th>r2_gold</th>\n",
       "      <th>r2_lh</th>\n",
       "      <th>r2_xp</th>\n",
       "      <th>r2_health</th>\n",
       "      <th>r2_max_health</th>\n",
       "      <th>r2_max_mana</th>\n",
       "      <th>r2_level</th>\n",
       "      <th>r2_x</th>\n",
       "      <th>r2_y</th>\n",
       "      <th>r2_stuns</th>\n",
       "      <th>r2_creeps_stacked</th>\n",
       "      <th>r2_camps_stacked</th>\n",
       "      <th>r2_rune_pickups</th>\n",
       "      <th>r2_firstblood_claimed</th>\n",
       "      <th>r2_teamfight_participation</th>\n",
       "      <th>r2_towers_killed</th>\n",
       "      <th>r2_roshans_killed</th>\n",
       "      <th>r2_obs_placed</th>\n",
       "      <th>r2_sen_placed</th>\n",
       "      <th>r3_hero_id</th>\n",
       "      <th>r3_kills</th>\n",
       "      <th>r3_deaths</th>\n",
       "      <th>r3_assists</th>\n",
       "      <th>r3_denies</th>\n",
       "      <th>r3_gold</th>\n",
       "      <th>r3_lh</th>\n",
       "      <th>r3_xp</th>\n",
       "      <th>r3_health</th>\n",
       "      <th>r3_max_health</th>\n",
       "      <th>r3_max_mana</th>\n",
       "      <th>r3_level</th>\n",
       "      <th>r3_x</th>\n",
       "      <th>r3_y</th>\n",
       "      <th>r3_stuns</th>\n",
       "      <th>r3_creeps_stacked</th>\n",
       "      <th>r3_camps_stacked</th>\n",
       "      <th>r3_rune_pickups</th>\n",
       "      <th>r3_firstblood_claimed</th>\n",
       "      <th>r3_teamfight_participation</th>\n",
       "      <th>r3_towers_killed</th>\n",
       "      <th>r3_roshans_killed</th>\n",
       "      <th>r3_obs_placed</th>\n",
       "      <th>r3_sen_placed</th>\n",
       "      <th>r4_hero_id</th>\n",
       "      <th>r4_kills</th>\n",
       "      <th>r4_deaths</th>\n",
       "      <th>r4_assists</th>\n",
       "      <th>r4_denies</th>\n",
       "      <th>r4_gold</th>\n",
       "      <th>r4_lh</th>\n",
       "      <th>r4_xp</th>\n",
       "      <th>r4_health</th>\n",
       "      <th>r4_max_health</th>\n",
       "      <th>r4_max_mana</th>\n",
       "      <th>r4_level</th>\n",
       "      <th>r4_x</th>\n",
       "      <th>r4_y</th>\n",
       "      <th>r4_stuns</th>\n",
       "      <th>r4_creeps_stacked</th>\n",
       "      <th>r4_camps_stacked</th>\n",
       "      <th>r4_rune_pickups</th>\n",
       "      <th>r4_firstblood_claimed</th>\n",
       "      <th>r4_teamfight_participation</th>\n",
       "      <th>r4_towers_killed</th>\n",
       "      <th>r4_roshans_killed</th>\n",
       "      <th>r4_obs_placed</th>\n",
       "      <th>r4_sen_placed</th>\n",
       "      <th>r5_hero_id</th>\n",
       "      <th>r5_kills</th>\n",
       "      <th>r5_deaths</th>\n",
       "      <th>r5_assists</th>\n",
       "      <th>r5_denies</th>\n",
       "      <th>r5_gold</th>\n",
       "      <th>r5_lh</th>\n",
       "      <th>r5_xp</th>\n",
       "      <th>r5_health</th>\n",
       "      <th>r5_max_health</th>\n",
       "      <th>r5_max_mana</th>\n",
       "      <th>r5_level</th>\n",
       "      <th>r5_x</th>\n",
       "      <th>r5_y</th>\n",
       "      <th>r5_stuns</th>\n",
       "      <th>r5_creeps_stacked</th>\n",
       "      <th>r5_camps_stacked</th>\n",
       "      <th>r5_rune_pickups</th>\n",
       "      <th>r5_firstblood_claimed</th>\n",
       "      <th>r5_teamfight_participation</th>\n",
       "      <th>r5_towers_killed</th>\n",
       "      <th>r5_roshans_killed</th>\n",
       "      <th>r5_obs_placed</th>\n",
       "      <th>r5_sen_placed</th>\n",
       "      <th>d1_hero_id</th>\n",
       "      <th>d1_kills</th>\n",
       "      <th>d1_deaths</th>\n",
       "      <th>d1_assists</th>\n",
       "      <th>d1_denies</th>\n",
       "      <th>d1_gold</th>\n",
       "      <th>d1_lh</th>\n",
       "      <th>d1_xp</th>\n",
       "      <th>d1_health</th>\n",
       "      <th>d1_max_health</th>\n",
       "      <th>d1_max_mana</th>\n",
       "      <th>d1_level</th>\n",
       "      <th>d1_x</th>\n",
       "      <th>d1_y</th>\n",
       "      <th>d1_stuns</th>\n",
       "      <th>d1_creeps_stacked</th>\n",
       "      <th>d1_camps_stacked</th>\n",
       "      <th>d1_rune_pickups</th>\n",
       "      <th>d1_firstblood_claimed</th>\n",
       "      <th>d1_teamfight_participation</th>\n",
       "      <th>d1_towers_killed</th>\n",
       "      <th>d1_roshans_killed</th>\n",
       "      <th>d1_obs_placed</th>\n",
       "      <th>d1_sen_placed</th>\n",
       "      <th>d2_hero_id</th>\n",
       "      <th>d2_kills</th>\n",
       "      <th>d2_deaths</th>\n",
       "      <th>d2_assists</th>\n",
       "      <th>d2_denies</th>\n",
       "      <th>d2_gold</th>\n",
       "      <th>d2_lh</th>\n",
       "      <th>d2_xp</th>\n",
       "      <th>d2_health</th>\n",
       "      <th>d2_max_health</th>\n",
       "      <th>d2_max_mana</th>\n",
       "      <th>d2_level</th>\n",
       "      <th>d2_x</th>\n",
       "      <th>d2_y</th>\n",
       "      <th>d2_stuns</th>\n",
       "      <th>d2_creeps_stacked</th>\n",
       "      <th>d2_camps_stacked</th>\n",
       "      <th>d2_rune_pickups</th>\n",
       "      <th>d2_firstblood_claimed</th>\n",
       "      <th>d2_teamfight_participation</th>\n",
       "      <th>d2_towers_killed</th>\n",
       "      <th>d2_roshans_killed</th>\n",
       "      <th>d2_obs_placed</th>\n",
       "      <th>d2_sen_placed</th>\n",
       "      <th>d3_hero_id</th>\n",
       "      <th>d3_kills</th>\n",
       "      <th>d3_deaths</th>\n",
       "      <th>d3_assists</th>\n",
       "      <th>d3_denies</th>\n",
       "      <th>d3_gold</th>\n",
       "      <th>d3_lh</th>\n",
       "      <th>d3_xp</th>\n",
       "      <th>d3_health</th>\n",
       "      <th>d3_max_health</th>\n",
       "      <th>d3_max_mana</th>\n",
       "      <th>d3_level</th>\n",
       "      <th>d3_x</th>\n",
       "      <th>d3_y</th>\n",
       "      <th>d3_stuns</th>\n",
       "      <th>d3_creeps_stacked</th>\n",
       "      <th>d3_camps_stacked</th>\n",
       "      <th>d3_rune_pickups</th>\n",
       "      <th>d3_firstblood_claimed</th>\n",
       "      <th>d3_teamfight_participation</th>\n",
       "      <th>d3_towers_killed</th>\n",
       "      <th>d3_roshans_killed</th>\n",
       "      <th>d3_obs_placed</th>\n",
       "      <th>d3_sen_placed</th>\n",
       "      <th>d4_hero_id</th>\n",
       "      <th>d4_kills</th>\n",
       "      <th>d4_deaths</th>\n",
       "      <th>d4_assists</th>\n",
       "      <th>d4_denies</th>\n",
       "      <th>d4_gold</th>\n",
       "      <th>d4_lh</th>\n",
       "      <th>d4_xp</th>\n",
       "      <th>d4_health</th>\n",
       "      <th>d4_max_health</th>\n",
       "      <th>d4_max_mana</th>\n",
       "      <th>d4_level</th>\n",
       "      <th>d4_x</th>\n",
       "      <th>d4_y</th>\n",
       "      <th>d4_stuns</th>\n",
       "      <th>d4_creeps_stacked</th>\n",
       "      <th>d4_camps_stacked</th>\n",
       "      <th>d4_rune_pickups</th>\n",
       "      <th>d4_firstblood_claimed</th>\n",
       "      <th>d4_teamfight_participation</th>\n",
       "      <th>d4_towers_killed</th>\n",
       "      <th>d4_roshans_killed</th>\n",
       "      <th>d4_obs_placed</th>\n",
       "      <th>d4_sen_placed</th>\n",
       "      <th>d5_hero_id</th>\n",
       "      <th>d5_kills</th>\n",
       "      <th>d5_deaths</th>\n",
       "      <th>d5_assists</th>\n",
       "      <th>d5_denies</th>\n",
       "      <th>d5_gold</th>\n",
       "      <th>d5_lh</th>\n",
       "      <th>d5_xp</th>\n",
       "      <th>d5_health</th>\n",
       "      <th>d5_max_health</th>\n",
       "      <th>d5_max_mana</th>\n",
       "      <th>d5_level</th>\n",
       "      <th>d5_x</th>\n",
       "      <th>d5_y</th>\n",
       "      <th>d5_stuns</th>\n",
       "      <th>d5_creeps_stacked</th>\n",
       "      <th>d5_camps_stacked</th>\n",
       "      <th>d5_rune_pickups</th>\n",
       "      <th>d5_firstblood_claimed</th>\n",
       "      <th>d5_teamfight_participation</th>\n",
       "      <th>d5_towers_killed</th>\n",
       "      <th>d5_roshans_killed</th>\n",
       "      <th>d5_obs_placed</th>\n",
       "      <th>d5_sen_placed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>match_id_hash</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ee84861e709fc9cf5d48ba0f04b7f43b</th>\n",
       "      <td>1807</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>10093</td>\n",
       "      <td>39</td>\n",
       "      <td>9174</td>\n",
       "      <td>1340</td>\n",
       "      <td>1340</td>\n",
       "      <td>554.93805</td>\n",
       "      <td>14</td>\n",
       "      <td>150</td>\n",
       "      <td>110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>14134</td>\n",
       "      <td>133</td>\n",
       "      <td>12376</td>\n",
       "      <td>0</td>\n",
       "      <td>2155</td>\n",
       "      <td>837.93830</td>\n",
       "      <td>16</td>\n",
       "      <td>154</td>\n",
       "      <td>176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.317073</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>7846</td>\n",
       "      <td>17</td>\n",
       "      <td>8674</td>\n",
       "      <td>809</td>\n",
       "      <td>1240</td>\n",
       "      <td>1128.9386</td>\n",
       "      <td>13</td>\n",
       "      <td>70</td>\n",
       "      <td>74</td>\n",
       "      <td>45.296062</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>101</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>17765</td>\n",
       "      <td>80</td>\n",
       "      <td>20122</td>\n",
       "      <td>1700</td>\n",
       "      <td>1700</td>\n",
       "      <td>2148.93950</td>\n",
       "      <td>21</td>\n",
       "      <td>156</td>\n",
       "      <td>130</td>\n",
       "      <td>0.301084</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>36</td>\n",
       "      <td>19040</td>\n",
       "      <td>243</td>\n",
       "      <td>17067</td>\n",
       "      <td>1257</td>\n",
       "      <td>2705</td>\n",
       "      <td>1296.93870</td>\n",
       "      <td>20</td>\n",
       "      <td>130</td>\n",
       "      <td>156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>12182</td>\n",
       "      <td>137</td>\n",
       "      <td>15391</td>\n",
       "      <td>1996</td>\n",
       "      <td>2260</td>\n",
       "      <td>1828.93920</td>\n",
       "      <td>18</td>\n",
       "      <td>158</td>\n",
       "      <td>168</td>\n",
       "      <td>68.531250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>9914</td>\n",
       "      <td>134</td>\n",
       "      <td>14370</td>\n",
       "      <td>1960</td>\n",
       "      <td>1960</td>\n",
       "      <td>1248.93870</td>\n",
       "      <td>18</td>\n",
       "      <td>178</td>\n",
       "      <td>150</td>\n",
       "      <td>31.498530</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8039</td>\n",
       "      <td>109</td>\n",
       "      <td>7914</td>\n",
       "      <td>1123</td>\n",
       "      <td>1260</td>\n",
       "      <td>410.9379</td>\n",
       "      <td>13</td>\n",
       "      <td>158</td>\n",
       "      <td>166</td>\n",
       "      <td>2.499243</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>8977</td>\n",
       "      <td>31</td>\n",
       "      <td>12141</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>902.93835</td>\n",
       "      <td>16</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>92.217285</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>9169</td>\n",
       "      <td>73</td>\n",
       "      <td>11146</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>626.93810</td>\n",
       "      <td>15</td>\n",
       "      <td>158</td>\n",
       "      <td>168</td>\n",
       "      <td>12.174799</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a9475ee47c8a10d6cf37c1461814653e</th>\n",
       "      <td>2591</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>106</td>\n",
       "      <td>119</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>17261</td>\n",
       "      <td>55</td>\n",
       "      <td>27367</td>\n",
       "      <td>1283</td>\n",
       "      <td>1770</td>\n",
       "      <td>1860.93930</td>\n",
       "      <td>25</td>\n",
       "      <td>108</td>\n",
       "      <td>112</td>\n",
       "      <td>90.076220</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>23462</td>\n",
       "      <td>361</td>\n",
       "      <td>26912</td>\n",
       "      <td>714</td>\n",
       "      <td>2420</td>\n",
       "      <td>650.93810</td>\n",
       "      <td>25</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>4.047237</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>18954</td>\n",
       "      <td>257</td>\n",
       "      <td>22056</td>\n",
       "      <td>1973</td>\n",
       "      <td>2035</td>\n",
       "      <td>1305.9387</td>\n",
       "      <td>22</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>14366</td>\n",
       "      <td>170</td>\n",
       "      <td>20358</td>\n",
       "      <td>1895</td>\n",
       "      <td>1895</td>\n",
       "      <td>1651.93910</td>\n",
       "      <td>22</td>\n",
       "      <td>114</td>\n",
       "      <td>112</td>\n",
       "      <td>10.800685</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>13802</td>\n",
       "      <td>112</td>\n",
       "      <td>23291</td>\n",
       "      <td>1164</td>\n",
       "      <td>2160</td>\n",
       "      <td>1526.93900</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>110</td>\n",
       "      <td>27.565226</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>16950</td>\n",
       "      <td>43</td>\n",
       "      <td>27283</td>\n",
       "      <td>0</td>\n",
       "      <td>4800</td>\n",
       "      <td>1614.93910</td>\n",
       "      <td>25</td>\n",
       "      <td>152</td>\n",
       "      <td>84</td>\n",
       "      <td>64.296265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>18233</td>\n",
       "      <td>172</td>\n",
       "      <td>23674</td>\n",
       "      <td>1578</td>\n",
       "      <td>2480</td>\n",
       "      <td>950.93840</td>\n",
       "      <td>23</td>\n",
       "      <td>114</td>\n",
       "      <td>112</td>\n",
       "      <td>32.733032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>11525</td>\n",
       "      <td>58</td>\n",
       "      <td>16089</td>\n",
       "      <td>1675</td>\n",
       "      <td>1675</td>\n",
       "      <td>1755.9392</td>\n",
       "      <td>19</td>\n",
       "      <td>122</td>\n",
       "      <td>124</td>\n",
       "      <td>30.817260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.361702</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>20428</td>\n",
       "      <td>156</td>\n",
       "      <td>24126</td>\n",
       "      <td>2184</td>\n",
       "      <td>2940</td>\n",
       "      <td>686.93820</td>\n",
       "      <td>23</td>\n",
       "      <td>106</td>\n",
       "      <td>114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>22728</td>\n",
       "      <td>196</td>\n",
       "      <td>26945</td>\n",
       "      <td>2620</td>\n",
       "      <td>2620</td>\n",
       "      <td>2768.94020</td>\n",
       "      <td>25</td>\n",
       "      <td>120</td>\n",
       "      <td>122</td>\n",
       "      <td>31.994320</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b56ea18db1408fc68263757232c1facb</th>\n",
       "      <td>958</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5815</td>\n",
       "      <td>54</td>\n",
       "      <td>5680</td>\n",
       "      <td>1120</td>\n",
       "      <td>1120</td>\n",
       "      <td>854.93830</td>\n",
       "      <td>10</td>\n",
       "      <td>86</td>\n",
       "      <td>172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3905</td>\n",
       "      <td>23</td>\n",
       "      <td>2663</td>\n",
       "      <td>829</td>\n",
       "      <td>900</td>\n",
       "      <td>744.93823</td>\n",
       "      <td>6</td>\n",
       "      <td>104</td>\n",
       "      <td>168</td>\n",
       "      <td>39.490303</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>7283</td>\n",
       "      <td>104</td>\n",
       "      <td>7799</td>\n",
       "      <td>1300</td>\n",
       "      <td>1300</td>\n",
       "      <td>734.9382</td>\n",
       "      <td>13</td>\n",
       "      <td>112</td>\n",
       "      <td>102</td>\n",
       "      <td>9.997559</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3052</td>\n",
       "      <td>14</td>\n",
       "      <td>3264</td>\n",
       "      <td>131</td>\n",
       "      <td>1000</td>\n",
       "      <td>398.93787</td>\n",
       "      <td>7</td>\n",
       "      <td>174</td>\n",
       "      <td>102</td>\n",
       "      <td>21.628084</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>5767</td>\n",
       "      <td>80</td>\n",
       "      <td>6573</td>\n",
       "      <td>1180</td>\n",
       "      <td>1180</td>\n",
       "      <td>602.93805</td>\n",
       "      <td>11</td>\n",
       "      <td>84</td>\n",
       "      <td>174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>5595</td>\n",
       "      <td>57</td>\n",
       "      <td>6236</td>\n",
       "      <td>930</td>\n",
       "      <td>1060</td>\n",
       "      <td>518.93800</td>\n",
       "      <td>11</td>\n",
       "      <td>180</td>\n",
       "      <td>106</td>\n",
       "      <td>0.132027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3143</td>\n",
       "      <td>11</td>\n",
       "      <td>3268</td>\n",
       "      <td>1100</td>\n",
       "      <td>1100</td>\n",
       "      <td>458.93793</td>\n",
       "      <td>7</td>\n",
       "      <td>104</td>\n",
       "      <td>164</td>\n",
       "      <td>9.231054</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5499</td>\n",
       "      <td>62</td>\n",
       "      <td>6139</td>\n",
       "      <td>1200</td>\n",
       "      <td>1200</td>\n",
       "      <td>1020.9385</td>\n",
       "      <td>11</td>\n",
       "      <td>112</td>\n",
       "      <td>166</td>\n",
       "      <td>1.949498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6543</td>\n",
       "      <td>111</td>\n",
       "      <td>6376</td>\n",
       "      <td>1178</td>\n",
       "      <td>1180</td>\n",
       "      <td>554.93805</td>\n",
       "      <td>11</td>\n",
       "      <td>122</td>\n",
       "      <td>146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3488</td>\n",
       "      <td>20</td>\n",
       "      <td>4560</td>\n",
       "      <td>968</td>\n",
       "      <td>1020</td>\n",
       "      <td>602.93805</td>\n",
       "      <td>9</td>\n",
       "      <td>102</td>\n",
       "      <td>170</td>\n",
       "      <td>20.528862</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9587640246910f0e1b033a6c8f6d8211</th>\n",
       "      <td>2092</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>14347</td>\n",
       "      <td>123</td>\n",
       "      <td>18693</td>\n",
       "      <td>1351</td>\n",
       "      <td>1650</td>\n",
       "      <td>614.93810</td>\n",
       "      <td>21</td>\n",
       "      <td>112</td>\n",
       "      <td>104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9788</td>\n",
       "      <td>52</td>\n",
       "      <td>14005</td>\n",
       "      <td>2060</td>\n",
       "      <td>2060</td>\n",
       "      <td>578.93805</td>\n",
       "      <td>17</td>\n",
       "      <td>102</td>\n",
       "      <td>114</td>\n",
       "      <td>31.913910</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>15988</td>\n",
       "      <td>145</td>\n",
       "      <td>18528</td>\n",
       "      <td>1960</td>\n",
       "      <td>1960</td>\n",
       "      <td>842.9383</td>\n",
       "      <td>21</td>\n",
       "      <td>106</td>\n",
       "      <td>104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>14432</td>\n",
       "      <td>120</td>\n",
       "      <td>16664</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>662.93810</td>\n",
       "      <td>19</td>\n",
       "      <td>104</td>\n",
       "      <td>112</td>\n",
       "      <td>45.303608</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>16860</td>\n",
       "      <td>171</td>\n",
       "      <td>19033</td>\n",
       "      <td>1089</td>\n",
       "      <td>2010</td>\n",
       "      <td>770.93823</td>\n",
       "      <td>21</td>\n",
       "      <td>106</td>\n",
       "      <td>108</td>\n",
       "      <td>3.310254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7598</td>\n",
       "      <td>15</td>\n",
       "      <td>11233</td>\n",
       "      <td>0</td>\n",
       "      <td>1220</td>\n",
       "      <td>794.93823</td>\n",
       "      <td>15</td>\n",
       "      <td>108</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>16598</td>\n",
       "      <td>177</td>\n",
       "      <td>19945</td>\n",
       "      <td>2460</td>\n",
       "      <td>2460</td>\n",
       "      <td>878.93835</td>\n",
       "      <td>21</td>\n",
       "      <td>182</td>\n",
       "      <td>176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>13593</td>\n",
       "      <td>84</td>\n",
       "      <td>16954</td>\n",
       "      <td>0</td>\n",
       "      <td>1720</td>\n",
       "      <td>2088.9395</td>\n",
       "      <td>20</td>\n",
       "      <td>98</td>\n",
       "      <td>96</td>\n",
       "      <td>2.032837</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>9765</td>\n",
       "      <td>41</td>\n",
       "      <td>13426</td>\n",
       "      <td>2240</td>\n",
       "      <td>2240</td>\n",
       "      <td>936.93840</td>\n",
       "      <td>17</td>\n",
       "      <td>104</td>\n",
       "      <td>120</td>\n",
       "      <td>20.910597</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>114</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>14028</td>\n",
       "      <td>116</td>\n",
       "      <td>14056</td>\n",
       "      <td>0</td>\n",
       "      <td>2100</td>\n",
       "      <td>794.93823</td>\n",
       "      <td>18</td>\n",
       "      <td>112</td>\n",
       "      <td>104</td>\n",
       "      <td>27.558594</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3eb93fbd9056ebdb52ffff84e6c3664a</th>\n",
       "      <td>554</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>2873</td>\n",
       "      <td>42</td>\n",
       "      <td>2341</td>\n",
       "      <td>589</td>\n",
       "      <td>880</td>\n",
       "      <td>314.93780</td>\n",
       "      <td>6</td>\n",
       "      <td>174</td>\n",
       "      <td>86</td>\n",
       "      <td>1.566286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>15</td>\n",
       "      <td>2248</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>350.93784</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>160</td>\n",
       "      <td>0.566554</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1573</td>\n",
       "      <td>2</td>\n",
       "      <td>1696</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>720.9382</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>84</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2161</td>\n",
       "      <td>28</td>\n",
       "      <td>3072</td>\n",
       "      <td>860</td>\n",
       "      <td>860</td>\n",
       "      <td>770.93823</td>\n",
       "      <td>7</td>\n",
       "      <td>144</td>\n",
       "      <td>108</td>\n",
       "      <td>3.865735</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1611</td>\n",
       "      <td>4</td>\n",
       "      <td>1429</td>\n",
       "      <td>860</td>\n",
       "      <td>860</td>\n",
       "      <td>338.93784</td>\n",
       "      <td>4</td>\n",
       "      <td>138</td>\n",
       "      <td>98</td>\n",
       "      <td>3.265857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1905</td>\n",
       "      <td>23</td>\n",
       "      <td>2126</td>\n",
       "      <td>940</td>\n",
       "      <td>940</td>\n",
       "      <td>410.93790</td>\n",
       "      <td>5</td>\n",
       "      <td>178</td>\n",
       "      <td>120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>3181</td>\n",
       "      <td>51</td>\n",
       "      <td>3913</td>\n",
       "      <td>1160</td>\n",
       "      <td>1160</td>\n",
       "      <td>422.93790</td>\n",
       "      <td>8</td>\n",
       "      <td>86</td>\n",
       "      <td>170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1604</td>\n",
       "      <td>5</td>\n",
       "      <td>1836</td>\n",
       "      <td>720</td>\n",
       "      <td>720</td>\n",
       "      <td>708.9382</td>\n",
       "      <td>5</td>\n",
       "      <td>180</td>\n",
       "      <td>126</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2904</td>\n",
       "      <td>38</td>\n",
       "      <td>4134</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>710.93820</td>\n",
       "      <td>8</td>\n",
       "      <td>118</td>\n",
       "      <td>122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2069</td>\n",
       "      <td>5</td>\n",
       "      <td>1346</td>\n",
       "      <td>700</td>\n",
       "      <td>700</td>\n",
       "      <td>446.93793</td>\n",
       "      <td>4</td>\n",
       "      <td>86</td>\n",
       "      <td>160</td>\n",
       "      <td>11.663805</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  game_time  game_mode  lobby_type  \\\n",
       "match_id_hash                                                        \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b       1807         22           7   \n",
       "a9475ee47c8a10d6cf37c1461814653e       2591         22           7   \n",
       "b56ea18db1408fc68263757232c1facb        958         22           7   \n",
       "9587640246910f0e1b033a6c8f6d8211       2092          4           0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a        554         22           7   \n",
       "\n",
       "                                  objectives_len  chat_len  r1_hero_id  \\\n",
       "match_id_hash                                                            \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b              17        12          32   \n",
       "a9475ee47c8a10d6cf37c1461814653e              13       106         119   \n",
       "b56ea18db1408fc68263757232c1facb               4         0          53   \n",
       "9587640246910f0e1b033a6c8f6d8211              14         2          44   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a               1         0          95   \n",
       "\n",
       "                                  r1_kills  r1_deaths  r1_assists  r1_denies  \\\n",
       "match_id_hash                                                                  \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b         2          5          14          0   \n",
       "a9475ee47c8a10d6cf37c1461814653e        17          9          16          4   \n",
       "b56ea18db1408fc68263757232c1facb         5          2           3         10   \n",
       "9587640246910f0e1b033a6c8f6d8211         8          8           8         10   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a         0          0           3         17   \n",
       "\n",
       "                                  r1_gold  r1_lh  r1_xp  r1_health  \\\n",
       "match_id_hash                                                        \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b    10093     39   9174       1340   \n",
       "a9475ee47c8a10d6cf37c1461814653e    17261     55  27367       1283   \n",
       "b56ea18db1408fc68263757232c1facb     5815     54   5680       1120   \n",
       "9587640246910f0e1b033a6c8f6d8211    14347    123  18693       1351   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a     2873     42   2341        589   \n",
       "\n",
       "                                  r1_max_health  r1_max_mana  r1_level  r1_x  \\\n",
       "match_id_hash                                                                  \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b           1340    554.93805        14   150   \n",
       "a9475ee47c8a10d6cf37c1461814653e           1770   1860.93930        25   108   \n",
       "b56ea18db1408fc68263757232c1facb           1120    854.93830        10    86   \n",
       "9587640246910f0e1b033a6c8f6d8211           1650    614.93810        21   112   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a            880    314.93780         6   174   \n",
       "\n",
       "                                  r1_y   r1_stuns  r1_creeps_stacked  \\\n",
       "match_id_hash                                                          \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b   110   0.000000                  0   \n",
       "a9475ee47c8a10d6cf37c1461814653e   112  90.076220                  0   \n",
       "b56ea18db1408fc68263757232c1facb   172   0.000000                  0   \n",
       "9587640246910f0e1b033a6c8f6d8211   104   0.000000                  0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a    86   1.566286                  0   \n",
       "\n",
       "                                  r1_camps_stacked  r1_rune_pickups  \\\n",
       "match_id_hash                                                         \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                 0               11   \n",
       "a9475ee47c8a10d6cf37c1461814653e                 0                6   \n",
       "b56ea18db1408fc68263757232c1facb                 0                2   \n",
       "9587640246910f0e1b033a6c8f6d8211                 0                6   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                 0                1   \n",
       "\n",
       "                                  r1_firstblood_claimed  \\\n",
       "match_id_hash                                             \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                      0   \n",
       "a9475ee47c8a10d6cf37c1461814653e                      0   \n",
       "b56ea18db1408fc68263757232c1facb                      1   \n",
       "9587640246910f0e1b033a6c8f6d8211                      0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                      0   \n",
       "\n",
       "                                  r1_teamfight_participation  \\\n",
       "match_id_hash                                                  \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                    0.390244   \n",
       "a9475ee47c8a10d6cf37c1461814653e                    0.785714   \n",
       "b56ea18db1408fc68263757232c1facb                    0.727273   \n",
       "9587640246910f0e1b033a6c8f6d8211                    0.516129   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                    1.000000   \n",
       "\n",
       "                                  r1_towers_killed  r1_roshans_killed  \\\n",
       "match_id_hash                                                           \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                 0                  0   \n",
       "a9475ee47c8a10d6cf37c1461814653e                 0                  0   \n",
       "b56ea18db1408fc68263757232c1facb                 1                  0   \n",
       "9587640246910f0e1b033a6c8f6d8211                 1                  0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                 0                  0   \n",
       "\n",
       "                                  r1_obs_placed  r1_sen_placed  r2_hero_id  \\\n",
       "match_id_hash                                                                \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b              0              1          15   \n",
       "a9475ee47c8a10d6cf37c1461814653e              0              0          44   \n",
       "b56ea18db1408fc68263757232c1facb              1              0           3   \n",
       "9587640246910f0e1b033a6c8f6d8211              1              0          49   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a              0              0          69   \n",
       "\n",
       "                                  r2_kills  r2_deaths  r2_assists  r2_denies  \\\n",
       "match_id_hash                                                                  \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b         7          7           6         14   \n",
       "a9475ee47c8a10d6cf37c1461814653e        11          7           6         12   \n",
       "b56ea18db1408fc68263757232c1facb         3          1           1          3   \n",
       "9587640246910f0e1b033a6c8f6d8211         2         11           9          0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a         0          1           0          0   \n",
       "\n",
       "                                  r2_gold  r2_lh  r2_xp  r2_health  \\\n",
       "match_id_hash                                                        \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b    14134    133  12376          0   \n",
       "a9475ee47c8a10d6cf37c1461814653e    23462    361  26912        714   \n",
       "b56ea18db1408fc68263757232c1facb     3905     23   2663        829   \n",
       "9587640246910f0e1b033a6c8f6d8211     9788     52  14005       2060   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a     2011     15   2248       1000   \n",
       "\n",
       "                                  r2_max_health  r2_max_mana  r2_level  r2_x  \\\n",
       "match_id_hash                                                                  \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b           2155    837.93830        16   154   \n",
       "a9475ee47c8a10d6cf37c1461814653e           2420    650.93810        25    80   \n",
       "b56ea18db1408fc68263757232c1facb            900    744.93823         6   104   \n",
       "9587640246910f0e1b033a6c8f6d8211           2060    578.93805        17   102   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a           1000    350.93784         5    76   \n",
       "\n",
       "                                  r2_y   r2_stuns  r2_creeps_stacked  \\\n",
       "match_id_hash                                                          \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b   176   0.000000                  1   \n",
       "a9475ee47c8a10d6cf37c1461814653e    82   4.047237                  3   \n",
       "b56ea18db1408fc68263757232c1facb   168  39.490303                  0   \n",
       "9587640246910f0e1b033a6c8f6d8211   114  31.913910                  0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a   160   0.566554                  0   \n",
       "\n",
       "                                  r2_camps_stacked  r2_rune_pickups  \\\n",
       "match_id_hash                                                         \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                 1               10   \n",
       "a9475ee47c8a10d6cf37c1461814653e                 1                5   \n",
       "b56ea18db1408fc68263757232c1facb                 0                6   \n",
       "9587640246910f0e1b033a6c8f6d8211                 0                3   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                 0                5   \n",
       "\n",
       "                                  r2_firstblood_claimed  \\\n",
       "match_id_hash                                             \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                      0   \n",
       "a9475ee47c8a10d6cf37c1461814653e                      0   \n",
       "b56ea18db1408fc68263757232c1facb                      0   \n",
       "9587640246910f0e1b033a6c8f6d8211                      0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                      0   \n",
       "\n",
       "                                  r2_teamfight_participation  \\\n",
       "match_id_hash                                                  \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                    0.317073   \n",
       "a9475ee47c8a10d6cf37c1461814653e                    0.404762   \n",
       "b56ea18db1408fc68263757232c1facb                    0.363636   \n",
       "9587640246910f0e1b033a6c8f6d8211                    0.354839   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                    0.000000   \n",
       "\n",
       "                                  r2_towers_killed  r2_roshans_killed  \\\n",
       "match_id_hash                                                           \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                 2                  0   \n",
       "a9475ee47c8a10d6cf37c1461814653e                 0                  0   \n",
       "b56ea18db1408fc68263757232c1facb                 0                  0   \n",
       "9587640246910f0e1b033a6c8f6d8211                 0                  0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                 0                  0   \n",
       "\n",
       "                                  r2_obs_placed  r2_sen_placed  r3_hero_id  \\\n",
       "match_id_hash                                                                \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b              1              0          86   \n",
       "a9475ee47c8a10d6cf37c1461814653e              0              0          34   \n",
       "b56ea18db1408fc68263757232c1facb              6              1          72   \n",
       "9587640246910f0e1b033a6c8f6d8211              0              0           6   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a              1              1          87   \n",
       "\n",
       "                                  r3_kills  r3_deaths  r3_assists  r3_denies  \\\n",
       "match_id_hash                                                                  \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b         4          5          13          3   \n",
       "a9475ee47c8a10d6cf37c1461814653e         6         13          21          9   \n",
       "b56ea18db1408fc68263757232c1facb         2          2           2         21   \n",
       "9587640246910f0e1b033a6c8f6d8211         8          7          13          8   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a         2          0           1          5   \n",
       "\n",
       "                                  r3_gold  r3_lh  r3_xp  r3_health  \\\n",
       "match_id_hash                                                        \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b     7846     17   8674        809   \n",
       "a9475ee47c8a10d6cf37c1461814653e    18954    257  22056       1973   \n",
       "b56ea18db1408fc68263757232c1facb     7283    104   7799       1300   \n",
       "9587640246910f0e1b033a6c8f6d8211    15988    145  18528       1960   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a     1573      2   1696        760   \n",
       "\n",
       "                                  r3_max_health  r3_max_mana  r3_level  r3_x  \\\n",
       "match_id_hash                                                                  \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b           1240    1128.9386        13    70   \n",
       "a9475ee47c8a10d6cf37c1461814653e           2035    1305.9387        22   104   \n",
       "b56ea18db1408fc68263757232c1facb           1300     734.9382        13   112   \n",
       "9587640246910f0e1b033a6c8f6d8211           1960     842.9383        21   106   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a            760     720.9382         5   172   \n",
       "\n",
       "                                  r3_y   r3_stuns  r3_creeps_stacked  \\\n",
       "match_id_hash                                                          \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b    74  45.296062                  0   \n",
       "a9475ee47c8a10d6cf37c1461814653e   104   0.000000                  0   \n",
       "b56ea18db1408fc68263757232c1facb   102   9.997559                  2   \n",
       "9587640246910f0e1b033a6c8f6d8211   104   0.000000                  0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a    84   0.000000                  0   \n",
       "\n",
       "                                  r3_camps_stacked  r3_rune_pickups  \\\n",
       "match_id_hash                                                         \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                 0                6   \n",
       "a9475ee47c8a10d6cf37c1461814653e                 0                3   \n",
       "b56ea18db1408fc68263757232c1facb                 1                6   \n",
       "9587640246910f0e1b033a6c8f6d8211                 0                5   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                 0                1   \n",
       "\n",
       "                                  r3_firstblood_claimed  \\\n",
       "match_id_hash                                             \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                      0   \n",
       "a9475ee47c8a10d6cf37c1461814653e                      0   \n",
       "b56ea18db1408fc68263757232c1facb                      0   \n",
       "9587640246910f0e1b033a6c8f6d8211                      1   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                      1   \n",
       "\n",
       "                                  r3_teamfight_participation  \\\n",
       "match_id_hash                                                  \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                    0.414634   \n",
       "a9475ee47c8a10d6cf37c1461814653e                    0.642857   \n",
       "b56ea18db1408fc68263757232c1facb                    0.363636   \n",
       "9587640246910f0e1b033a6c8f6d8211                    0.677419   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                    1.000000   \n",
       "\n",
       "                                  r3_towers_killed  r3_roshans_killed  \\\n",
       "match_id_hash                                                           \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                 0                  0   \n",
       "a9475ee47c8a10d6cf37c1461814653e                 0                  0   \n",
       "b56ea18db1408fc68263757232c1facb                 0                  0   \n",
       "9587640246910f0e1b033a6c8f6d8211                 2                  0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                 0                  0   \n",
       "\n",
       "                                  r3_obs_placed  r3_sen_placed  r4_hero_id  \\\n",
       "match_id_hash                                                                \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b             11              8         101   \n",
       "a9475ee47c8a10d6cf37c1461814653e              3              1          36   \n",
       "b56ea18db1408fc68263757232c1facb              0              0          16   \n",
       "9587640246910f0e1b033a6c8f6d8211              0              0          18   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a              1              0          25   \n",
       "\n",
       "                                  r4_kills  r4_deaths  r4_assists  r4_denies  \\\n",
       "match_id_hash                                                                  \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b        22          2           7          1   \n",
       "a9475ee47c8a10d6cf37c1461814653e         3         11          11          5   \n",
       "b56ea18db1408fc68263757232c1facb         0          3           5          1   \n",
       "9587640246910f0e1b033a6c8f6d8211         8          6          13          5   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a         0          1           0          8   \n",
       "\n",
       "                                  r4_gold  r4_lh  r4_xp  r4_health  \\\n",
       "match_id_hash                                                        \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b    17765     80  20122       1700   \n",
       "a9475ee47c8a10d6cf37c1461814653e    14366    170  20358       1895   \n",
       "b56ea18db1408fc68263757232c1facb     3052     14   3264        131   \n",
       "9587640246910f0e1b033a6c8f6d8211    14432    120  16664       2500   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a     2161     28   3072        860   \n",
       "\n",
       "                                  r4_max_health  r4_max_mana  r4_level  r4_x  \\\n",
       "match_id_hash                                                                  \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b           1700   2148.93950        21   156   \n",
       "a9475ee47c8a10d6cf37c1461814653e           1895   1651.93910        22   114   \n",
       "b56ea18db1408fc68263757232c1facb           1000    398.93787         7   174   \n",
       "9587640246910f0e1b033a6c8f6d8211           2500    662.93810        19   104   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a            860    770.93823         7   144   \n",
       "\n",
       "                                  r4_y   r4_stuns  r4_creeps_stacked  \\\n",
       "match_id_hash                                                          \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b   130   0.301084                  0   \n",
       "a9475ee47c8a10d6cf37c1461814653e   112  10.800685                  3   \n",
       "b56ea18db1408fc68263757232c1facb   102  21.628084                  0   \n",
       "9587640246910f0e1b033a6c8f6d8211   112  45.303608                  0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a   108   3.865735                  0   \n",
       "\n",
       "                                  r4_camps_stacked  r4_rune_pickups  \\\n",
       "match_id_hash                                                         \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                 0               32   \n",
       "a9475ee47c8a10d6cf37c1461814653e                 1                7   \n",
       "b56ea18db1408fc68263757232c1facb                 0                5   \n",
       "9587640246910f0e1b033a6c8f6d8211                 0               11   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                 0                1   \n",
       "\n",
       "                                  r4_firstblood_claimed  \\\n",
       "match_id_hash                                             \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                      0   \n",
       "a9475ee47c8a10d6cf37c1461814653e                      0   \n",
       "b56ea18db1408fc68263757232c1facb                      0   \n",
       "9587640246910f0e1b033a6c8f6d8211                      0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                      0   \n",
       "\n",
       "                                  r4_teamfight_participation  \\\n",
       "match_id_hash                                                  \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                    0.707317   \n",
       "a9475ee47c8a10d6cf37c1461814653e                    0.333333   \n",
       "b56ea18db1408fc68263757232c1facb                    0.454545   \n",
       "9587640246910f0e1b033a6c8f6d8211                    0.677419   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                    0.000000   \n",
       "\n",
       "                                  r4_towers_killed  r4_roshans_killed  \\\n",
       "match_id_hash                                                           \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                 0                  0   \n",
       "a9475ee47c8a10d6cf37c1461814653e                 0                  0   \n",
       "b56ea18db1408fc68263757232c1facb                 0                  0   \n",
       "9587640246910f0e1b033a6c8f6d8211                 1                  0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                 0                  0   \n",
       "\n",
       "                                  r4_obs_placed  r4_sen_placed  r5_hero_id  \\\n",
       "match_id_hash                                                                \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b              0              0         109   \n",
       "a9475ee47c8a10d6cf37c1461814653e              2              0          92   \n",
       "b56ea18db1408fc68263757232c1facb              0              0          47   \n",
       "9587640246910f0e1b033a6c8f6d8211              0              0           1   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a              0              1          23   \n",
       "\n",
       "                                  r5_kills  r5_deaths  r5_assists  r5_denies  \\\n",
       "match_id_hash                                                                  \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b         6          1           6         36   \n",
       "a9475ee47c8a10d6cf37c1461814653e         4          7          12          8   \n",
       "b56ea18db1408fc68263757232c1facb         1          2           2         15   \n",
       "9587640246910f0e1b033a6c8f6d8211         2          3           9          0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a         1          1           2          1   \n",
       "\n",
       "                                  r5_gold  r5_lh  r5_xp  r5_health  \\\n",
       "match_id_hash                                                        \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b    19040    243  17067       1257   \n",
       "a9475ee47c8a10d6cf37c1461814653e    13802    112  23291       1164   \n",
       "b56ea18db1408fc68263757232c1facb     5767     80   6573       1180   \n",
       "9587640246910f0e1b033a6c8f6d8211    16860    171  19033       1089   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a     1611      4   1429        860   \n",
       "\n",
       "                                  r5_max_health  r5_max_mana  r5_level  r5_x  \\\n",
       "match_id_hash                                                                  \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b           2705   1296.93870        20   130   \n",
       "a9475ee47c8a10d6cf37c1461814653e           2160   1526.93900        23   112   \n",
       "b56ea18db1408fc68263757232c1facb           1180    602.93805        11    84   \n",
       "9587640246910f0e1b033a6c8f6d8211           2010    770.93823        21   106   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a            860    338.93784         4   138   \n",
       "\n",
       "                                  r5_y   r5_stuns  r5_creeps_stacked  \\\n",
       "match_id_hash                                                          \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b   156   0.000000                  8   \n",
       "a9475ee47c8a10d6cf37c1461814653e   110  27.565226                  4   \n",
       "b56ea18db1408fc68263757232c1facb   174   0.000000                  0   \n",
       "9587640246910f0e1b033a6c8f6d8211   108   3.310254                  0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a    98   3.265857                  0   \n",
       "\n",
       "                                  r5_camps_stacked  r5_rune_pickups  \\\n",
       "match_id_hash                                                         \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                 4                9   \n",
       "a9475ee47c8a10d6cf37c1461814653e                 1               11   \n",
       "b56ea18db1408fc68263757232c1facb                 0                2   \n",
       "9587640246910f0e1b033a6c8f6d8211                 0               21   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                 0                4   \n",
       "\n",
       "                                  r5_firstblood_claimed  \\\n",
       "match_id_hash                                             \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                      0   \n",
       "a9475ee47c8a10d6cf37c1461814653e                      0   \n",
       "b56ea18db1408fc68263757232c1facb                      0   \n",
       "9587640246910f0e1b033a6c8f6d8211                      0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                      0   \n",
       "\n",
       "                                  r5_teamfight_participation  \\\n",
       "match_id_hash                                                  \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                    0.292683   \n",
       "a9475ee47c8a10d6cf37c1461814653e                    0.380952   \n",
       "b56ea18db1408fc68263757232c1facb                    0.272727   \n",
       "9587640246910f0e1b033a6c8f6d8211                    0.354839   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                    1.000000   \n",
       "\n",
       "                                  r5_towers_killed  r5_roshans_killed  \\\n",
       "match_id_hash                                                           \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                 3                  1   \n",
       "a9475ee47c8a10d6cf37c1461814653e                 0                  0   \n",
       "b56ea18db1408fc68263757232c1facb                 0                  0   \n",
       "9587640246910f0e1b033a6c8f6d8211                 2                  0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                 0                  0   \n",
       "\n",
       "                                  r5_obs_placed  r5_sen_placed  d1_hero_id  \\\n",
       "match_id_hash                                                                \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b              0              0          76   \n",
       "a9475ee47c8a10d6cf37c1461814653e              4              6          14   \n",
       "b56ea18db1408fc68263757232c1facb              0              0         120   \n",
       "9587640246910f0e1b033a6c8f6d8211              0              0          91   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a              0              1         104   \n",
       "\n",
       "                                  d1_kills  d1_deaths  d1_assists  d1_denies  \\\n",
       "match_id_hash                                                                  \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b         5          8           2          8   \n",
       "a9475ee47c8a10d6cf37c1461814653e        11          9          22          0   \n",
       "b56ea18db1408fc68263757232c1facb         3          2           3         12   \n",
       "9587640246910f0e1b033a6c8f6d8211         0          4          11          3   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a         0          3           0          4   \n",
       "\n",
       "                                  d1_gold  d1_lh  d1_xp  d1_health  \\\n",
       "match_id_hash                                                        \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b    12182    137  15391       1996   \n",
       "a9475ee47c8a10d6cf37c1461814653e    16950     43  27283          0   \n",
       "b56ea18db1408fc68263757232c1facb     5595     57   6236        930   \n",
       "9587640246910f0e1b033a6c8f6d8211     7598     15  11233          0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a     1905     23   2126        940   \n",
       "\n",
       "                                  d1_max_health  d1_max_mana  d1_level  d1_x  \\\n",
       "match_id_hash                                                                  \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b           2260   1828.93920        18   158   \n",
       "a9475ee47c8a10d6cf37c1461814653e           4800   1614.93910        25   152   \n",
       "b56ea18db1408fc68263757232c1facb           1060    518.93800        11   180   \n",
       "9587640246910f0e1b033a6c8f6d8211           1220    794.93823        15   108   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a            940    410.93790         5   178   \n",
       "\n",
       "                                  d1_y   d1_stuns  d1_creeps_stacked  \\\n",
       "match_id_hash                                                          \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b   168  68.531250                  0   \n",
       "a9475ee47c8a10d6cf37c1461814653e    84  64.296265                  0   \n",
       "b56ea18db1408fc68263757232c1facb   106   0.132027                  0   \n",
       "9587640246910f0e1b033a6c8f6d8211   100   0.000000                  0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a   120   0.000000                  0   \n",
       "\n",
       "                                  d1_camps_stacked  d1_rune_pickups  \\\n",
       "match_id_hash                                                         \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                 0                1   \n",
       "a9475ee47c8a10d6cf37c1461814653e                 0               17   \n",
       "b56ea18db1408fc68263757232c1facb                 0                5   \n",
       "9587640246910f0e1b033a6c8f6d8211                 0               11   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                 0                1   \n",
       "\n",
       "                                  d1_firstblood_claimed  \\\n",
       "match_id_hash                                             \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                      0   \n",
       "a9475ee47c8a10d6cf37c1461814653e                      1   \n",
       "b56ea18db1408fc68263757232c1facb                      0   \n",
       "9587640246910f0e1b033a6c8f6d8211                      0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                      0   \n",
       "\n",
       "                                  d1_teamfight_participation  \\\n",
       "match_id_hash                                                  \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                    0.350000   \n",
       "a9475ee47c8a10d6cf37c1461814653e                    0.702128   \n",
       "b56ea18db1408fc68263757232c1facb                    0.600000   \n",
       "9587640246910f0e1b033a6c8f6d8211                    0.314286   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                    0.000000   \n",
       "\n",
       "                                  d1_towers_killed  d1_roshans_killed  \\\n",
       "match_id_hash                                                           \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                 0                  0   \n",
       "a9475ee47c8a10d6cf37c1461814653e                 0                  0   \n",
       "b56ea18db1408fc68263757232c1facb                 0                  0   \n",
       "9587640246910f0e1b033a6c8f6d8211                 0                  0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                 0                  0   \n",
       "\n",
       "                                  d1_obs_placed  d1_sen_placed  d2_hero_id  \\\n",
       "match_id_hash                                                                \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b              0              1         108   \n",
       "a9475ee47c8a10d6cf37c1461814653e             11              0          28   \n",
       "b56ea18db1408fc68263757232c1facb              1              0         100   \n",
       "9587640246910f0e1b033a6c8f6d8211              0              0           4   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a              1              0          54   \n",
       "\n",
       "                                  d2_kills  d2_deaths  d2_assists  d2_denies  \\\n",
       "match_id_hash                                                                  \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b         0          9           8          4   \n",
       "a9475ee47c8a10d6cf37c1461814653e        10          8           6         21   \n",
       "b56ea18db1408fc68263757232c1facb         1          4           4          1   \n",
       "9587640246910f0e1b033a6c8f6d8211        12          8           9         19   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a         0          0           0         26   \n",
       "\n",
       "                                  d2_gold  d2_lh  d2_xp  d2_health  \\\n",
       "match_id_hash                                                        \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b     9914    134  14370       1960   \n",
       "a9475ee47c8a10d6cf37c1461814653e    18233    172  23674       1578   \n",
       "b56ea18db1408fc68263757232c1facb     3143     11   3268       1100   \n",
       "9587640246910f0e1b033a6c8f6d8211    16598    177  19945       2460   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a     3181     51   3913       1160   \n",
       "\n",
       "                                  d2_max_health  d2_max_mana  d2_level  d2_x  \\\n",
       "match_id_hash                                                                  \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b           1960   1248.93870        18   178   \n",
       "a9475ee47c8a10d6cf37c1461814653e           2480    950.93840        23   114   \n",
       "b56ea18db1408fc68263757232c1facb           1100    458.93793         7   104   \n",
       "9587640246910f0e1b033a6c8f6d8211           2460    878.93835        21   182   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a           1160    422.93790         8    86   \n",
       "\n",
       "                                  d2_y   d2_stuns  d2_creeps_stacked  \\\n",
       "match_id_hash                                                          \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b   150  31.498530                  0   \n",
       "a9475ee47c8a10d6cf37c1461814653e   112  32.733032                  0   \n",
       "b56ea18db1408fc68263757232c1facb   164   9.231054                  0   \n",
       "9587640246910f0e1b033a6c8f6d8211   176   0.000000                  0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a   170   0.000000                  0   \n",
       "\n",
       "                                  d2_camps_stacked  d2_rune_pickups  \\\n",
       "match_id_hash                                                         \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                 0                1   \n",
       "a9475ee47c8a10d6cf37c1461814653e                 0               11   \n",
       "b56ea18db1408fc68263757232c1facb                 0                2   \n",
       "9587640246910f0e1b033a6c8f6d8211                 0                2   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                 0                0   \n",
       "\n",
       "                                  d2_firstblood_claimed  \\\n",
       "match_id_hash                                             \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                      0   \n",
       "a9475ee47c8a10d6cf37c1461814653e                      0   \n",
       "b56ea18db1408fc68263757232c1facb                      0   \n",
       "9587640246910f0e1b033a6c8f6d8211                      0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                      0   \n",
       "\n",
       "                                  d2_teamfight_participation  \\\n",
       "match_id_hash                                                  \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                    0.400000   \n",
       "a9475ee47c8a10d6cf37c1461814653e                    0.340426   \n",
       "b56ea18db1408fc68263757232c1facb                    0.500000   \n",
       "9587640246910f0e1b033a6c8f6d8211                    0.600000   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                    0.000000   \n",
       "\n",
       "                                  d2_towers_killed  d2_roshans_killed  \\\n",
       "match_id_hash                                                           \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                 1                  0   \n",
       "a9475ee47c8a10d6cf37c1461814653e                 0                  1   \n",
       "b56ea18db1408fc68263757232c1facb                 0                  0   \n",
       "9587640246910f0e1b033a6c8f6d8211                 0                  0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                 0                  0   \n",
       "\n",
       "                                  d2_obs_placed  d2_sen_placed  d3_hero_id  \\\n",
       "match_id_hash                                                                \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b              1              0          95   \n",
       "a9475ee47c8a10d6cf37c1461814653e              0              0          30   \n",
       "b56ea18db1408fc68263757232c1facb              0              0          22   \n",
       "9587640246910f0e1b033a6c8f6d8211              0              0         101   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a              0              0          31   \n",
       "\n",
       "                                  d3_kills  d3_deaths  d3_assists  d3_denies  \\\n",
       "match_id_hash                                                                  \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b         2          9           4          0   \n",
       "a9475ee47c8a10d6cf37c1461814653e         3          5          14          0   \n",
       "b56ea18db1408fc68263757232c1facb         2          1           6          1   \n",
       "9587640246910f0e1b033a6c8f6d8211        13          8           8         17   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a         1          0           0          1   \n",
       "\n",
       "                                  d3_gold  d3_lh  d3_xp  d3_health  \\\n",
       "match_id_hash                                                        \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b     8039    109   7914       1123   \n",
       "a9475ee47c8a10d6cf37c1461814653e    11525     58  16089       1675   \n",
       "b56ea18db1408fc68263757232c1facb     5499     62   6139       1200   \n",
       "9587640246910f0e1b033a6c8f6d8211    13593     84  16954          0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a     1604      5   1836        720   \n",
       "\n",
       "                                  d3_max_health  d3_max_mana  d3_level  d3_x  \\\n",
       "match_id_hash                                                                  \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b           1260     410.9379        13   158   \n",
       "a9475ee47c8a10d6cf37c1461814653e           1675    1755.9392        19   122   \n",
       "b56ea18db1408fc68263757232c1facb           1200    1020.9385        11   112   \n",
       "9587640246910f0e1b033a6c8f6d8211           1720    2088.9395        20    98   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a            720     708.9382         5   180   \n",
       "\n",
       "                                  d3_y   d3_stuns  d3_creeps_stacked  \\\n",
       "match_id_hash                                                          \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b   166   2.499243                  2   \n",
       "a9475ee47c8a10d6cf37c1461814653e   124  30.817260                  0   \n",
       "b56ea18db1408fc68263757232c1facb   166   1.949498                  0   \n",
       "9587640246910f0e1b033a6c8f6d8211    96   2.032837                  0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a   126   0.000000                  0   \n",
       "\n",
       "                                  d3_camps_stacked  d3_rune_pickups  \\\n",
       "match_id_hash                                                         \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                 1                1   \n",
       "a9475ee47c8a10d6cf37c1461814653e                 0               13   \n",
       "b56ea18db1408fc68263757232c1facb                 0                6   \n",
       "9587640246910f0e1b033a6c8f6d8211                 0                7   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                 0                4   \n",
       "\n",
       "                                  d3_firstblood_claimed  \\\n",
       "match_id_hash                                             \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                      0   \n",
       "a9475ee47c8a10d6cf37c1461814653e                      0   \n",
       "b56ea18db1408fc68263757232c1facb                      0   \n",
       "9587640246910f0e1b033a6c8f6d8211                      0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                      0   \n",
       "\n",
       "                                  d3_teamfight_participation  \\\n",
       "match_id_hash                                                  \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                    0.300000   \n",
       "a9475ee47c8a10d6cf37c1461814653e                    0.361702   \n",
       "b56ea18db1408fc68263757232c1facb                    0.800000   \n",
       "9587640246910f0e1b033a6c8f6d8211                    0.600000   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                    0.333333   \n",
       "\n",
       "                                  d3_towers_killed  d3_roshans_killed  \\\n",
       "match_id_hash                                                           \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                 0                  0   \n",
       "a9475ee47c8a10d6cf37c1461814653e                 0                  0   \n",
       "b56ea18db1408fc68263757232c1facb                 0                  0   \n",
       "9587640246910f0e1b033a6c8f6d8211                 1                  0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                 0                  0   \n",
       "\n",
       "                                  d3_obs_placed  d3_sen_placed  d4_hero_id  \\\n",
       "match_id_hash                                                                \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b              0              1         103   \n",
       "a9475ee47c8a10d6cf37c1461814653e              5              0          59   \n",
       "b56ea18db1408fc68263757232c1facb              2              0         109   \n",
       "9587640246910f0e1b033a6c8f6d8211              1              0          51   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a              0              0          43   \n",
       "\n",
       "                                  d4_kills  d4_deaths  d4_assists  d4_denies  \\\n",
       "match_id_hash                                                                  \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b         5          9           9          0   \n",
       "a9475ee47c8a10d6cf37c1461814653e        12         13           9          2   \n",
       "b56ea18db1408fc68263757232c1facb         3          1           0          7   \n",
       "9587640246910f0e1b033a6c8f6d8211         2          4          16          6   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a         1          0           1         17   \n",
       "\n",
       "                                  d4_gold  d4_lh  d4_xp  d4_health  \\\n",
       "match_id_hash                                                        \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b     8977     31  12141          0   \n",
       "a9475ee47c8a10d6cf37c1461814653e    20428    156  24126       2184   \n",
       "b56ea18db1408fc68263757232c1facb     6543    111   6376       1178   \n",
       "9587640246910f0e1b033a6c8f6d8211     9765     41  13426       2240   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a     2904     38   4134       1000   \n",
       "\n",
       "                                  d4_max_health  d4_max_mana  d4_level  d4_x  \\\n",
       "match_id_hash                                                                  \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b           1500    902.93835        16   172   \n",
       "a9475ee47c8a10d6cf37c1461814653e           2940    686.93820        23   106   \n",
       "b56ea18db1408fc68263757232c1facb           1180    554.93805        11   122   \n",
       "9587640246910f0e1b033a6c8f6d8211           2240    936.93840        17   104   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a           1000    710.93820         8   118   \n",
       "\n",
       "                                  d4_y   d4_stuns  d4_creeps_stacked  \\\n",
       "match_id_hash                                                          \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b   172  92.217285                  0   \n",
       "a9475ee47c8a10d6cf37c1461814653e   114   0.000000                  0   \n",
       "b56ea18db1408fc68263757232c1facb   146   0.000000                  5   \n",
       "9587640246910f0e1b033a6c8f6d8211   120  20.910597                  0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a   122   0.000000                  0   \n",
       "\n",
       "                                  d4_camps_stacked  d4_rune_pickups  \\\n",
       "match_id_hash                                                         \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                 0                2   \n",
       "a9475ee47c8a10d6cf37c1461814653e                 0               17   \n",
       "b56ea18db1408fc68263757232c1facb                 2                0   \n",
       "9587640246910f0e1b033a6c8f6d8211                 0                9   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                 0                1   \n",
       "\n",
       "                                  d4_firstblood_claimed  \\\n",
       "match_id_hash                                             \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                      1   \n",
       "a9475ee47c8a10d6cf37c1461814653e                      0   \n",
       "b56ea18db1408fc68263757232c1facb                      0   \n",
       "9587640246910f0e1b033a6c8f6d8211                      0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                      0   \n",
       "\n",
       "                                  d4_teamfight_participation  \\\n",
       "match_id_hash                                                  \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                    0.700000   \n",
       "a9475ee47c8a10d6cf37c1461814653e                    0.446809   \n",
       "b56ea18db1408fc68263757232c1facb                    0.300000   \n",
       "9587640246910f0e1b033a6c8f6d8211                    0.514286   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                    0.666667   \n",
       "\n",
       "                                  d4_towers_killed  d4_roshans_killed  \\\n",
       "match_id_hash                                                           \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                 0                  0   \n",
       "a9475ee47c8a10d6cf37c1461814653e                 1                  1   \n",
       "b56ea18db1408fc68263757232c1facb                 1                  0   \n",
       "9587640246910f0e1b033a6c8f6d8211                 0                  0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                 0                  0   \n",
       "\n",
       "                                  d4_obs_placed  d4_sen_placed  d5_hero_id  \\\n",
       "match_id_hash                                                                \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b              7              3          10   \n",
       "a9475ee47c8a10d6cf37c1461814653e              3              2          22   \n",
       "b56ea18db1408fc68263757232c1facb              0              0           5   \n",
       "9587640246910f0e1b033a6c8f6d8211              0              4         114   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a              1              0          21   \n",
       "\n",
       "                                  d5_kills  d5_deaths  d5_assists  d5_denies  \\\n",
       "match_id_hash                                                                  \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b         8          6           5         18   \n",
       "a9475ee47c8a10d6cf37c1461814653e        11          8          15          2   \n",
       "b56ea18db1408fc68263757232c1facb         1          3           5          1   \n",
       "9587640246910f0e1b033a6c8f6d8211         6          7          12         23   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a         1          0           2          0   \n",
       "\n",
       "                                  d5_gold  d5_lh  d5_xp  d5_health  \\\n",
       "match_id_hash                                                        \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b     9169     73  11146          0   \n",
       "a9475ee47c8a10d6cf37c1461814653e    22728    196  26945       2620   \n",
       "b56ea18db1408fc68263757232c1facb     3488     20   4560        968   \n",
       "9587640246910f0e1b033a6c8f6d8211    14028    116  14056          0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a     2069      5   1346        700   \n",
       "\n",
       "                                  d5_max_health  d5_max_mana  d5_level  d5_x  \\\n",
       "match_id_hash                                                                  \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b            800    626.93810        15   158   \n",
       "a9475ee47c8a10d6cf37c1461814653e           2620   2768.94020        25   120   \n",
       "b56ea18db1408fc68263757232c1facb           1020    602.93805         9   102   \n",
       "9587640246910f0e1b033a6c8f6d8211           2100    794.93823        18   112   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a            700    446.93793         4    86   \n",
       "\n",
       "                                  d5_y   d5_stuns  d5_creeps_stacked  \\\n",
       "match_id_hash                                                          \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b   168  12.174799                  0   \n",
       "a9475ee47c8a10d6cf37c1461814653e   122  31.994320                  0   \n",
       "b56ea18db1408fc68263757232c1facb   170  20.528862                  0   \n",
       "9587640246910f0e1b033a6c8f6d8211   104  27.558594                  0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a   160  11.663805                  6   \n",
       "\n",
       "                                  d5_camps_stacked  d5_rune_pickups  \\\n",
       "match_id_hash                                                         \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                 0                1   \n",
       "a9475ee47c8a10d6cf37c1461814653e                 0               12   \n",
       "b56ea18db1408fc68263757232c1facb                 0                4   \n",
       "9587640246910f0e1b033a6c8f6d8211                 0                6   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                 2                6   \n",
       "\n",
       "                                  d5_firstblood_claimed  \\\n",
       "match_id_hash                                             \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                      0   \n",
       "a9475ee47c8a10d6cf37c1461814653e                      0   \n",
       "b56ea18db1408fc68263757232c1facb                      0   \n",
       "9587640246910f0e1b033a6c8f6d8211                      0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                      0   \n",
       "\n",
       "                                  d5_teamfight_participation  \\\n",
       "match_id_hash                                                  \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                    0.650000   \n",
       "a9475ee47c8a10d6cf37c1461814653e                    0.553191   \n",
       "b56ea18db1408fc68263757232c1facb                    0.600000   \n",
       "9587640246910f0e1b033a6c8f6d8211                    0.514286   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                    1.000000   \n",
       "\n",
       "                                  d5_towers_killed  d5_roshans_killed  \\\n",
       "match_id_hash                                                           \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b                 0                  0   \n",
       "a9475ee47c8a10d6cf37c1461814653e                 1                  0   \n",
       "b56ea18db1408fc68263757232c1facb                 0                  0   \n",
       "9587640246910f0e1b033a6c8f6d8211                 1                  0   \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a                 0                  0   \n",
       "\n",
       "                                  d5_obs_placed  d5_sen_placed  \n",
       "match_id_hash                                                   \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b              0              0  \n",
       "a9475ee47c8a10d6cf37c1461814653e              0              0  \n",
       "b56ea18db1408fc68263757232c1facb              4              2  \n",
       "9587640246910f0e1b033a6c8f6d8211              0              0  \n",
       "3eb93fbd9056ebdb52ffff84e6c3664a              3              3  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сортеруем данные по полю match_id_hash\n",
    "df_features = df_features.sort_values(by='match_id_hash').reset_index(drop=True)\n",
    "df_target = df_target.sort_values(by='match_id_hash').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id_hash</th>\n",
       "      <th>game_time</th>\n",
       "      <th>game_mode</th>\n",
       "      <th>lobby_type</th>\n",
       "      <th>objectives_len</th>\n",
       "      <th>chat_len</th>\n",
       "      <th>r1_hero_id</th>\n",
       "      <th>r1_kills</th>\n",
       "      <th>r1_deaths</th>\n",
       "      <th>r1_assists</th>\n",
       "      <th>r1_denies</th>\n",
       "      <th>r1_gold</th>\n",
       "      <th>r1_lh</th>\n",
       "      <th>r1_xp</th>\n",
       "      <th>r1_health</th>\n",
       "      <th>r1_max_health</th>\n",
       "      <th>r1_max_mana</th>\n",
       "      <th>r1_level</th>\n",
       "      <th>r1_x</th>\n",
       "      <th>r1_y</th>\n",
       "      <th>r1_stuns</th>\n",
       "      <th>r1_creeps_stacked</th>\n",
       "      <th>r1_camps_stacked</th>\n",
       "      <th>r1_rune_pickups</th>\n",
       "      <th>r1_firstblood_claimed</th>\n",
       "      <th>r1_teamfight_participation</th>\n",
       "      <th>r1_towers_killed</th>\n",
       "      <th>r1_roshans_killed</th>\n",
       "      <th>r1_obs_placed</th>\n",
       "      <th>r1_sen_placed</th>\n",
       "      <th>r2_hero_id</th>\n",
       "      <th>r2_kills</th>\n",
       "      <th>r2_deaths</th>\n",
       "      <th>r2_assists</th>\n",
       "      <th>r2_denies</th>\n",
       "      <th>r2_gold</th>\n",
       "      <th>r2_lh</th>\n",
       "      <th>r2_xp</th>\n",
       "      <th>r2_health</th>\n",
       "      <th>r2_max_health</th>\n",
       "      <th>r2_max_mana</th>\n",
       "      <th>r2_level</th>\n",
       "      <th>r2_x</th>\n",
       "      <th>r2_y</th>\n",
       "      <th>r2_stuns</th>\n",
       "      <th>r2_creeps_stacked</th>\n",
       "      <th>r2_camps_stacked</th>\n",
       "      <th>r2_rune_pickups</th>\n",
       "      <th>r2_firstblood_claimed</th>\n",
       "      <th>r2_teamfight_participation</th>\n",
       "      <th>r2_towers_killed</th>\n",
       "      <th>r2_roshans_killed</th>\n",
       "      <th>r2_obs_placed</th>\n",
       "      <th>r2_sen_placed</th>\n",
       "      <th>r3_hero_id</th>\n",
       "      <th>r3_kills</th>\n",
       "      <th>r3_deaths</th>\n",
       "      <th>r3_assists</th>\n",
       "      <th>r3_denies</th>\n",
       "      <th>r3_gold</th>\n",
       "      <th>r3_lh</th>\n",
       "      <th>r3_xp</th>\n",
       "      <th>r3_health</th>\n",
       "      <th>r3_max_health</th>\n",
       "      <th>r3_max_mana</th>\n",
       "      <th>r3_level</th>\n",
       "      <th>r3_x</th>\n",
       "      <th>r3_y</th>\n",
       "      <th>r3_stuns</th>\n",
       "      <th>r3_creeps_stacked</th>\n",
       "      <th>r3_camps_stacked</th>\n",
       "      <th>r3_rune_pickups</th>\n",
       "      <th>r3_firstblood_claimed</th>\n",
       "      <th>r3_teamfight_participation</th>\n",
       "      <th>r3_towers_killed</th>\n",
       "      <th>r3_roshans_killed</th>\n",
       "      <th>r3_obs_placed</th>\n",
       "      <th>r3_sen_placed</th>\n",
       "      <th>r4_hero_id</th>\n",
       "      <th>r4_kills</th>\n",
       "      <th>r4_deaths</th>\n",
       "      <th>r4_assists</th>\n",
       "      <th>r4_denies</th>\n",
       "      <th>r4_gold</th>\n",
       "      <th>r4_lh</th>\n",
       "      <th>r4_xp</th>\n",
       "      <th>r4_health</th>\n",
       "      <th>r4_max_health</th>\n",
       "      <th>r4_max_mana</th>\n",
       "      <th>r4_level</th>\n",
       "      <th>r4_x</th>\n",
       "      <th>r4_y</th>\n",
       "      <th>r4_stuns</th>\n",
       "      <th>r4_creeps_stacked</th>\n",
       "      <th>r4_camps_stacked</th>\n",
       "      <th>r4_rune_pickups</th>\n",
       "      <th>r4_firstblood_claimed</th>\n",
       "      <th>r4_teamfight_participation</th>\n",
       "      <th>r4_towers_killed</th>\n",
       "      <th>r4_roshans_killed</th>\n",
       "      <th>r4_obs_placed</th>\n",
       "      <th>r4_sen_placed</th>\n",
       "      <th>r5_hero_id</th>\n",
       "      <th>r5_kills</th>\n",
       "      <th>r5_deaths</th>\n",
       "      <th>r5_assists</th>\n",
       "      <th>r5_denies</th>\n",
       "      <th>r5_gold</th>\n",
       "      <th>r5_lh</th>\n",
       "      <th>r5_xp</th>\n",
       "      <th>r5_health</th>\n",
       "      <th>r5_max_health</th>\n",
       "      <th>r5_max_mana</th>\n",
       "      <th>r5_level</th>\n",
       "      <th>r5_x</th>\n",
       "      <th>r5_y</th>\n",
       "      <th>r5_stuns</th>\n",
       "      <th>r5_creeps_stacked</th>\n",
       "      <th>r5_camps_stacked</th>\n",
       "      <th>r5_rune_pickups</th>\n",
       "      <th>r5_firstblood_claimed</th>\n",
       "      <th>r5_teamfight_participation</th>\n",
       "      <th>r5_towers_killed</th>\n",
       "      <th>r5_roshans_killed</th>\n",
       "      <th>r5_obs_placed</th>\n",
       "      <th>r5_sen_placed</th>\n",
       "      <th>d1_hero_id</th>\n",
       "      <th>d1_kills</th>\n",
       "      <th>d1_deaths</th>\n",
       "      <th>d1_assists</th>\n",
       "      <th>d1_denies</th>\n",
       "      <th>d1_gold</th>\n",
       "      <th>d1_lh</th>\n",
       "      <th>d1_xp</th>\n",
       "      <th>d1_health</th>\n",
       "      <th>d1_max_health</th>\n",
       "      <th>d1_max_mana</th>\n",
       "      <th>d1_level</th>\n",
       "      <th>d1_x</th>\n",
       "      <th>d1_y</th>\n",
       "      <th>d1_stuns</th>\n",
       "      <th>d1_creeps_stacked</th>\n",
       "      <th>d1_camps_stacked</th>\n",
       "      <th>d1_rune_pickups</th>\n",
       "      <th>d1_firstblood_claimed</th>\n",
       "      <th>d1_teamfight_participation</th>\n",
       "      <th>d1_towers_killed</th>\n",
       "      <th>d1_roshans_killed</th>\n",
       "      <th>d1_obs_placed</th>\n",
       "      <th>d1_sen_placed</th>\n",
       "      <th>d2_hero_id</th>\n",
       "      <th>d2_kills</th>\n",
       "      <th>d2_deaths</th>\n",
       "      <th>d2_assists</th>\n",
       "      <th>d2_denies</th>\n",
       "      <th>d2_gold</th>\n",
       "      <th>d2_lh</th>\n",
       "      <th>d2_xp</th>\n",
       "      <th>d2_health</th>\n",
       "      <th>d2_max_health</th>\n",
       "      <th>d2_max_mana</th>\n",
       "      <th>d2_level</th>\n",
       "      <th>d2_x</th>\n",
       "      <th>d2_y</th>\n",
       "      <th>d2_stuns</th>\n",
       "      <th>d2_creeps_stacked</th>\n",
       "      <th>d2_camps_stacked</th>\n",
       "      <th>d2_rune_pickups</th>\n",
       "      <th>d2_firstblood_claimed</th>\n",
       "      <th>d2_teamfight_participation</th>\n",
       "      <th>d2_towers_killed</th>\n",
       "      <th>d2_roshans_killed</th>\n",
       "      <th>d2_obs_placed</th>\n",
       "      <th>d2_sen_placed</th>\n",
       "      <th>d3_hero_id</th>\n",
       "      <th>d3_kills</th>\n",
       "      <th>d3_deaths</th>\n",
       "      <th>d3_assists</th>\n",
       "      <th>d3_denies</th>\n",
       "      <th>d3_gold</th>\n",
       "      <th>d3_lh</th>\n",
       "      <th>d3_xp</th>\n",
       "      <th>d3_health</th>\n",
       "      <th>d3_max_health</th>\n",
       "      <th>d3_max_mana</th>\n",
       "      <th>d3_level</th>\n",
       "      <th>d3_x</th>\n",
       "      <th>d3_y</th>\n",
       "      <th>d3_stuns</th>\n",
       "      <th>d3_creeps_stacked</th>\n",
       "      <th>d3_camps_stacked</th>\n",
       "      <th>d3_rune_pickups</th>\n",
       "      <th>d3_firstblood_claimed</th>\n",
       "      <th>d3_teamfight_participation</th>\n",
       "      <th>d3_towers_killed</th>\n",
       "      <th>d3_roshans_killed</th>\n",
       "      <th>d3_obs_placed</th>\n",
       "      <th>d3_sen_placed</th>\n",
       "      <th>d4_hero_id</th>\n",
       "      <th>d4_kills</th>\n",
       "      <th>d4_deaths</th>\n",
       "      <th>d4_assists</th>\n",
       "      <th>d4_denies</th>\n",
       "      <th>d4_gold</th>\n",
       "      <th>d4_lh</th>\n",
       "      <th>d4_xp</th>\n",
       "      <th>d4_health</th>\n",
       "      <th>d4_max_health</th>\n",
       "      <th>d4_max_mana</th>\n",
       "      <th>d4_level</th>\n",
       "      <th>d4_x</th>\n",
       "      <th>d4_y</th>\n",
       "      <th>d4_stuns</th>\n",
       "      <th>d4_creeps_stacked</th>\n",
       "      <th>d4_camps_stacked</th>\n",
       "      <th>d4_rune_pickups</th>\n",
       "      <th>d4_firstblood_claimed</th>\n",
       "      <th>d4_teamfight_participation</th>\n",
       "      <th>d4_towers_killed</th>\n",
       "      <th>d4_roshans_killed</th>\n",
       "      <th>d4_obs_placed</th>\n",
       "      <th>d4_sen_placed</th>\n",
       "      <th>d5_hero_id</th>\n",
       "      <th>d5_kills</th>\n",
       "      <th>d5_deaths</th>\n",
       "      <th>d5_assists</th>\n",
       "      <th>d5_denies</th>\n",
       "      <th>d5_gold</th>\n",
       "      <th>d5_lh</th>\n",
       "      <th>d5_xp</th>\n",
       "      <th>d5_health</th>\n",
       "      <th>d5_max_health</th>\n",
       "      <th>d5_max_mana</th>\n",
       "      <th>d5_level</th>\n",
       "      <th>d5_x</th>\n",
       "      <th>d5_y</th>\n",
       "      <th>d5_stuns</th>\n",
       "      <th>d5_creeps_stacked</th>\n",
       "      <th>d5_camps_stacked</th>\n",
       "      <th>d5_rune_pickups</th>\n",
       "      <th>d5_firstblood_claimed</th>\n",
       "      <th>d5_teamfight_participation</th>\n",
       "      <th>d5_towers_killed</th>\n",
       "      <th>d5_roshans_killed</th>\n",
       "      <th>d5_obs_placed</th>\n",
       "      <th>d5_sen_placed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000c270e25494c03d5c81036463fc45</td>\n",
       "      <td>1304</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>8449</td>\n",
       "      <td>104</td>\n",
       "      <td>8897</td>\n",
       "      <td>1162</td>\n",
       "      <td>1180</td>\n",
       "      <td>710.93820</td>\n",
       "      <td>14</td>\n",
       "      <td>142</td>\n",
       "      <td>138</td>\n",
       "      <td>27.993195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6633</td>\n",
       "      <td>11</td>\n",
       "      <td>7179</td>\n",
       "      <td>1040</td>\n",
       "      <td>1080</td>\n",
       "      <td>1172.93860</td>\n",
       "      <td>12</td>\n",
       "      <td>142</td>\n",
       "      <td>138</td>\n",
       "      <td>89.179440</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>76</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10232</td>\n",
       "      <td>119</td>\n",
       "      <td>11261</td>\n",
       "      <td>1950</td>\n",
       "      <td>1950</td>\n",
       "      <td>1564.93900</td>\n",
       "      <td>15</td>\n",
       "      <td>152</td>\n",
       "      <td>138</td>\n",
       "      <td>44.355835</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5053</td>\n",
       "      <td>8</td>\n",
       "      <td>5073</td>\n",
       "      <td>179</td>\n",
       "      <td>920</td>\n",
       "      <td>770.93823</td>\n",
       "      <td>9</td>\n",
       "      <td>146</td>\n",
       "      <td>138</td>\n",
       "      <td>62.519253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>6319</td>\n",
       "      <td>52</td>\n",
       "      <td>7160</td>\n",
       "      <td>0</td>\n",
       "      <td>1180</td>\n",
       "      <td>518.93800</td>\n",
       "      <td>12</td>\n",
       "      <td>142</td>\n",
       "      <td>136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>12678</td>\n",
       "      <td>169</td>\n",
       "      <td>11676</td>\n",
       "      <td>594</td>\n",
       "      <td>1340</td>\n",
       "      <td>566.93805</td>\n",
       "      <td>16</td>\n",
       "      <td>146</td>\n",
       "      <td>140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>6683</td>\n",
       "      <td>59</td>\n",
       "      <td>8200</td>\n",
       "      <td>1670</td>\n",
       "      <td>1675</td>\n",
       "      <td>1017.93850</td>\n",
       "      <td>13</td>\n",
       "      <td>156</td>\n",
       "      <td>154</td>\n",
       "      <td>3.099145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>8032</td>\n",
       "      <td>140</td>\n",
       "      <td>9487</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>602.93805</td>\n",
       "      <td>14</td>\n",
       "      <td>182</td>\n",
       "      <td>176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4794</td>\n",
       "      <td>11</td>\n",
       "      <td>5069</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>852.93830</td>\n",
       "      <td>9</td>\n",
       "      <td>158</td>\n",
       "      <td>160</td>\n",
       "      <td>31.858887</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4225</td>\n",
       "      <td>10</td>\n",
       "      <td>4661</td>\n",
       "      <td>1340</td>\n",
       "      <td>1340</td>\n",
       "      <td>470.93796</td>\n",
       "      <td>9</td>\n",
       "      <td>146</td>\n",
       "      <td>140</td>\n",
       "      <td>11.797119</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000cbef31e13f297dbbe47d84a08169</td>\n",
       "      <td>1056</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3397</td>\n",
       "      <td>16</td>\n",
       "      <td>3544</td>\n",
       "      <td>960</td>\n",
       "      <td>960</td>\n",
       "      <td>864.93835</td>\n",
       "      <td>7</td>\n",
       "      <td>106</td>\n",
       "      <td>128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5470</td>\n",
       "      <td>37</td>\n",
       "      <td>6619</td>\n",
       "      <td>1051</td>\n",
       "      <td>1340</td>\n",
       "      <td>482.93796</td>\n",
       "      <td>11</td>\n",
       "      <td>130</td>\n",
       "      <td>106</td>\n",
       "      <td>28.359995</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4047</td>\n",
       "      <td>4</td>\n",
       "      <td>4231</td>\n",
       "      <td>310</td>\n",
       "      <td>960</td>\n",
       "      <td>600.93805</td>\n",
       "      <td>8</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>8.078904</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7225</td>\n",
       "      <td>126</td>\n",
       "      <td>9017</td>\n",
       "      <td>824</td>\n",
       "      <td>1140</td>\n",
       "      <td>878.93835</td>\n",
       "      <td>14</td>\n",
       "      <td>120</td>\n",
       "      <td>100</td>\n",
       "      <td>5.065430</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>6427</td>\n",
       "      <td>74</td>\n",
       "      <td>8017</td>\n",
       "      <td>1116</td>\n",
       "      <td>1120</td>\n",
       "      <td>590.93805</td>\n",
       "      <td>13</td>\n",
       "      <td>96</td>\n",
       "      <td>132</td>\n",
       "      <td>12.316595</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5736</td>\n",
       "      <td>48</td>\n",
       "      <td>4536</td>\n",
       "      <td>823</td>\n",
       "      <td>840</td>\n",
       "      <td>782.93823</td>\n",
       "      <td>9</td>\n",
       "      <td>140</td>\n",
       "      <td>108</td>\n",
       "      <td>1.532959</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4025</td>\n",
       "      <td>22</td>\n",
       "      <td>4687</td>\n",
       "      <td>1340</td>\n",
       "      <td>1340</td>\n",
       "      <td>434.93793</td>\n",
       "      <td>9</td>\n",
       "      <td>136</td>\n",
       "      <td>116</td>\n",
       "      <td>14.563202</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>7133</td>\n",
       "      <td>81</td>\n",
       "      <td>8052</td>\n",
       "      <td>1220</td>\n",
       "      <td>1220</td>\n",
       "      <td>662.93810</td>\n",
       "      <td>13</td>\n",
       "      <td>130</td>\n",
       "      <td>128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>8309</td>\n",
       "      <td>131</td>\n",
       "      <td>8684</td>\n",
       "      <td>1037</td>\n",
       "      <td>1480</td>\n",
       "      <td>530.93800</td>\n",
       "      <td>13</td>\n",
       "      <td>106</td>\n",
       "      <td>156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3215</td>\n",
       "      <td>14</td>\n",
       "      <td>3985</td>\n",
       "      <td>980</td>\n",
       "      <td>980</td>\n",
       "      <td>614.93810</td>\n",
       "      <td>8</td>\n",
       "      <td>142</td>\n",
       "      <td>110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000432b654aee6e8792ce17bb19ccf16</td>\n",
       "      <td>170</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>566</td>\n",
       "      <td>0</td>\n",
       "      <td>331</td>\n",
       "      <td>577</td>\n",
       "      <td>580</td>\n",
       "      <td>302.93777</td>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "      <td>162</td>\n",
       "      <td>5.465307</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1305</td>\n",
       "      <td>13</td>\n",
       "      <td>899</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>326.93780</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>603</td>\n",
       "      <td>1</td>\n",
       "      <td>559</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>254.93774</td>\n",
       "      <td>2</td>\n",
       "      <td>166</td>\n",
       "      <td>84</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>654</td>\n",
       "      <td>5</td>\n",
       "      <td>1076</td>\n",
       "      <td>518</td>\n",
       "      <td>560</td>\n",
       "      <td>374.93787</td>\n",
       "      <td>3</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>781</td>\n",
       "      <td>7</td>\n",
       "      <td>502</td>\n",
       "      <td>670</td>\n",
       "      <td>700</td>\n",
       "      <td>314.93780</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>84</td>\n",
       "      <td>2.666016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>626</td>\n",
       "      <td>3</td>\n",
       "      <td>602</td>\n",
       "      <td>663</td>\n",
       "      <td>760</td>\n",
       "      <td>350.93784</td>\n",
       "      <td>3</td>\n",
       "      <td>176</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>823</td>\n",
       "      <td>6</td>\n",
       "      <td>562</td>\n",
       "      <td>593</td>\n",
       "      <td>600</td>\n",
       "      <td>314.93780</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>88</td>\n",
       "      <td>1.566272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>717</td>\n",
       "      <td>10</td>\n",
       "      <td>1262</td>\n",
       "      <td>475</td>\n",
       "      <td>740</td>\n",
       "      <td>266.93774</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1467</td>\n",
       "      <td>9</td>\n",
       "      <td>1053</td>\n",
       "      <td>286</td>\n",
       "      <td>680</td>\n",
       "      <td>278.93777</td>\n",
       "      <td>3</td>\n",
       "      <td>94</td>\n",
       "      <td>172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>384</td>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "      <td>338.93784</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000a2ba6b82a4a1829ca226a880ec993</td>\n",
       "      <td>393</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1594</td>\n",
       "      <td>5</td>\n",
       "      <td>4706</td>\n",
       "      <td>0</td>\n",
       "      <td>860</td>\n",
       "      <td>446.93793</td>\n",
       "      <td>9</td>\n",
       "      <td>116</td>\n",
       "      <td>118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2874</td>\n",
       "      <td>14</td>\n",
       "      <td>3732</td>\n",
       "      <td>1160</td>\n",
       "      <td>1160</td>\n",
       "      <td>422.93790</td>\n",
       "      <td>8</td>\n",
       "      <td>172</td>\n",
       "      <td>84</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3502</td>\n",
       "      <td>11</td>\n",
       "      <td>3952</td>\n",
       "      <td>1160</td>\n",
       "      <td>1160</td>\n",
       "      <td>386.93787</td>\n",
       "      <td>8</td>\n",
       "      <td>86</td>\n",
       "      <td>144</td>\n",
       "      <td>4.132328</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3144</td>\n",
       "      <td>11</td>\n",
       "      <td>4244</td>\n",
       "      <td>248</td>\n",
       "      <td>800</td>\n",
       "      <td>350.93784</td>\n",
       "      <td>8</td>\n",
       "      <td>86</td>\n",
       "      <td>148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2366</td>\n",
       "      <td>3</td>\n",
       "      <td>3076</td>\n",
       "      <td>0</td>\n",
       "      <td>840</td>\n",
       "      <td>494.93796</td>\n",
       "      <td>7</td>\n",
       "      <td>166</td>\n",
       "      <td>88</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2894</td>\n",
       "      <td>6</td>\n",
       "      <td>3375</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>984.93840</td>\n",
       "      <td>7</td>\n",
       "      <td>96</td>\n",
       "      <td>156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2072</td>\n",
       "      <td>2</td>\n",
       "      <td>3947</td>\n",
       "      <td>723</td>\n",
       "      <td>1220</td>\n",
       "      <td>386.93787</td>\n",
       "      <td>8</td>\n",
       "      <td>174</td>\n",
       "      <td>94</td>\n",
       "      <td>4.965462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6052</td>\n",
       "      <td>42</td>\n",
       "      <td>8566</td>\n",
       "      <td>1105</td>\n",
       "      <td>1340</td>\n",
       "      <td>758.93823</td>\n",
       "      <td>13</td>\n",
       "      <td>146</td>\n",
       "      <td>122</td>\n",
       "      <td>2.532715</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2396</td>\n",
       "      <td>10</td>\n",
       "      <td>3339</td>\n",
       "      <td>1020</td>\n",
       "      <td>1020</td>\n",
       "      <td>636.93810</td>\n",
       "      <td>7</td>\n",
       "      <td>80</td>\n",
       "      <td>166</td>\n",
       "      <td>18.196856</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3352</td>\n",
       "      <td>19</td>\n",
       "      <td>3926</td>\n",
       "      <td>420</td>\n",
       "      <td>940</td>\n",
       "      <td>314.93780</td>\n",
       "      <td>8</td>\n",
       "      <td>174</td>\n",
       "      <td>88</td>\n",
       "      <td>0.766487</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000a9891b8b7712e9a19e032b583023e</td>\n",
       "      <td>1142</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4542</td>\n",
       "      <td>45</td>\n",
       "      <td>4235</td>\n",
       "      <td>1240</td>\n",
       "      <td>1240</td>\n",
       "      <td>494.93796</td>\n",
       "      <td>8</td>\n",
       "      <td>74</td>\n",
       "      <td>102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4514</td>\n",
       "      <td>23</td>\n",
       "      <td>4180</td>\n",
       "      <td>920</td>\n",
       "      <td>920</td>\n",
       "      <td>530.93800</td>\n",
       "      <td>8</td>\n",
       "      <td>104</td>\n",
       "      <td>106</td>\n",
       "      <td>0.499924</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>8155</td>\n",
       "      <td>119</td>\n",
       "      <td>7723</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>566.93805</td>\n",
       "      <td>13</td>\n",
       "      <td>76</td>\n",
       "      <td>102</td>\n",
       "      <td>11.263947</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>6327</td>\n",
       "      <td>108</td>\n",
       "      <td>7407</td>\n",
       "      <td>1100</td>\n",
       "      <td>1100</td>\n",
       "      <td>614.93810</td>\n",
       "      <td>12</td>\n",
       "      <td>104</td>\n",
       "      <td>110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4112</td>\n",
       "      <td>19</td>\n",
       "      <td>4397</td>\n",
       "      <td>1140</td>\n",
       "      <td>1140</td>\n",
       "      <td>864.93835</td>\n",
       "      <td>9</td>\n",
       "      <td>84</td>\n",
       "      <td>90</td>\n",
       "      <td>19.761868</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>6268</td>\n",
       "      <td>61</td>\n",
       "      <td>6194</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>780.93823</td>\n",
       "      <td>11</td>\n",
       "      <td>154</td>\n",
       "      <td>86</td>\n",
       "      <td>-0.816772</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>10251</td>\n",
       "      <td>111</td>\n",
       "      <td>9444</td>\n",
       "      <td>1305</td>\n",
       "      <td>1540</td>\n",
       "      <td>1154.93860</td>\n",
       "      <td>14</td>\n",
       "      <td>126</td>\n",
       "      <td>144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3550</td>\n",
       "      <td>15</td>\n",
       "      <td>4418</td>\n",
       "      <td>880</td>\n",
       "      <td>880</td>\n",
       "      <td>876.93835</td>\n",
       "      <td>9</td>\n",
       "      <td>128</td>\n",
       "      <td>130</td>\n",
       "      <td>12.796868</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>11252</td>\n",
       "      <td>166</td>\n",
       "      <td>11686</td>\n",
       "      <td>1645</td>\n",
       "      <td>1890</td>\n",
       "      <td>866.93835</td>\n",
       "      <td>16</td>\n",
       "      <td>76</td>\n",
       "      <td>116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5867</td>\n",
       "      <td>21</td>\n",
       "      <td>6803</td>\n",
       "      <td>1403</td>\n",
       "      <td>1880</td>\n",
       "      <td>944.93840</td>\n",
       "      <td>12</td>\n",
       "      <td>124</td>\n",
       "      <td>128</td>\n",
       "      <td>16.362675</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      match_id_hash  game_time  game_mode  lobby_type  \\\n",
       "0  0000c270e25494c03d5c81036463fc45       1304         22           7   \n",
       "1  0000cbef31e13f297dbbe47d84a08169       1056         22           7   \n",
       "2  000432b654aee6e8792ce17bb19ccf16        170         22           7   \n",
       "3  000a2ba6b82a4a1829ca226a880ec993        393         23           0   \n",
       "4  000a9891b8b7712e9a19e032b583023e       1142         22           7   \n",
       "\n",
       "   objectives_len  chat_len  r1_hero_id  r1_kills  r1_deaths  r1_assists  \\\n",
       "0               7         3           9         2          1           2   \n",
       "1               3         0          85         1          2           2   \n",
       "2               1         1           5         0          0           1   \n",
       "3               1         2          56         0          2           0   \n",
       "4               7         0         104         1          5           0   \n",
       "\n",
       "   r1_denies  r1_gold  r1_lh  r1_xp  r1_health  r1_max_health  r1_max_mana  \\\n",
       "0          9     8449    104   8897       1162           1180    710.93820   \n",
       "1          1     3397     16   3544        960            960    864.93835   \n",
       "2          0      566      0    331        577            580    302.93777   \n",
       "3          2     1594      5   4706          0            860    446.93793   \n",
       "4          3     4542     45   4235       1240           1240    494.93796   \n",
       "\n",
       "   r1_level  r1_x  r1_y   r1_stuns  r1_creeps_stacked  r1_camps_stacked  \\\n",
       "0        14   142   138  27.993195                  0                 0   \n",
       "1         7   106   128   0.000000                  0                 0   \n",
       "2         2    78   162   5.465307                  0                 0   \n",
       "3         9   116   118   0.000000                  0                 0   \n",
       "4         8    74   102   0.000000                  0                 0   \n",
       "\n",
       "   r1_rune_pickups  r1_firstblood_claimed  r1_teamfight_participation  \\\n",
       "0                4                      0                    0.235294   \n",
       "1                6                      1                    0.187500   \n",
       "2                3                      0                    0.333333   \n",
       "3                0                      0                    0.000000   \n",
       "4                4                      0                    0.111111   \n",
       "\n",
       "   r1_towers_killed  r1_roshans_killed  r1_obs_placed  r1_sen_placed  \\\n",
       "0                 0                  0              0              0   \n",
       "1                 0                  0              1              1   \n",
       "2                 0                  0              1              0   \n",
       "3                 0                  0              0              0   \n",
       "4                 0                  0              1              0   \n",
       "\n",
       "   r2_hero_id  r2_kills  r2_deaths  r2_assists  r2_denies  r2_gold  r2_lh  \\\n",
       "0          27         5          2           6          5     6633     11   \n",
       "1          16         3          2           8          3     5470     37   \n",
       "2           2         2          2           0          0     1305     13   \n",
       "3          54         1          1           0          1     2874     14   \n",
       "4          62         3          2           3          2     4514     23   \n",
       "\n",
       "   r2_xp  r2_health  r2_max_health  r2_max_mana  r2_level  r2_x  r2_y  \\\n",
       "0   7179       1040           1080   1172.93860        12   142   138   \n",
       "1   6619       1051           1340    482.93796        11   130   106   \n",
       "2    899        800            800    326.93780         3    80   146   \n",
       "3   3732       1160           1160    422.93790         8   172    84   \n",
       "4   4180        920            920    530.93800         8   104   106   \n",
       "\n",
       "    r2_stuns  r2_creeps_stacked  r2_camps_stacked  r2_rune_pickups  \\\n",
       "0  89.179440                  0                 0               13   \n",
       "1  28.359995                  2                 1                9   \n",
       "2   0.000000                  0                 0                0   \n",
       "3   0.000000                  0                 0                1   \n",
       "4   0.499924                  0                 0                4   \n",
       "\n",
       "   r2_firstblood_claimed  r2_teamfight_participation  r2_towers_killed  \\\n",
       "0                      0                    0.647059                 1   \n",
       "1                      0                    0.687500                 0   \n",
       "2                      0                    0.666667                 0   \n",
       "3                      0                    0.333333                 0   \n",
       "4                      1                    0.666667                 0   \n",
       "\n",
       "   r2_roshans_killed  r2_obs_placed  r2_sen_placed  r3_hero_id  r3_kills  \\\n",
       "0                  0              5              4          76         8   \n",
       "1                  0              0              0          20         4   \n",
       "2                  0              0              0          14         0   \n",
       "3                  0              0              0          41         2   \n",
       "4                  0              3              2         106         2   \n",
       "\n",
       "   r3_deaths  r3_assists  r3_denies  r3_gold  r3_lh  r3_xp  r3_health  \\\n",
       "0          1           4          9    10232    119  11261       1950   \n",
       "1          4           7          3     4047      4   4231        310   \n",
       "2          0           1          0      603      1    559        760   \n",
       "3          1           0          0     3502     11   3952       1160   \n",
       "4          3           3         23     8155    119   7723       1080   \n",
       "\n",
       "   r3_max_health  r3_max_mana  r3_level  r3_x  r3_y   r3_stuns  \\\n",
       "0           1950   1564.93900        15   152   138  44.355835   \n",
       "1            960    600.93805         8    74    74   8.078904   \n",
       "2            760    254.93774         2   166    84   0.000000   \n",
       "3           1160    386.93787         8    86   144   4.132328   \n",
       "4           1080    566.93805        13    76   102  11.263947   \n",
       "\n",
       "   r3_creeps_stacked  r3_camps_stacked  r3_rune_pickups  \\\n",
       "0                  0                 0                0   \n",
       "1                  0                 0                4   \n",
       "2                  0                 0                1   \n",
       "3                  0                 0                4   \n",
       "4                  3                 1                3   \n",
       "\n",
       "   r3_firstblood_claimed  r3_teamfight_participation  r3_towers_killed  \\\n",
       "0                      0                    0.705882                 1   \n",
       "1                      0                    0.687500                 0   \n",
       "2                      0                    0.333333                 0   \n",
       "3                      0                    0.666667                 0   \n",
       "4                      0                    0.555556                 1   \n",
       "\n",
       "   r3_roshans_killed  r3_obs_placed  r3_sen_placed  r4_hero_id  r4_kills  \\\n",
       "0                  0              0              0          26         2   \n",
       "1                  0              4              2          11         3   \n",
       "2                  0              0              0          94         0   \n",
       "3                  0              0              0          32         0   \n",
       "4                  0              0              0          11         1   \n",
       "\n",
       "   r4_deaths  r4_assists  r4_denies  r4_gold  r4_lh  r4_xp  r4_health  \\\n",
       "0          2          10          0     5053      8   5073        179   \n",
       "1          1           3         10     7225    126   9017        824   \n",
       "2          0           0          0      654      5   1076        518   \n",
       "3          1           2          1     3144     11   4244        248   \n",
       "4          7           0         13     6327    108   7407       1100   \n",
       "\n",
       "   r4_max_health  r4_max_mana  r4_level  r4_x  r4_y   r4_stuns  \\\n",
       "0            920    770.93823         9   146   138  62.519253   \n",
       "1           1140    878.93835        14   120   100   5.065430   \n",
       "2            560    374.93787         3   122   120   0.000000   \n",
       "3            800    350.93784         8    86   148   0.000000   \n",
       "4           1100    614.93810        12   104   110   0.000000   \n",
       "\n",
       "   r4_creeps_stacked  r4_camps_stacked  r4_rune_pickups  \\\n",
       "0                  0                 0                7   \n",
       "1                 10                 4                0   \n",
       "2                  0                 0                0   \n",
       "3                  0                 0                3   \n",
       "4                  0                 0                0   \n",
       "\n",
       "   r4_firstblood_claimed  r4_teamfight_participation  r4_towers_killed  \\\n",
       "0                      1                    0.705882                 1   \n",
       "1                      0                    0.375000                 0   \n",
       "2                      0                    0.000000                 0   \n",
       "3                      0                    0.666667                 0   \n",
       "4                      0                    0.111111                 0   \n",
       "\n",
       "   r4_roshans_killed  r4_obs_placed  r4_sen_placed  r5_hero_id  r5_kills  \\\n",
       "0                  0              4              2          63         0   \n",
       "1                  0              0              0          48         4   \n",
       "2                  0              1              2          97         0   \n",
       "3                  0              0              0          91         0   \n",
       "4                  0              2              0          27         2   \n",
       "\n",
       "   r5_deaths  r5_assists  r5_denies  r5_gold  r5_lh  r5_xp  r5_health  \\\n",
       "0          2          11          3     6319     52   7160          0   \n",
       "1          4           9         21     6427     74   8017       1116   \n",
       "2          1           1          2      781      7    502        670   \n",
       "3          1           1          1     2366      3   3076          0   \n",
       "4          4           5          1     4112     19   4397       1140   \n",
       "\n",
       "   r5_max_health  r5_max_mana  r5_level  r5_x  r5_y   r5_stuns  \\\n",
       "0           1180    518.93800        12   142   136   0.000000   \n",
       "1           1120    590.93805        13    96   132  12.316595   \n",
       "2            700    314.93780         2   172    84   2.666016   \n",
       "3            840    494.93796         7   166    88   0.000000   \n",
       "4           1140    864.93835         9    84    90  19.761868   \n",
       "\n",
       "   r5_creeps_stacked  r5_camps_stacked  r5_rune_pickups  \\\n",
       "0                  0                 0                5   \n",
       "1                  0                 0                0   \n",
       "2                  0                 0                1   \n",
       "3                  0                 0                4   \n",
       "4                  0                 0                3   \n",
       "\n",
       "   r5_firstblood_claimed  r5_teamfight_participation  r5_towers_killed  \\\n",
       "0                      0                    0.647059                 1   \n",
       "1                      0                    0.812500                 0   \n",
       "2                      0                    0.333333                 0   \n",
       "3                      0                    0.333333                 0   \n",
       "4                      0                    0.777778                 1   \n",
       "\n",
       "   r5_roshans_killed  r5_obs_placed  r5_sen_placed  d1_hero_id  d1_kills  \\\n",
       "0                  0              0              0          44         4   \n",
       "1                  0              0              0          90         3   \n",
       "2                  0              0              0          59         0   \n",
       "3                  0              0              0          39         1   \n",
       "4                  0              2              1         120         1   \n",
       "\n",
       "   d1_deaths  d1_assists  d1_denies  d1_gold  d1_lh  d1_xp  d1_health  \\\n",
       "0          2           1         21    12678    169  11676        594   \n",
       "1          5           5          0     5736     48   4536        823   \n",
       "2          0           1          0      626      3    602        663   \n",
       "3          1           1          0     2894      6   3375        760   \n",
       "4          4           3          7     6268     61   6194       1080   \n",
       "\n",
       "   d1_max_health  d1_max_mana  d1_level  d1_x  d1_y  d1_stuns  \\\n",
       "0           1340    566.93805        16   146   140  0.000000   \n",
       "1            840    782.93823         9   140   108  1.532959   \n",
       "2            760    350.93784         3   176    90  0.000000   \n",
       "3            760    984.93840         7    96   156  0.000000   \n",
       "4           1080    780.93823        11   154    86 -0.816772   \n",
       "\n",
       "   d1_creeps_stacked  d1_camps_stacked  d1_rune_pickups  \\\n",
       "0                  0                 0                7   \n",
       "1                  0                 0               12   \n",
       "2                  0                 0                2   \n",
       "3                  0                 0                1   \n",
       "4                  0                 0                8   \n",
       "\n",
       "   d1_firstblood_claimed  d1_teamfight_participation  d1_towers_killed  \\\n",
       "0                      0                    0.625000                 1   \n",
       "1                      0                    0.615385                 0   \n",
       "2                      0                    0.333333                 0   \n",
       "3                      0                    0.333333                 0   \n",
       "4                      0                    0.190476                 0   \n",
       "\n",
       "   d1_roshans_killed  d1_obs_placed  d1_sen_placed  d2_hero_id  d2_kills  \\\n",
       "0                  0              0              0          36         1   \n",
       "1                  0              4              0          14         3   \n",
       "2                  0              0              0          88         1   \n",
       "3                  0              0              0          14         1   \n",
       "4                  0              1              0          39         8   \n",
       "\n",
       "   d2_deaths  d2_assists  d2_denies  d2_gold  d2_lh  d2_xp  d2_health  \\\n",
       "0          3           4         14     6683     59   8200       1670   \n",
       "1          7           5          3     4025     22   4687       1340   \n",
       "2          1           0          2      823      6    562        593   \n",
       "3          1           2          0     2072      2   3947        723   \n",
       "4          0           4         11    10251    111   9444       1305   \n",
       "\n",
       "   d2_max_health  d2_max_mana  d2_level  d2_x  d2_y   d2_stuns  \\\n",
       "0           1675   1017.93850        13   156   154   3.099145   \n",
       "1           1340    434.93793         9   136   116  14.563202   \n",
       "2            600    314.93780         2   174    88   1.566272   \n",
       "3           1220    386.93787         8   174    94   4.965462   \n",
       "4           1540   1154.93860        14   126   144   0.000000   \n",
       "\n",
       "   d2_creeps_stacked  d2_camps_stacked  d2_rune_pickups  \\\n",
       "0                  0                 0                5   \n",
       "1                  0                 0                5   \n",
       "2                  0                 0                0   \n",
       "3                  0                 0                0   \n",
       "4                  0                 0                8   \n",
       "\n",
       "   d2_firstblood_claimed  d2_teamfight_participation  d2_towers_killed  \\\n",
       "0                      0                    0.625000                 0   \n",
       "1                      0                    0.615385                 0   \n",
       "2                      0                    0.333333                 0   \n",
       "3                      0                    0.500000                 0   \n",
       "4                      0                    0.571429                 1   \n",
       "\n",
       "   d2_roshans_killed  d2_obs_placed  d2_sen_placed  d3_hero_id  d3_kills  \\\n",
       "0                  0              3              2          11         1   \n",
       "1                  0              0              1          46         6   \n",
       "2                  0              0              0          95         0   \n",
       "3                  0              0              0          11         2   \n",
       "4                  0              1              1         119         1   \n",
       "\n",
       "   d3_deaths  d3_assists  d3_denies  d3_gold  d3_lh  d3_xp  d3_health  \\\n",
       "0          3           3         19     8032    140   9487       1080   \n",
       "1          1           0         21     7133     81   8052       1220   \n",
       "2          0           0          4      717     10   1262        475   \n",
       "3          0           0          9     6052     42   8566       1105   \n",
       "4          0           4          3     3550     15   4418        880   \n",
       "\n",
       "   d3_max_health  d3_max_mana  d3_level  d3_x  d3_y   d3_stuns  \\\n",
       "0           1080    602.93805        14   182   176   0.000000   \n",
       "1           1220    662.93810        13   130   128   0.000000   \n",
       "2            740    266.93774         4   128   132   0.000000   \n",
       "3           1340    758.93823        13   146   122   2.532715   \n",
       "4            880    876.93835         9   128   130  12.796868   \n",
       "\n",
       "   d3_creeps_stacked  d3_camps_stacked  d3_rune_pickups  \\\n",
       "0                 16                 4                4   \n",
       "1                  0                 0                5   \n",
       "2                  0                 0                0   \n",
       "3                  0                 0                2   \n",
       "4                  0                 0                5   \n",
       "\n",
       "   d3_firstblood_claimed  d3_teamfight_participation  d3_towers_killed  \\\n",
       "0                      0                    0.500000                 0   \n",
       "1                      0                    0.461538                 1   \n",
       "2                      0                    0.000000                 0   \n",
       "3                      1                    0.333333                 0   \n",
       "4                      0                    0.238095                 0   \n",
       "\n",
       "   d3_roshans_killed  d3_obs_placed  d3_sen_placed  d4_hero_id  d4_kills  \\\n",
       "0                  0              0              0           3         2   \n",
       "1                  0              0              0          54         1   \n",
       "2                  0              1              0          44         2   \n",
       "3                  0              0              0           7         1   \n",
       "4                  0              6              7          12         5   \n",
       "\n",
       "   d4_deaths  d4_assists  d4_denies  d4_gold  d4_lh  d4_xp  d4_health  \\\n",
       "0          5           1          6     4794     11   5069       1080   \n",
       "1          0           1         55     8309    131   8684       1037   \n",
       "2          0           0          2     1467      9   1053        286   \n",
       "3          1           1          1     2396     10   3339       1020   \n",
       "4          1           5         20    11252    166  11686       1645   \n",
       "\n",
       "   d4_max_health  d4_max_mana  d4_level  d4_x  d4_y   d4_stuns  \\\n",
       "0           1080    852.93830         9   158   160  31.858887   \n",
       "1           1480    530.93800        13   106   156   0.000000   \n",
       "2            680    278.93777         3    94   172   0.000000   \n",
       "3           1020    636.93810         7    80   166  18.196856   \n",
       "4           1890    866.93835        16    76   116   0.000000   \n",
       "\n",
       "   d4_creeps_stacked  d4_camps_stacked  d4_rune_pickups  \\\n",
       "0                  0                 0                2   \n",
       "1                  0                 0                1   \n",
       "2                  0                 0                1   \n",
       "3                  0                 0                0   \n",
       "4                  0                 0                3   \n",
       "\n",
       "   d4_firstblood_claimed  d4_teamfight_participation  d4_towers_killed  \\\n",
       "0                      0                    0.375000                 0   \n",
       "1                      0                    0.153846                 0   \n",
       "2                      1                    0.666667                 0   \n",
       "3                      0                    0.333333                 0   \n",
       "4                      0                    0.476190                 1   \n",
       "\n",
       "   d4_roshans_killed  d4_obs_placed  d4_sen_placed  d5_hero_id  d5_kills  \\\n",
       "0                  0              1              2          84         0   \n",
       "1                  0              0              0          40         0   \n",
       "2                  0              0              0          62         0   \n",
       "3                  0              0              0          95         1   \n",
       "4                  0              0              0          14         4   \n",
       "\n",
       "   d5_deaths  d5_assists  d5_denies  d5_gold  d5_lh  d5_xp  d5_health  \\\n",
       "0          4           2          1     4225     10   4661       1340   \n",
       "1          4           9          1     3215     14   3985        980   \n",
       "2          2           2          0      384      0    204        600   \n",
       "3          1           1          4     3352     19   3926        420   \n",
       "4          5          10          0     5867     21   6803       1403   \n",
       "\n",
       "   d5_max_health  d5_max_mana  d5_level  d5_x  d5_y   d5_stuns  \\\n",
       "0           1340    470.93796         9   146   140  11.797119   \n",
       "1            980    614.93810         8   142   110   0.000000   \n",
       "2            600    338.93784         2   168   170   0.000000   \n",
       "3            940    314.93780         8   174    88   0.766487   \n",
       "4           1880    944.93840        12   124   128  16.362675   \n",
       "\n",
       "   d5_creeps_stacked  d5_camps_stacked  d5_rune_pickups  \\\n",
       "0                 17                 5                6   \n",
       "1                  6                 2                2   \n",
       "2                  0                 0                0   \n",
       "3                  0                 0                1   \n",
       "4                  0                 0                7   \n",
       "\n",
       "   d5_firstblood_claimed  d5_teamfight_participation  d5_towers_killed  \\\n",
       "0                      0                    0.250000                 0   \n",
       "1                      0                    0.692308                 0   \n",
       "2                      0                    0.666667                 0   \n",
       "3                      0                    0.333333                 0   \n",
       "4                      0                    0.666667                 0   \n",
       "\n",
       "   d5_roshans_killed  d5_obs_placed  d5_sen_placed  \n",
       "0                  0              3              1  \n",
       "1                  0              3              3  \n",
       "2                  0              1              0  \n",
       "3                  0              0              0  \n",
       "4                  0              0              3  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id_hash</th>\n",
       "      <th>game_time</th>\n",
       "      <th>radiant_win</th>\n",
       "      <th>duration</th>\n",
       "      <th>time_remaining</th>\n",
       "      <th>next_roshan_team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000c270e25494c03d5c81036463fc45</td>\n",
       "      <td>1304</td>\n",
       "      <td>True</td>\n",
       "      <td>1893</td>\n",
       "      <td>589</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000cbef31e13f297dbbe47d84a08169</td>\n",
       "      <td>1056</td>\n",
       "      <td>True</td>\n",
       "      <td>2137</td>\n",
       "      <td>1081</td>\n",
       "      <td>Radiant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000432b654aee6e8792ce17bb19ccf16</td>\n",
       "      <td>170</td>\n",
       "      <td>True</td>\n",
       "      <td>1889</td>\n",
       "      <td>1719</td>\n",
       "      <td>Radiant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000a2ba6b82a4a1829ca226a880ec993</td>\n",
       "      <td>393</td>\n",
       "      <td>True</td>\n",
       "      <td>1376</td>\n",
       "      <td>983</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000a9891b8b7712e9a19e032b583023e</td>\n",
       "      <td>1142</td>\n",
       "      <td>False</td>\n",
       "      <td>1728</td>\n",
       "      <td>586</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      match_id_hash  game_time  radiant_win  duration  \\\n",
       "0  0000c270e25494c03d5c81036463fc45       1304         True      1893   \n",
       "1  0000cbef31e13f297dbbe47d84a08169       1056         True      2137   \n",
       "2  000432b654aee6e8792ce17bb19ccf16        170         True      1889   \n",
       "3  000a2ba6b82a4a1829ca226a880ec993        393         True      1376   \n",
       "4  000a9891b8b7712e9a19e032b583023e       1142        False      1728   \n",
       "\n",
       "   time_remaining next_roshan_team  \n",
       "0             589             None  \n",
       "1            1081          Radiant  \n",
       "2            1719          Radiant  \n",
       "3             983             None  \n",
       "4             586             None  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.set_index('match_id_hash', inplace=True)\n",
    "df_target.set_index('match_id_hash', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "game_mode\n",
       "22    26990\n",
       "4      3028\n",
       "23     2171\n",
       "3      1018\n",
       "2       358\n",
       "5       152\n",
       "12        4\n",
       "16        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features['game_mode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = df_features['game_mode'].value_counts().plot(kind='bar', title='Количество игр в разных режимах')\n",
    "ax.set_xlabel(\"Режим игры\")\n",
    "ax.set_ylabel(\"Колличесво\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features['radiant_win'] = df_target['radiant_win']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_features['game_time'], bins=60, label='Train');\n",
    "plt.hist(df_test['game_time'], bins=60, label='Test');\n",
    "plt.title('Распределене игрового времени');\n",
    "plt.legend()\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_features.loc[df_features['radiant_win'] == True, 'r1_gold'], bins=60, label='Золото r1_игрока победившей команды')\n",
    "plt.hist(df_features.loc[df_features['radiant_win'] == False, 'r1_gold'], bins=60, label='Золото r1_игрока проигравшей команды')\n",
    "plt.hist(df_test['r1_gold'], bins=60, label='Золото игрока r1 в тестовых данных')\n",
    "plt.title('Распределение игрового времени')\n",
    "plt.legend()\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# подготовка к обучению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features['radiant_win'] = df_features['radiant_win'].astype(int)\n",
    "df_target['radiant_win'] = df_target['radiant_win'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_features.copy()\n",
    "test = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_features.drop(['radiant_win'], axis=1).reset_index(drop=True)\n",
    "y = df_target['radiant_win']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n",
    "                                                      test_size=0.3, \n",
    "                                                      random_state=43, stratify= y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:33:03,277] A new study created in memory with name: no-name-bf64da2d-d02e-444d-8a09-2db1df31e4c5\n",
      "[I 2024-11-08 13:33:04,817] Trial 0 finished with value: 0.7771299115237785 and parameters: {'learning_rate': 0.017353869718512598, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.7216423777735153, 'colsample_bytree': 0.7963313109755115, 'lambda': 0.3215708104893683, 'alpha': 6.647759753469571e-05}. Best is trial 0 with value: 0.7771299115237785.\n",
      "[I 2024-11-08 13:33:05,610] Trial 1 finished with value: 0.7865999839736573 and parameters: {'learning_rate': 0.2799370164827341, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.6148671098983227, 'colsample_bytree': 0.5172211471609297, 'lambda': 0.01910952936271195, 'alpha': 0.02185668777933813}. Best is trial 1 with value: 0.7865999839736573.\n",
      "[I 2024-11-08 13:33:07,300] Trial 2 finished with value: 0.7910314322325784 and parameters: {'learning_rate': 0.06989410719278097, 'max_depth': 7, 'min_child_weight': 4, 'subsample': 0.6089213659146069, 'colsample_bytree': 0.5285970197185212, 'lambda': 0.023876198114577075, 'alpha': 0.000371910616737567}. Best is trial 2 with value: 0.7910314322325784.\n",
      "[I 2024-11-08 13:33:09,298] Trial 3 finished with value: 0.7755438636535785 and parameters: {'learning_rate': 0.19552399162255188, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.8179717115968848, 'colsample_bytree': 0.9896439526417367, 'lambda': 1.2127360081198524e-08, 'alpha': 0.0005438668590025047}. Best is trial 2 with value: 0.7910314322325784.\n",
      "[I 2024-11-08 13:33:10,209] Trial 4 finished with value: 0.7730213596056738 and parameters: {'learning_rate': 0.23406053421590742, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.7904458441054485, 'colsample_bytree': 0.8568023700205811, 'lambda': 0.47351820486494506, 'alpha': 1.863097750782525e-08}. Best is trial 2 with value: 0.7910314322325784.\n",
      "[I 2024-11-08 13:33:11,682] Trial 5 finished with value: 0.7847019472319741 and parameters: {'learning_rate': 0.043875067747549575, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.9681742104534732, 'colsample_bytree': 0.5691197306696227, 'lambda': 8.848642281160119e-06, 'alpha': 0.001451436171472712}. Best is trial 2 with value: 0.7910314322325784.\n",
      "[I 2024-11-08 13:33:12,965] Trial 6 finished with value: 0.7882728412003277 and parameters: {'learning_rate': 0.16229965054447829, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.9046133500405017, 'colsample_bytree': 0.9122793858627243, 'lambda': 0.09642559334114283, 'alpha': 0.030827917347950644}. Best is trial 2 with value: 0.7910314322325784.\n",
      "[I 2024-11-08 13:33:14,181] Trial 7 finished with value: 0.7913575988559416 and parameters: {'learning_rate': 0.1887029768423554, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.6931129746902183, 'colsample_bytree': 0.5074296144867277, 'lambda': 1.8515669497415164e-06, 'alpha': 0.0003777932441822752}. Best is trial 7 with value: 0.7913575988559416.\n",
      "[I 2024-11-08 13:33:15,310] Trial 8 finished with value: 0.774157557591634 and parameters: {'learning_rate': 0.19643027203667304, 'max_depth': 9, 'min_child_weight': 4, 'subsample': 0.6755958559475465, 'colsample_bytree': 0.5742153914205078, 'lambda': 0.003216044267834735, 'alpha': 0.005851582534538694}. Best is trial 7 with value: 0.7913575988559416.\n",
      "[I 2024-11-08 13:33:16,767] Trial 9 finished with value: 0.7905882991562043 and parameters: {'learning_rate': 0.09855534105928829, 'max_depth': 3, 'min_child_weight': 4, 'subsample': 0.5552653967905636, 'colsample_bytree': 0.5476027345287627, 'lambda': 1.1754840283247753e-08, 'alpha': 1.3097127293923047e-08}. Best is trial 7 with value: 0.7913575988559416.\n",
      "[I 2024-11-08 13:33:18,032] Trial 10 finished with value: 0.7955470657889202 and parameters: {'learning_rate': 0.12874050807794676, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.7043712518383239, 'colsample_bytree': 0.6778196333530182, 'lambda': 8.865745538727885e-06, 'alpha': 0.557443727478282}. Best is trial 10 with value: 0.7955470657889202.\n",
      "[I 2024-11-08 13:33:19,014] Trial 11 finished with value: 0.7894699996028662 and parameters: {'learning_rate': 0.12796740581118504, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.7060934482678363, 'colsample_bytree': 0.6683661140305369, 'lambda': 1.1003398285789523e-05, 'alpha': 0.6679323534523794}. Best is trial 10 with value: 0.7955470657889202.\n",
      "[I 2024-11-08 13:33:19,957] Trial 12 finished with value: 0.7887089833134127 and parameters: {'learning_rate': 0.12823977884243012, 'max_depth': 5, 'min_child_weight': 8, 'subsample': 0.5161545779601855, 'colsample_bytree': 0.678391427116513, 'lambda': 1.6154854248095616e-06, 'alpha': 0.1595499285571972}. Best is trial 10 with value: 0.7955470657889202.\n",
      "[I 2024-11-08 13:33:21,248] Trial 13 finished with value: 0.7937135339017855 and parameters: {'learning_rate': 0.16153333815666976, 'max_depth': 3, 'min_child_weight': 7, 'subsample': 0.7817020418143892, 'colsample_bytree': 0.6595125197315738, 'lambda': 0.0003054279946804289, 'alpha': 0.853208248269659}. Best is trial 10 with value: 0.7955470657889202.\n",
      "[I 2024-11-08 13:33:21,764] Trial 14 finished with value: 0.7506574834521745 and parameters: {'learning_rate': 0.09386126524442548, 'max_depth': 3, 'min_child_weight': 10, 'subsample': 0.7986589528101511, 'colsample_bytree': 0.70832183090214, 'lambda': 0.0006506119242693774, 'alpha': 0.8716774622289571}. Best is trial 10 with value: 0.7955470657889202.\n",
      "[I 2024-11-08 13:33:23,081] Trial 15 finished with value: 0.7967263845064274 and parameters: {'learning_rate': 0.1339624521899971, 'max_depth': 4, 'min_child_weight': 8, 'subsample': 0.8612153169963153, 'colsample_bytree': 0.6325653818633424, 'lambda': 0.00010730351936371698, 'alpha': 0.9275827419866541}. Best is trial 15 with value: 0.7967263845064274.\n",
      "[I 2024-11-08 13:33:24,458] Trial 16 finished with value: 0.7925229552294011 and parameters: {'learning_rate': 0.10886982458255079, 'max_depth': 6, 'min_child_weight': 9, 'subsample': 0.8916469394133842, 'colsample_bytree': 0.6161667958948676, 'lambda': 3.1003894012976274e-05, 'alpha': 0.10312415310361517}. Best is trial 15 with value: 0.7967263845064274.\n",
      "[I 2024-11-08 13:33:25,733] Trial 17 finished with value: 0.7961516568269673 and parameters: {'learning_rate': 0.13662969320800739, 'max_depth': 4, 'min_child_weight': 8, 'subsample': 0.8375065685998138, 'colsample_bytree': 0.7422111478143637, 'lambda': 0.0001006824164409772, 'alpha': 0.04904093802946183}. Best is trial 15 with value: 0.7967263845064274.\n",
      "[I 2024-11-08 13:33:27,356] Trial 18 finished with value: 0.7922284339748752 and parameters: {'learning_rate': 0.06982657981888038, 'max_depth': 4, 'min_child_weight': 8, 'subsample': 0.858632023899233, 'colsample_bytree': 0.7489080501112046, 'lambda': 9.027090152948153e-05, 'alpha': 0.014330833924643729}. Best is trial 15 with value: 0.7967263845064274.\n",
      "[I 2024-11-08 13:33:28,664] Trial 19 finished with value: 0.7924039521932473 and parameters: {'learning_rate': 0.15604019732848845, 'max_depth': 4, 'min_child_weight': 6, 'subsample': 0.9787218634723449, 'colsample_bytree': 0.7539028715001702, 'lambda': 0.0019746754960916183, 'alpha': 0.09874166261806794}. Best is trial 15 with value: 0.7967263845064274.\n",
      "[I 2024-11-08 13:33:29,431] Trial 20 finished with value: 0.7669504031690487 and parameters: {'learning_rate': 0.012107958499396401, 'max_depth': 6, 'min_child_weight': 8, 'subsample': 0.846424213618315, 'colsample_bytree': 0.5938472982100813, 'lambda': 0.00019793878791127658, 'alpha': 0.004508102686666182}. Best is trial 15 with value: 0.7967263845064274.\n",
      "[I 2024-11-08 13:33:30,218] Trial 21 finished with value: 0.7835784191430669 and parameters: {'learning_rate': 0.1307022841934716, 'max_depth': 4, 'min_child_weight': 9, 'subsample': 0.7639231464454678, 'colsample_bytree': 0.6348799487707556, 'lambda': 7.281681538409133e-05, 'alpha': 0.210552868176854}. Best is trial 15 with value: 0.7967263845064274.\n",
      "[I 2024-11-08 13:33:31,220] Trial 22 finished with value: 0.783932392959344 and parameters: {'learning_rate': 0.1361036519823502, 'max_depth': 6, 'min_child_weight': 10, 'subsample': 0.7497797963336963, 'colsample_bytree': 0.7112837232334607, 'lambda': 2.876647015277035e-05, 'alpha': 0.07499380729258769}. Best is trial 15 with value: 0.7967263845064274.\n",
      "[I 2024-11-08 13:33:32,724] Trial 23 finished with value: 0.7963557263744019 and parameters: {'learning_rate': 0.10894286158819935, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.8379607009373837, 'colsample_bytree': 0.6280545181866128, 'lambda': 0.0008251422509873178, 'alpha': 0.9355623665757974}. Best is trial 15 with value: 0.7967263845064274.\n",
      "[I 2024-11-08 13:33:34,036] Trial 24 finished with value: 0.7863999484274485 and parameters: {'learning_rate': 0.08498561604303763, 'max_depth': 3, 'min_child_weight': 7, 'subsample': 0.9177073063052776, 'colsample_bytree': 0.623956388328214, 'lambda': 0.001696993551536207, 'alpha': 0.20707428958489105}. Best is trial 15 with value: 0.7967263845064274.\n",
      "[I 2024-11-08 13:33:35,464] Trial 25 finished with value: 0.7955770466426888 and parameters: {'learning_rate': 0.10434748046100634, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.8367824944497356, 'colsample_bytree': 0.6021737088903666, 'lambda': 0.00040886525821282304, 'alpha': 0.024410428730592446}. Best is trial 15 with value: 0.7967263845064274.\n",
      "[I 2024-11-08 13:33:38,350] Trial 26 finished with value: 0.7930627868400071 and parameters: {'learning_rate': 0.07042300018005429, 'max_depth': 10, 'min_child_weight': 8, 'subsample': 0.8782682150040435, 'colsample_bytree': 0.6257995427864488, 'lambda': 0.006723008344716395, 'alpha': 0.8226708398928356}. Best is trial 15 with value: 0.7967263845064274.\n",
      "[I 2024-11-08 13:33:39,398] Trial 27 finished with value: 0.7893793716530029 and parameters: {'learning_rate': 0.17591731226157503, 'max_depth': 4, 'min_child_weight': 5, 'subsample': 0.8296958614834719, 'colsample_bytree': 0.5508843550506779, 'lambda': 0.0008033042886289429, 'alpha': 0.0601991513939179}. Best is trial 15 with value: 0.7967263845064274.\n",
      "[I 2024-11-08 13:33:39,939] Trial 28 finished with value: 0.7544187000317473 and parameters: {'learning_rate': 0.1475409574506762, 'max_depth': 3, 'min_child_weight': 6, 'subsample': 0.9307401563021062, 'colsample_bytree': 0.5848016420238347, 'lambda': 0.00020834200350582175, 'alpha': 0.33022824765053616}. Best is trial 15 with value: 0.7967263845064274.\n",
      "[I 2024-11-08 13:33:42,198] Trial 29 finished with value: 0.7947627854535637 and parameters: {'learning_rate': 0.04710839041021493, 'max_depth': 6, 'min_child_weight': 9, 'subsample': 0.8629162316793204, 'colsample_bytree': 0.8107546292607991, 'lambda': 0.08903210954615598, 'alpha': 2.8969522457228894e-05}. Best is trial 15 with value: 0.7967263845064274.\n",
      "[I 2024-11-08 13:33:43,378] Trial 30 finished with value: 0.7937671312870008 and parameters: {'learning_rate': 0.1155569631971476, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.8163377174037669, 'colsample_bytree': 0.7192430868094821, 'lambda': 0.005665902448444728, 'alpha': 0.17893029372102956}. Best is trial 15 with value: 0.7967263845064274.\n",
      "[I 2024-11-08 13:33:44,939] Trial 31 finished with value: 0.7983001345476488 and parameters: {'learning_rate': 0.11265487727473895, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.8388518529105767, 'colsample_bytree': 0.6462073456520846, 'lambda': 0.0010074038134853386, 'alpha': 0.025498800548601666}. Best is trial 31 with value: 0.7983001345476488.\n",
      "[I 2024-11-08 13:33:46,137] Trial 32 finished with value: 0.7908423433207631 and parameters: {'learning_rate': 0.14274120002955326, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.8647225875138732, 'colsample_bytree': 0.6417465322289665, 'lambda': 0.0015705191546394656, 'alpha': 0.04475830990083744}. Best is trial 31 with value: 0.7983001345476488.\n",
      "[I 2024-11-08 13:33:47,547] Trial 33 finished with value: 0.7926604441740837 and parameters: {'learning_rate': 0.1085255429383703, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.7444903711103948, 'colsample_bytree': 0.6466934484005415, 'lambda': 0.012277123717658989, 'alpha': 0.012531502505174184}. Best is trial 31 with value: 0.7983001345476488.\n",
      "[I 2024-11-08 13:33:48,831] Trial 34 finished with value: 0.7928867986409098 and parameters: {'learning_rate': 0.11859328803846345, 'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.8036883389141589, 'colsample_bytree': 0.6900705299727388, 'lambda': 0.0008456552894738113, 'alpha': 0.32677025231913004}. Best is trial 31 with value: 0.7983001345476488.\n",
      "[I 2024-11-08 13:33:50,206] Trial 35 finished with value: 0.7958442698500864 and parameters: {'learning_rate': 0.14558515242090608, 'max_depth': 4, 'min_child_weight': 6, 'subsample': 0.9419632603542185, 'colsample_bytree': 0.6517579436923653, 'lambda': 0.00018200055323284021, 'alpha': 0.04848522215947585}. Best is trial 31 with value: 0.7983001345476488.\n",
      "[I 2024-11-08 13:33:51,139] Trial 36 finished with value: 0.7736591626149759 and parameters: {'learning_rate': 0.28296017394301265, 'max_depth': 8, 'min_child_weight': 7, 'subsample': 0.8892347763004866, 'colsample_bytree': 0.5984639813918677, 'lambda': 0.024174859227475025, 'alpha': 0.24682549084980004}. Best is trial 31 with value: 0.7983001345476488.\n",
      "[I 2024-11-08 13:33:52,722] Trial 37 finished with value: 0.7963078470880112 and parameters: {'learning_rate': 0.09109013595494288, 'max_depth': 5, 'min_child_weight': 8, 'subsample': 0.8240726575961199, 'colsample_bytree': 0.5289184488232015, 'lambda': 0.0004904159286857734, 'alpha': 0.006342249873777925}. Best is trial 31 with value: 0.7983001345476488.\n",
      "[I 2024-11-08 13:33:54,381] Trial 38 finished with value: 0.7961789352915654 and parameters: {'learning_rate': 0.08690375772118729, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.810844465728614, 'colsample_bytree': 0.5251906565025907, 'lambda': 0.003700829063043691, 'alpha': 0.001941162682375173}. Best is trial 31 with value: 0.7983001345476488.\n",
      "[I 2024-11-08 13:33:55,572] Trial 39 finished with value: 0.78152861779217 and parameters: {'learning_rate': 0.03969354546033139, 'max_depth': 7, 'min_child_weight': 6, 'subsample': 0.7792391937962339, 'colsample_bytree': 0.500880630901878, 'lambda': 0.0009156417498046416, 'alpha': 0.01179543346344742}. Best is trial 31 with value: 0.7983001345476488.\n",
      "[I 2024-11-08 13:33:56,989] Trial 40 finished with value: 0.7944518148736524 and parameters: {'learning_rate': 0.11263628076512135, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.9076926664109435, 'colsample_bytree': 0.5403657065415844, 'lambda': 0.7741772770264362, 'alpha': 0.022795300994177384}. Best is trial 31 with value: 0.7983001345476488.\n",
      "[I 2024-11-08 13:33:58,514] Trial 41 finished with value: 0.7952558343994716 and parameters: {'learning_rate': 0.0953769616330983, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.8123078421436979, 'colsample_bytree': 0.5236084198174162, 'lambda': 0.0030911701453767634, 'alpha': 0.0021423185420016465}. Best is trial 31 with value: 0.7983001345476488.\n",
      "[I 2024-11-08 13:34:00,256] Trial 42 finished with value: 0.7970399399803283 and parameters: {'learning_rate': 0.07642329124998992, 'max_depth': 6, 'min_child_weight': 7, 'subsample': 0.8284152264582854, 'colsample_bytree': 0.5551598729990961, 'lambda': 0.005031446465844005, 'alpha': 0.0008838996188199452}. Best is trial 31 with value: 0.7983001345476488.\n",
      "[I 2024-11-08 13:34:01,982] Trial 43 finished with value: 0.7960480652420976 and parameters: {'learning_rate': 0.07547125573400493, 'max_depth': 6, 'min_child_weight': 7, 'subsample': 0.8749284936163606, 'colsample_bytree': 0.567348136097353, 'lambda': 0.008914121697911913, 'alpha': 0.0007010653732981068}. Best is trial 31 with value: 0.7983001345476488.\n",
      "[I 2024-11-08 13:34:04,156] Trial 44 finished with value: 0.7967351574799666 and parameters: {'learning_rate': 0.06139908626606436, 'max_depth': 8, 'min_child_weight': 8, 'subsample': 0.8435657299720362, 'colsample_bytree': 0.5627496286440545, 'lambda': 0.03093378076157521, 'alpha': 0.00571163746964683}. Best is trial 31 with value: 0.7983001345476488.\n",
      "[I 2024-11-08 13:34:07,005] Trial 45 finished with value: 0.7961978911808195 and parameters: {'learning_rate': 0.046334101207941625, 'max_depth': 8, 'min_child_weight': 7, 'subsample': 0.8492099222532802, 'colsample_bytree': 0.5641857203231007, 'lambda': 0.02976572126711333, 'alpha': 0.00016569527627580875}. Best is trial 31 with value: 0.7983001345476488.\n",
      "[I 2024-11-08 13:34:09,680] Trial 46 finished with value: 0.795747003422478 and parameters: {'learning_rate': 0.0652598331899692, 'max_depth': 9, 'min_child_weight': 6, 'subsample': 0.8914718585811411, 'colsample_bytree': 0.6068274895321182, 'lambda': 0.07159464400931406, 'alpha': 0.46577586416423045}. Best is trial 31 with value: 0.7983001345476488.\n",
      "[I 2024-11-08 13:34:11,259] Trial 47 finished with value: 0.7835912261178315 and parameters: {'learning_rate': 0.02660611266648992, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.7865066756201713, 'colsample_bytree': 0.5674574555571633, 'lambda': 0.20221546843011257, 'alpha': 0.10122584451582708}. Best is trial 31 with value: 0.7983001345476488.\n",
      "[I 2024-11-08 13:34:12,956] Trial 48 finished with value: 0.7846784090306483 and parameters: {'learning_rate': 0.05595691640002272, 'max_depth': 9, 'min_child_weight': 8, 'subsample': 0.8481725062286735, 'colsample_bytree': 0.5909003644323741, 'lambda': 0.018321941111427063, 'alpha': 0.9639355541398124}. Best is trial 31 with value: 0.7983001345476488.\n",
      "[I 2024-11-08 13:34:14,672] Trial 49 finished with value: 0.7946103354557925 and parameters: {'learning_rate': 0.07967267269667626, 'max_depth': 7, 'min_child_weight': 7, 'subsample': 0.9471990366351499, 'colsample_bytree': 0.6255801962791036, 'lambda': 0.005273904484308201, 'alpha': 0.0009142887917949937}. Best is trial 31 with value: 0.7983001345476488.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'learning_rate': 0.11265487727473895, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.8388518529105767, 'colsample_bytree': 0.6462073456520846, 'lambda': 0.0010074038134853386, 'alpha': 0.025498800548601666}\n",
      "[0]\tvalidation_0-logloss:0.67901\n",
      "[1]\tvalidation_0-logloss:0.66859\n",
      "[2]\tvalidation_0-logloss:0.65898\n",
      "[3]\tvalidation_0-logloss:0.65065\n",
      "[4]\tvalidation_0-logloss:0.64334\n",
      "[5]\tvalidation_0-logloss:0.63661\n",
      "[6]\tvalidation_0-logloss:0.63067\n",
      "[7]\tvalidation_0-logloss:0.62581\n",
      "[8]\tvalidation_0-logloss:0.62108\n",
      "[9]\tvalidation_0-logloss:0.61724\n",
      "[10]\tvalidation_0-logloss:0.61284\n",
      "[11]\tvalidation_0-logloss:0.60940\n",
      "[12]\tvalidation_0-logloss:0.60610\n",
      "[13]\tvalidation_0-logloss:0.60329\n",
      "[14]\tvalidation_0-logloss:0.59973\n",
      "[15]\tvalidation_0-logloss:0.59703\n",
      "[16]\tvalidation_0-logloss:0.59446\n",
      "[17]\tvalidation_0-logloss:0.59202\n",
      "[18]\tvalidation_0-logloss:0.59001\n",
      "[19]\tvalidation_0-logloss:0.58740\n",
      "[20]\tvalidation_0-logloss:0.58560\n",
      "[21]\tvalidation_0-logloss:0.58384\n",
      "[22]\tvalidation_0-logloss:0.58205\n",
      "[23]\tvalidation_0-logloss:0.58058\n",
      "[24]\tvalidation_0-logloss:0.57904\n",
      "[25]\tvalidation_0-logloss:0.57704\n",
      "[26]\tvalidation_0-logloss:0.57523\n",
      "[27]\tvalidation_0-logloss:0.57417\n",
      "[28]\tvalidation_0-logloss:0.57294\n",
      "[29]\tvalidation_0-logloss:0.57176\n",
      "[30]\tvalidation_0-logloss:0.57084\n",
      "[31]\tvalidation_0-logloss:0.57003\n",
      "[32]\tvalidation_0-logloss:0.56901\n",
      "[33]\tvalidation_0-logloss:0.56808\n",
      "[34]\tvalidation_0-logloss:0.56700\n",
      "[35]\tvalidation_0-logloss:0.56639\n",
      "[36]\tvalidation_0-logloss:0.56532\n",
      "[37]\tvalidation_0-logloss:0.56436\n",
      "[38]\tvalidation_0-logloss:0.56322\n",
      "[39]\tvalidation_0-logloss:0.56236\n",
      "[40]\tvalidation_0-logloss:0.56151\n",
      "[41]\tvalidation_0-logloss:0.56078\n",
      "[42]\tvalidation_0-logloss:0.55967\n",
      "[43]\tvalidation_0-logloss:0.55880\n",
      "[44]\tvalidation_0-logloss:0.55794\n",
      "[45]\tvalidation_0-logloss:0.55733\n",
      "[46]\tvalidation_0-logloss:0.55682\n",
      "[47]\tvalidation_0-logloss:0.55621\n",
      "[48]\tvalidation_0-logloss:0.55570\n",
      "[49]\tvalidation_0-logloss:0.55515\n",
      "[50]\tvalidation_0-logloss:0.55473\n",
      "[51]\tvalidation_0-logloss:0.55428\n",
      "[52]\tvalidation_0-logloss:0.55364\n",
      "[53]\tvalidation_0-logloss:0.55328\n",
      "[54]\tvalidation_0-logloss:0.55274\n",
      "[55]\tvalidation_0-logloss:0.55229\n",
      "[56]\tvalidation_0-logloss:0.55179\n",
      "[57]\tvalidation_0-logloss:0.55139\n",
      "[58]\tvalidation_0-logloss:0.55113\n",
      "[59]\tvalidation_0-logloss:0.55080\n",
      "[60]\tvalidation_0-logloss:0.55036\n",
      "[61]\tvalidation_0-logloss:0.54987\n",
      "[62]\tvalidation_0-logloss:0.54925\n",
      "[63]\tvalidation_0-logloss:0.54886\n",
      "[64]\tvalidation_0-logloss:0.54840\n",
      "[65]\tvalidation_0-logloss:0.54802\n",
      "[66]\tvalidation_0-logloss:0.54765\n",
      "[67]\tvalidation_0-logloss:0.54726\n",
      "[68]\tvalidation_0-logloss:0.54657\n",
      "[69]\tvalidation_0-logloss:0.54624\n",
      "[70]\tvalidation_0-logloss:0.54598\n",
      "[71]\tvalidation_0-logloss:0.54564\n",
      "[72]\tvalidation_0-logloss:0.54526\n",
      "[73]\tvalidation_0-logloss:0.54462\n",
      "[74]\tvalidation_0-logloss:0.54440\n",
      "[75]\tvalidation_0-logloss:0.54407\n",
      "[76]\tvalidation_0-logloss:0.54393\n",
      "[77]\tvalidation_0-logloss:0.54369\n",
      "[78]\tvalidation_0-logloss:0.54339\n",
      "[79]\tvalidation_0-logloss:0.54314\n",
      "[80]\tvalidation_0-logloss:0.54280\n",
      "[81]\tvalidation_0-logloss:0.54254\n",
      "[82]\tvalidation_0-logloss:0.54239\n",
      "[83]\tvalidation_0-logloss:0.54217\n",
      "[84]\tvalidation_0-logloss:0.54213\n",
      "[85]\tvalidation_0-logloss:0.54196\n",
      "[86]\tvalidation_0-logloss:0.54170\n",
      "[87]\tvalidation_0-logloss:0.54140\n",
      "[88]\tvalidation_0-logloss:0.54090\n",
      "[89]\tvalidation_0-logloss:0.54069\n",
      "[90]\tvalidation_0-logloss:0.54056\n",
      "[91]\tvalidation_0-logloss:0.54031\n",
      "[92]\tvalidation_0-logloss:0.54016\n",
      "[93]\tvalidation_0-logloss:0.54003\n",
      "[94]\tvalidation_0-logloss:0.53976\n",
      "[95]\tvalidation_0-logloss:0.53957\n",
      "[96]\tvalidation_0-logloss:0.53944\n",
      "[97]\tvalidation_0-logloss:0.53921\n",
      "[98]\tvalidation_0-logloss:0.53888\n",
      "[99]\tvalidation_0-logloss:0.53864\n",
      "Validation ROC-AUC score: 0.7983001345476488\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Функция для оптимизации гиперпараметров\n",
    "def optimize_xgb(trial):\n",
    "    param = {\n",
    "        'tree_method': 'hist',\n",
    "        'early_stopping_rounds': 2,\n",
    "        'eval_metric': 'auc',\n",
    "        'objective': 'binary:logistic',\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'lambda': trial.suggest_float('lambda', 1e-8, 1.0, log=True),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-8, 1.0, log=True)\n",
    "    }\n",
    "\n",
    "    clf = xgb.XGBClassifier(**param, use_label_encoder=False)\n",
    "    clf.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=False)\n",
    "    \n",
    "    y_pred = clf.predict_proba(X_valid)[:, 1]\n",
    "    roc_auc = roc_auc_score(y_valid, y_pred)\n",
    "    return roc_auc\n",
    "\n",
    "# Оптимизация гиперпараметров\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(optimize_xgb, n_trials=50)\n",
    "\n",
    "# Обучение модели с лучшими параметрами\n",
    "best_params = study.best_params\n",
    "print(f\"Лучшие параметры: {best_params}\")\n",
    "\n",
    "clf = xgb.XGBClassifier(**best_params, tree_method=\"hist\", early_stopping_rounds=2, use_label_encoder=False)\n",
    "clf.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=True)\n",
    "\n",
    "# Предсказание и оценка модели\n",
    "y_pred_clf = clf.predict_proba(X_valid)[:, 1]\n",
    "valid_score_clf = roc_auc_score(y_valid, y_pred_clf)\n",
    "print('Validation ROC-AUC score:', valid_score_clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.copy()\n",
    "y_test_pred_clf = clf.predict_proba(X_test)[:, 1]\n",
    "df_submission_clf = pd.DataFrame({'radiant_win_prob': y_test_pred_clf}, \n",
    "                                 index=df_test.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radiant_win_prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>match_id_hash</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ee84861e709fc9cf5d48ba0f04b7f43b</th>\n",
       "      <td>0.905217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a9475ee47c8a10d6cf37c1461814653e</th>\n",
       "      <td>0.326050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b56ea18db1408fc68263757232c1facb</th>\n",
       "      <td>0.518637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9587640246910f0e1b033a6c8f6d8211</th>\n",
       "      <td>0.379845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3eb93fbd9056ebdb52ffff84e6c3664a</th>\n",
       "      <td>0.444800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  radiant_win_prob\n",
       "match_id_hash                                     \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b          0.905217\n",
       "a9475ee47c8a10d6cf37c1461814653e          0.326050\n",
       "b56ea18db1408fc68263757232c1facb          0.518637\n",
       "9587640246910f0e1b033a6c8f6d8211          0.379845\n",
       "3eb93fbd9056ebdb52ffff84e6c3664a          0.444800"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission_clf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:34:22,512] A new study created in memory with name: no-name-555cbbed-8d2e-476c-8331-4f319d43ae65\n",
      "[I 2024-11-08 13:34:28,842] Trial 0 finished with value: 0.7776796758544062 and parameters: {'n_estimators': 62, 'max_depth': 11, 'min_samples_split': 14, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.7776796758544062.\n",
      "[I 2024-11-08 13:34:40,052] Trial 1 finished with value: 0.7742070476210205 and parameters: {'n_estimators': 175, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 13}. Best is trial 0 with value: 0.7776796758544062.\n",
      "[I 2024-11-08 13:34:57,960] Trial 2 finished with value: 0.7841222530115085 and parameters: {'n_estimators': 166, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 2 with value: 0.7841222530115085.\n",
      "[I 2024-11-08 13:35:13,523] Trial 3 finished with value: 0.7820974891523271 and parameters: {'n_estimators': 161, 'max_depth': 11, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.7841222530115085.\n",
      "[I 2024-11-08 13:35:23,497] Trial 4 finished with value: 0.7798911997078478 and parameters: {'n_estimators': 88, 'max_depth': 14, 'min_samples_split': 18, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.7841222530115085.\n",
      "[I 2024-11-08 13:35:37,055] Trial 5 finished with value: 0.7821769985978044 and parameters: {'n_estimators': 119, 'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 2 with value: 0.7841222530115085.\n",
      "[I 2024-11-08 13:35:45,129] Trial 6 finished with value: 0.7800977736637373 and parameters: {'n_estimators': 87, 'max_depth': 12, 'min_samples_split': 12, 'min_samples_leaf': 19}. Best is trial 2 with value: 0.7841222530115085.\n",
      "[I 2024-11-08 13:35:49,579] Trial 7 finished with value: 0.7747069658244298 and parameters: {'n_estimators': 52, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 13}. Best is trial 2 with value: 0.7841222530115085.\n",
      "[I 2024-11-08 13:36:02,358] Trial 8 finished with value: 0.7830444106195208 and parameters: {'n_estimators': 131, 'max_depth': 18, 'min_samples_split': 14, 'min_samples_leaf': 18}. Best is trial 2 with value: 0.7841222530115085.\n",
      "[I 2024-11-08 13:36:06,621] Trial 9 finished with value: 0.766447563419478 and parameters: {'n_estimators': 72, 'max_depth': 6, 'min_samples_split': 17, 'min_samples_leaf': 10}. Best is trial 2 with value: 0.7841222530115085.\n",
      "[I 2024-11-08 13:36:28,019] Trial 10 finished with value: 0.7859443981521551 and parameters: {'n_estimators': 200, 'max_depth': 16, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 10 with value: 0.7859443981521551.\n",
      "[I 2024-11-08 13:36:48,748] Trial 11 finished with value: 0.785851973661518 and parameters: {'n_estimators': 194, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 10 with value: 0.7859443981521551.\n",
      "[I 2024-11-08 13:37:08,417] Trial 12 finished with value: 0.7857490928304888 and parameters: {'n_estimators': 195, 'max_depth': 17, 'min_samples_split': 2, 'min_samples_leaf': 13}. Best is trial 10 with value: 0.7859443981521551.\n",
      "[I 2024-11-08 13:37:29,667] Trial 13 finished with value: 0.7859484950793996 and parameters: {'n_estimators': 199, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:37:49,790] Trial 14 finished with value: 0.7821876346079767 and parameters: {'n_estimators': 153, 'max_depth': 20, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:38:08,970] Trial 15 finished with value: 0.7837723940108141 and parameters: {'n_estimators': 198, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 15}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:38:23,485] Trial 16 finished with value: 0.7842061575167719 and parameters: {'n_estimators': 136, 'max_depth': 14, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:38:40,846] Trial 17 finished with value: 0.7842771871789413 and parameters: {'n_estimators': 179, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 11}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:38:51,585] Trial 18 finished with value: 0.783680060127258 and parameters: {'n_estimators': 112, 'max_depth': 16, 'min_samples_split': 12, 'min_samples_leaf': 16}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:39:07,119] Trial 19 finished with value: 0.7842301242594107 and parameters: {'n_estimators': 151, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 11}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:39:21,742] Trial 20 finished with value: 0.7790054709898134 and parameters: {'n_estimators': 182, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:39:42,346] Trial 21 finished with value: 0.7859447611472481 and parameters: {'n_estimators': 198, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:40:02,031] Trial 22 finished with value: 0.7846141678126729 and parameters: {'n_estimators': 186, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:40:21,912] Trial 23 finished with value: 0.7849630527379949 and parameters: {'n_estimators': 200, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:40:40,439] Trial 24 finished with value: 0.7849145420561894 and parameters: {'n_estimators': 171, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:40:58,977] Trial 25 finished with value: 0.7844382691561685 and parameters: {'n_estimators': 181, 'max_depth': 19, 'min_samples_split': 20, 'min_samples_leaf': 11}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:41:14,198] Trial 26 finished with value: 0.7844889465062708 and parameters: {'n_estimators': 147, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:41:33,751] Trial 27 finished with value: 0.784689533542863 and parameters: {'n_estimators': 189, 'max_depth': 13, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:41:50,163] Trial 28 finished with value: 0.7842267552687783 and parameters: {'n_estimators': 161, 'max_depth': 17, 'min_samples_split': 3, 'min_samples_leaf': 12}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:42:02,146] Trial 29 finished with value: 0.7807403194641773 and parameters: {'n_estimators': 103, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:42:19,094] Trial 30 finished with value: 0.7830864310474583 and parameters: {'n_estimators': 186, 'max_depth': 12, 'min_samples_split': 7, 'min_samples_leaf': 15}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:42:38,976] Trial 31 finished with value: 0.7858598712147907 and parameters: {'n_estimators': 192, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:42:57,565] Trial 32 finished with value: 0.7845706880496893 and parameters: {'n_estimators': 176, 'max_depth': 19, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:43:18,779] Trial 33 finished with value: 0.7846147785498497 and parameters: {'n_estimators': 200, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:43:37,751] Trial 34 finished with value: 0.7841091831436487 and parameters: {'n_estimators': 169, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:43:54,072] Trial 35 finished with value: 0.781368308174328 and parameters: {'n_estimators': 190, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:44:09,904] Trial 36 finished with value: 0.7837292557029044 and parameters: {'n_estimators': 161, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 12}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:44:28,455] Trial 37 finished with value: 0.7837818656267159 and parameters: {'n_estimators': 176, 'max_depth': 17, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:44:52,106] Trial 38 finished with value: 0.7842540732546627 and parameters: {'n_estimators': 192, 'max_depth': 19, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:45:09,006] Trial 39 finished with value: 0.7829146597537798 and parameters: {'n_estimators': 166, 'max_depth': 12, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:45:23,477] Trial 40 finished with value: 0.7838709260474561 and parameters: {'n_estimators': 138, 'max_depth': 15, 'min_samples_split': 15, 'min_samples_leaf': 8}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:45:44,676] Trial 41 finished with value: 0.7840338769454018 and parameters: {'n_estimators': 193, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:46:06,692] Trial 42 finished with value: 0.7859443981521551 and parameters: {'n_estimators': 200, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:46:29,126] Trial 43 finished with value: 0.7856350845410871 and parameters: {'n_estimators': 200, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:46:48,635] Trial 44 finished with value: 0.7845256279110032 and parameters: {'n_estimators': 185, 'max_depth': 17, 'min_samples_split': 6, 'min_samples_leaf': 12}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:47:08,562] Trial 45 finished with value: 0.7848265511678569 and parameters: {'n_estimators': 192, 'max_depth': 15, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:47:26,060] Trial 46 finished with value: 0.7845505171049278 and parameters: {'n_estimators': 173, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:47:29,770] Trial 47 finished with value: 0.7607619031238377 and parameters: {'n_estimators': 73, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 13}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:47:48,227] Trial 48 finished with value: 0.7846393606749101 and parameters: {'n_estimators': 182, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 13 with value: 0.7859484950793996.\n",
      "[I 2024-11-08 13:48:09,946] Trial 49 finished with value: 0.7855206121831053 and parameters: {'n_estimators': 194, 'max_depth': 16, 'min_samples_split': 12, 'min_samples_leaf': 5}. Best is trial 13 with value: 0.7859484950793996.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'n_estimators': 199, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 9}\n",
      "Validation ROC-AUC score: 0.7934781714710577\n"
     ]
    }
   ],
   "source": [
    "# Функция для оптимизации гиперпараметров\n",
    "def optimize_rf(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 20)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n",
    "    \n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        n_jobs=4,\n",
    "        random_state=43\n",
    "    )\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='roc_auc')\n",
    "    return scores.mean()\n",
    "\n",
    "# Оптимизация гиперпараметров\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(optimize_rf, n_trials=50)\n",
    "\n",
    "# Обучение модели с лучшими параметрами\n",
    "best_params = study.best_params\n",
    "print(f\"Лучшие параметры: {best_params}\")\n",
    "\n",
    "model = RandomForestClassifier(**best_params, n_jobs=4, random_state=43)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "valid_score = roc_auc_score(y_valid, y_pred)\n",
    "print('Validation ROC-AUC score:', valid_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.copy()\n",
    "y_test_pred = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission= pd.DataFrame({'ID' : df_test.index,\n",
    "                                 'Target': y_test_pred})\n",
    "df_submission.set_index('ID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ee84861e709fc9cf5d48ba0f04b7f43b</th>\n",
       "      <td>0.843226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a9475ee47c8a10d6cf37c1461814653e</th>\n",
       "      <td>0.299740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b56ea18db1408fc68263757232c1facb</th>\n",
       "      <td>0.607083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9587640246910f0e1b033a6c8f6d8211</th>\n",
       "      <td>0.301669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3eb93fbd9056ebdb52ffff84e6c3664a</th>\n",
       "      <td>0.509973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Target\n",
       "ID                                        \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b  0.843226\n",
       "a9475ee47c8a10d6cf37c1461814653e  0.299740\n",
       "b56ea18db1408fc68263757232c1facb  0.607083\n",
       "9587640246910f0e1b033a6c8f6d8211  0.301669\n",
       "3eb93fbd9056ebdb52ffff84e6c3664a  0.509973"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to submission_RF_2024-11-08.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "submission_filename = 'submission_RF_{}.csv'.format(\n",
    "    datetime.datetime.now().strftime('%Y-%m-%d'))\n",
    "df_submission.to_csv(submission_filename)\n",
    "print('Submission saved to {}'.format(submission_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:48:21,494] A new study created in memory with name: no-name-dea3e30e-db8e-430b-810d-bd8e7ec7bd6b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.635482\n",
      "[20]\tvalid_0's binary_logloss: 0.603829\n",
      "[30]\tvalid_0's binary_logloss: 0.583903\n",
      "[40]\tvalid_0's binary_logloss: 0.569818\n",
      "[50]\tvalid_0's binary_logloss: 0.559351\n",
      "[60]\tvalid_0's binary_logloss: 0.55165\n",
      "[70]\tvalid_0's binary_logloss: 0.545684\n",
      "[80]\tvalid_0's binary_logloss: 0.541519\n",
      "[90]\tvalid_0's binary_logloss: 0.538254\n",
      "[100]\tvalid_0's binary_logloss: 0.535181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:48:23,596] Trial 0 finished with value: 0.8016235640815977 and parameters: {'num_leaves': 103, 'learning_rate': 0.047639486709551274, 'n_estimators': 105}. Best is trial 0 with value: 0.8016235640815977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[105]\tvalid_0's binary_logloss: 0.534257\n",
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.653541\n",
      "[20]\tvalid_0's binary_logloss: 0.627413\n",
      "[30]\tvalid_0's binary_logloss: 0.609226\n",
      "[40]\tvalid_0's binary_logloss: 0.595756\n",
      "[50]\tvalid_0's binary_logloss: 0.585327\n",
      "[60]\tvalid_0's binary_logloss: 0.576778\n",
      "[70]\tvalid_0's binary_logloss: 0.569459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:48:24,838] Trial 1 finished with value: 0.7905857925923362 and parameters: {'num_leaves': 52, 'learning_rate': 0.031846297845759944, 'n_estimators': 94}. Best is trial 0 with value: 0.8016235640815977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80]\tvalid_0's binary_logloss: 0.563883\n",
      "[90]\tvalid_0's binary_logloss: 0.55881\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[94]\tvalid_0's binary_logloss: 0.556941\n",
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.638908\n",
      "[20]\tvalid_0's binary_logloss: 0.607651\n",
      "[30]\tvalid_0's binary_logloss: 0.587472\n",
      "[40]\tvalid_0's binary_logloss: 0.573506\n",
      "[50]\tvalid_0's binary_logloss: 0.562976\n",
      "[60]\tvalid_0's binary_logloss: 0.554581\n",
      "[70]\tvalid_0's binary_logloss: 0.548329\n",
      "[80]\tvalid_0's binary_logloss: 0.544146\n",
      "[90]\tvalid_0's binary_logloss: 0.540441\n",
      "[100]\tvalid_0's binary_logloss: 0.537456\n",
      "[110]\tvalid_0's binary_logloss: 0.534891\n",
      "[120]\tvalid_0's binary_logloss: 0.533173\n",
      "[130]\tvalid_0's binary_logloss: 0.53224\n",
      "[140]\tvalid_0's binary_logloss: 0.531429\n",
      "[150]\tvalid_0's binary_logloss: 0.530305\n",
      "[160]\tvalid_0's binary_logloss: 0.529704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:48:29,310] Trial 2 finished with value: 0.8041261331137375 and parameters: {'num_leaves': 137, 'learning_rate': 0.04223221967399604, 'n_estimators': 184}. Best is trial 2 with value: 0.8041261331137375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[170]\tvalid_0's binary_logloss: 0.52962\n",
      "Early stopping, best iteration is:\n",
      "[164]\tvalid_0's binary_logloss: 0.529583\n",
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022994 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.691011\n",
      "[20]\tvalid_0's binary_logloss: 0.689986\n",
      "[30]\tvalid_0's binary_logloss: 0.688981\n",
      "[40]\tvalid_0's binary_logloss: 0.687986\n",
      "[50]\tvalid_0's binary_logloss: 0.687009\n",
      "[60]\tvalid_0's binary_logloss: 0.686048\n",
      "[70]\tvalid_0's binary_logloss: 0.685095\n",
      "[80]\tvalid_0's binary_logloss: 0.684155\n",
      "[90]\tvalid_0's binary_logloss: 0.683222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:48:31,866] Trial 3 finished with value: 0.7277145714625667 and parameters: {'num_leaves': 142, 'learning_rate': 0.0006028726715611988, 'n_estimators': 101}. Best is trial 2 with value: 0.8041261331137375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.682291\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[101]\tvalid_0's binary_logloss: 0.682204\n",
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.667478\n",
      "[20]\tvalid_0's binary_logloss: 0.648441\n",
      "[30]\tvalid_0's binary_logloss: 0.633122\n",
      "[40]\tvalid_0's binary_logloss: 0.620166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:48:33,018] Trial 4 finished with value: 0.7779080037795849 and parameters: {'num_leaves': 115, 'learning_rate': 0.016806562150336723, 'n_estimators': 54}. Best is trial 2 with value: 0.8041261331137375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's binary_logloss: 0.609358\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[54]\tvalid_0's binary_logloss: 0.605606\n",
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020087 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.691826\n",
      "[20]\tvalid_0's binary_logloss: 0.691589\n",
      "[30]\tvalid_0's binary_logloss: 0.691352\n",
      "[40]\tvalid_0's binary_logloss: 0.691119\n",
      "[50]\tvalid_0's binary_logloss: 0.690887\n",
      "[60]\tvalid_0's binary_logloss: 0.690656\n",
      "[70]\tvalid_0's binary_logloss: 0.690426\n",
      "[80]\tvalid_0's binary_logloss: 0.690197\n",
      "[90]\tvalid_0's binary_logloss: 0.689968\n",
      "[100]\tvalid_0's binary_logloss: 0.689741\n",
      "[110]\tvalid_0's binary_logloss: 0.689515\n",
      "[120]\tvalid_0's binary_logloss: 0.689289\n",
      "[130]\tvalid_0's binary_logloss: 0.689063\n",
      "[140]\tvalid_0's binary_logloss: 0.688839\n",
      "[150]\tvalid_0's binary_logloss: 0.688615\n",
      "[160]\tvalid_0's binary_logloss: 0.688392\n",
      "[170]\tvalid_0's binary_logloss: 0.68817\n",
      "[180]\tvalid_0's binary_logloss: 0.687947\n",
      "[190]\tvalid_0's binary_logloss: 0.687726\n",
      "[200]\tvalid_0's binary_logloss: 0.687506\n",
      "[210]\tvalid_0's binary_logloss: 0.687287\n",
      "[220]\tvalid_0's binary_logloss: 0.687069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:48:38,993] Trial 5 finished with value: 0.7236681549128534 and parameters: {'num_leaves': 147, 'learning_rate': 0.00013517198392197792, 'n_estimators': 231}. Best is trial 2 with value: 0.8041261331137375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[230]\tvalid_0's binary_logloss: 0.686851\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[231]\tvalid_0's binary_logloss: 0.68683\n",
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.691427\n",
      "[20]\tvalid_0's binary_logloss: 0.690803\n",
      "[30]\tvalid_0's binary_logloss: 0.690185\n",
      "[40]\tvalid_0's binary_logloss: 0.689575\n",
      "[50]\tvalid_0's binary_logloss: 0.688969\n",
      "[60]\tvalid_0's binary_logloss: 0.688371\n",
      "[70]\tvalid_0's binary_logloss: 0.687777\n",
      "[80]\tvalid_0's binary_logloss: 0.687188\n",
      "[90]\tvalid_0's binary_logloss: 0.686606\n",
      "[100]\tvalid_0's binary_logloss: 0.686023\n",
      "[110]\tvalid_0's binary_logloss: 0.685446\n",
      "[120]\tvalid_0's binary_logloss: 0.684881\n",
      "[130]\tvalid_0's binary_logloss: 0.684318\n",
      "[140]\tvalid_0's binary_logloss: 0.683759\n",
      "[150]\tvalid_0's binary_logloss: 0.683208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:48:41,215] Trial 6 finished with value: 0.7248474736303606 and parameters: {'num_leaves': 34, 'learning_rate': 0.0004376326306016291, 'n_estimators': 169}. Best is trial 2 with value: 0.8041261331137375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[160]\tvalid_0's binary_logloss: 0.682658\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[169]\tvalid_0's binary_logloss: 0.682168\n",
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024817 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.691573\n",
      "[20]\tvalid_0's binary_logloss: 0.691088\n",
      "[30]\tvalid_0's binary_logloss: 0.690612\n",
      "[40]\tvalid_0's binary_logloss: 0.690139\n",
      "[50]\tvalid_0's binary_logloss: 0.689669\n",
      "[60]\tvalid_0's binary_logloss: 0.689203\n",
      "[70]\tvalid_0's binary_logloss: 0.68874\n",
      "[80]\tvalid_0's binary_logloss: 0.688281\n",
      "[90]\tvalid_0's binary_logloss: 0.687823\n",
      "[100]\tvalid_0's binary_logloss: 0.68737\n",
      "[110]\tvalid_0's binary_logloss: 0.686918\n",
      "[120]\tvalid_0's binary_logloss: 0.68647\n",
      "[130]\tvalid_0's binary_logloss: 0.686024\n",
      "[140]\tvalid_0's binary_logloss: 0.685581\n",
      "[150]\tvalid_0's binary_logloss: 0.68514\n",
      "[160]\tvalid_0's binary_logloss: 0.684701\n",
      "[170]\tvalid_0's binary_logloss: 0.684265\n",
      "[180]\tvalid_0's binary_logloss: 0.683834\n",
      "[190]\tvalid_0's binary_logloss: 0.683404\n",
      "[200]\tvalid_0's binary_logloss: 0.682974\n",
      "[210]\tvalid_0's binary_logloss: 0.682549\n",
      "[220]\tvalid_0's binary_logloss: 0.682122\n",
      "[230]\tvalid_0's binary_logloss: 0.681701\n",
      "[240]\tvalid_0's binary_logloss: 0.68128\n",
      "[250]\tvalid_0's binary_logloss: 0.680864\n",
      "[260]\tvalid_0's binary_logloss: 0.680451\n",
      "[270]\tvalid_0's binary_logloss: 0.680037\n",
      "[280]\tvalid_0's binary_logloss: 0.679625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:48:47,744] Trial 7 finished with value: 0.7335478547298977 and parameters: {'num_leaves': 117, 'learning_rate': 0.00028303840128577137, 'n_estimators': 286}. Best is trial 2 with value: 0.8041261331137375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[286]\tvalid_0's binary_logloss: 0.679378\n",
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.689451\n",
      "[20]\tvalid_0's binary_logloss: 0.686932\n",
      "[30]\tvalid_0's binary_logloss: 0.684486\n",
      "[40]\tvalid_0's binary_logloss: 0.682148\n",
      "[50]\tvalid_0's binary_logloss: 0.679874\n",
      "[60]\tvalid_0's binary_logloss: 0.677677\n",
      "[70]\tvalid_0's binary_logloss: 0.675542\n",
      "[80]\tvalid_0's binary_logloss: 0.673422\n",
      "[90]\tvalid_0's binary_logloss: 0.671372\n",
      "[100]\tvalid_0's binary_logloss: 0.669373\n",
      "[110]\tvalid_0's binary_logloss: 0.667405\n",
      "[120]\tvalid_0's binary_logloss: 0.665484\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[122]\tvalid_0's binary_logloss: 0.665097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:48:49,354] Trial 8 finished with value: 0.7524404728288084 and parameters: {'num_leaves': 58, 'learning_rate': 0.001692937202223443, 'n_estimators': 122}. Best is trial 2 with value: 0.8041261331137375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.691848\n",
      "[20]\tvalid_0's binary_logloss: 0.691634\n",
      "[30]\tvalid_0's binary_logloss: 0.691421\n",
      "[40]\tvalid_0's binary_logloss: 0.69121\n",
      "[50]\tvalid_0's binary_logloss: 0.691001\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[58]\tvalid_0's binary_logloss: 0.690834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:48:50,683] Trial 9 finished with value: 0.7191916472518934 and parameters: {'num_leaves': 86, 'learning_rate': 0.0001283944821105211, 'n_estimators': 58}. Best is trial 2 with value: 0.8041261331137375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.606277\n",
      "[20]\tvalid_0's binary_logloss: 0.573331\n",
      "[30]\tvalid_0's binary_logloss: 0.555074\n",
      "[40]\tvalid_0's binary_logloss: 0.544876\n",
      "[50]\tvalid_0's binary_logloss: 0.540329\n",
      "[60]\tvalid_0's binary_logloss: 0.536803\n",
      "[70]\tvalid_0's binary_logloss: 0.535014\n",
      "[80]\tvalid_0's binary_logloss: 0.535003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:48:52,546] Trial 10 finished with value: 0.7997067868584928 and parameters: {'num_leaves': 126, 'learning_rate': 0.08908253879922662, 'n_estimators': 196}. Best is trial 2 with value: 0.8041261331137375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's binary_logloss: 0.534875\n",
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027202 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.677827\n",
      "[20]\tvalid_0's binary_logloss: 0.66562\n",
      "[30]\tvalid_0's binary_logloss: 0.654919\n",
      "[40]\tvalid_0's binary_logloss: 0.645403\n",
      "[50]\tvalid_0's binary_logloss: 0.636888\n",
      "[60]\tvalid_0's binary_logloss: 0.629242\n",
      "[70]\tvalid_0's binary_logloss: 0.622382\n",
      "[80]\tvalid_0's binary_logloss: 0.616078\n",
      "[90]\tvalid_0's binary_logloss: 0.610505\n",
      "[100]\tvalid_0's binary_logloss: 0.605387\n",
      "[110]\tvalid_0's binary_logloss: 0.600634\n",
      "[120]\tvalid_0's binary_logloss: 0.596405\n",
      "[130]\tvalid_0's binary_logloss: 0.592459\n",
      "[140]\tvalid_0's binary_logloss: 0.588733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:48:55,801] Trial 11 finished with value: 0.7831040910960507 and parameters: {'num_leaves': 84, 'learning_rate': 0.00956060772919152, 'n_estimators': 156}. Best is trial 2 with value: 0.8041261331137375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150]\tvalid_0's binary_logloss: 0.585389\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[156]\tvalid_0's binary_logloss: 0.583463\n",
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018286 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.611465\n",
      "[20]\tvalid_0's binary_logloss: 0.578907\n",
      "[30]\tvalid_0's binary_logloss: 0.560359\n",
      "[40]\tvalid_0's binary_logloss: 0.550169\n",
      "[50]\tvalid_0's binary_logloss: 0.543991\n",
      "[60]\tvalid_0's binary_logloss: 0.540636\n",
      "[70]\tvalid_0's binary_logloss: 0.538571\n",
      "[80]\tvalid_0's binary_logloss: 0.536604\n",
      "[90]\tvalid_0's binary_logloss: 0.53589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:48:58,016] Trial 12 finished with value: 0.7978594101224918 and parameters: {'num_leaves': 94, 'learning_rate': 0.0838153294857598, 'n_estimators': 226}. Best is trial 2 with value: 0.8041261331137375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.536314\n",
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's binary_logloss: 0.535793\n",
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.682263\n",
      "[20]\tvalid_0's binary_logloss: 0.673617\n",
      "[30]\tvalid_0's binary_logloss: 0.665651\n",
      "[40]\tvalid_0's binary_logloss: 0.658444\n",
      "[50]\tvalid_0's binary_logloss: 0.651763\n",
      "[60]\tvalid_0's binary_logloss: 0.645567\n",
      "[70]\tvalid_0's binary_logloss: 0.639808\n",
      "[80]\tvalid_0's binary_logloss: 0.634464\n",
      "[90]\tvalid_0's binary_logloss: 0.629459\n",
      "[100]\tvalid_0's binary_logloss: 0.624735\n",
      "[110]\tvalid_0's binary_logloss: 0.620386\n",
      "[120]\tvalid_0's binary_logloss: 0.616257\n",
      "[130]\tvalid_0's binary_logloss: 0.612371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:49:01,312] Trial 13 finished with value: 0.7764788903065771 and parameters: {'num_leaves': 103, 'learning_rate': 0.006207504376830482, 'n_estimators': 143}. Best is trial 2 with value: 0.8041261331137375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[140]\tvalid_0's binary_logloss: 0.608733\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[143]\tvalid_0's binary_logloss: 0.60771\n",
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.640235\n",
      "[20]\tvalid_0's binary_logloss: 0.609453\n",
      "[30]\tvalid_0's binary_logloss: 0.589507\n",
      "[40]\tvalid_0's binary_logloss: 0.575493\n",
      "[50]\tvalid_0's binary_logloss: 0.565346\n",
      "[60]\tvalid_0's binary_logloss: 0.556743\n",
      "[70]\tvalid_0's binary_logloss: 0.550507\n",
      "[80]\tvalid_0's binary_logloss: 0.545657\n",
      "[90]\tvalid_0's binary_logloss: 0.541684\n",
      "[100]\tvalid_0's binary_logloss: 0.538724\n",
      "[110]\tvalid_0's binary_logloss: 0.536105\n",
      "[120]\tvalid_0's binary_logloss: 0.533979\n",
      "[130]\tvalid_0's binary_logloss: 0.53252\n",
      "[140]\tvalid_0's binary_logloss: 0.531491\n",
      "[150]\tvalid_0's binary_logloss: 0.531092\n",
      "[160]\tvalid_0's binary_logloss: 0.530447\n",
      "[170]\tvalid_0's binary_logloss: 0.529682\n",
      "[180]\tvalid_0's binary_logloss: 0.529336\n",
      "[190]\tvalid_0's binary_logloss: 0.528597\n",
      "[200]\tvalid_0's binary_logloss: 0.52843\n",
      "[210]\tvalid_0's binary_logloss: 0.528863\n",
      "Early stopping, best iteration is:\n",
      "[200]\tvalid_0's binary_logloss: 0.52843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:49:06,493] Trial 14 finished with value: 0.8047220686734269 and parameters: {'num_leaves': 135, 'learning_rate': 0.04117527965872779, 'n_estimators': 213}. Best is trial 14 with value: 0.8047220686734269.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019509 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.663307\n",
      "[20]\tvalid_0's binary_logloss: 0.641829\n",
      "[30]\tvalid_0's binary_logloss: 0.625198\n",
      "[40]\tvalid_0's binary_logloss: 0.611964\n",
      "[50]\tvalid_0's binary_logloss: 0.600948\n",
      "[60]\tvalid_0's binary_logloss: 0.591873\n",
      "[70]\tvalid_0's binary_logloss: 0.584263\n",
      "[80]\tvalid_0's binary_logloss: 0.577877\n",
      "[90]\tvalid_0's binary_logloss: 0.572172\n",
      "[100]\tvalid_0's binary_logloss: 0.566886\n",
      "[110]\tvalid_0's binary_logloss: 0.562543\n",
      "[120]\tvalid_0's binary_logloss: 0.558744\n",
      "[130]\tvalid_0's binary_logloss: 0.555384\n",
      "[140]\tvalid_0's binary_logloss: 0.552414\n",
      "[150]\tvalid_0's binary_logloss: 0.549652\n",
      "[160]\tvalid_0's binary_logloss: 0.547224\n",
      "[170]\tvalid_0's binary_logloss: 0.544998\n",
      "[180]\tvalid_0's binary_logloss: 0.543067\n",
      "[190]\tvalid_0's binary_logloss: 0.541221\n",
      "[200]\tvalid_0's binary_logloss: 0.539755\n",
      "[210]\tvalid_0's binary_logloss: 0.538419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:49:11,679] Trial 15 finished with value: 0.7997060427223445 and parameters: {'num_leaves': 132, 'learning_rate': 0.019803129202571705, 'n_estimators': 218}. Best is trial 14 with value: 0.8047220686734269.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[218]\tvalid_0's binary_logloss: 0.537679\n",
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031868 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.684536\n",
      "[20]\tvalid_0's binary_logloss: 0.677586\n",
      "[30]\tvalid_0's binary_logloss: 0.671233\n",
      "[40]\tvalid_0's binary_logloss: 0.665112\n",
      "[50]\tvalid_0's binary_logloss: 0.65948\n",
      "[60]\tvalid_0's binary_logloss: 0.654219\n",
      "[70]\tvalid_0's binary_logloss: 0.649176\n",
      "[80]\tvalid_0's binary_logloss: 0.644487\n",
      "[90]\tvalid_0's binary_logloss: 0.640033\n",
      "[100]\tvalid_0's binary_logloss: 0.635835\n",
      "[110]\tvalid_0's binary_logloss: 0.631902\n",
      "[120]\tvalid_0's binary_logloss: 0.628089\n",
      "[130]\tvalid_0's binary_logloss: 0.624509\n",
      "[140]\tvalid_0's binary_logloss: 0.621052\n",
      "[150]\tvalid_0's binary_logloss: 0.617836\n",
      "[160]\tvalid_0's binary_logloss: 0.614773\n",
      "[170]\tvalid_0's binary_logloss: 0.611837\n",
      "[180]\tvalid_0's binary_logloss: 0.608992\n",
      "[190]\tvalid_0's binary_logloss: 0.606277\n",
      "[200]\tvalid_0's binary_logloss: 0.603716\n",
      "[210]\tvalid_0's binary_logloss: 0.601286\n",
      "[220]\tvalid_0's binary_logloss: 0.598936\n",
      "[230]\tvalid_0's binary_logloss: 0.59672\n",
      "[240]\tvalid_0's binary_logloss: 0.594583\n",
      "[250]\tvalid_0's binary_logloss: 0.5925\n",
      "[260]\tvalid_0's binary_logloss: 0.590512\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[267]\tvalid_0's binary_logloss: 0.589147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:49:18,967] Trial 16 finished with value: 0.7823111552823366 and parameters: {'num_leaves': 148, 'learning_rate': 0.004559806752459132, 'n_estimators': 267}. Best is trial 14 with value: 0.8047220686734269.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.648086\n",
      "[20]\tvalid_0's binary_logloss: 0.620149\n",
      "[30]\tvalid_0's binary_logloss: 0.60132\n",
      "[40]\tvalid_0's binary_logloss: 0.586999\n",
      "[50]\tvalid_0's binary_logloss: 0.576618\n",
      "[60]\tvalid_0's binary_logloss: 0.567939\n",
      "[70]\tvalid_0's binary_logloss: 0.561133\n",
      "[80]\tvalid_0's binary_logloss: 0.555406\n",
      "[90]\tvalid_0's binary_logloss: 0.550796\n",
      "[100]\tvalid_0's binary_logloss: 0.547317\n",
      "[110]\tvalid_0's binary_logloss: 0.544084\n",
      "[120]\tvalid_0's binary_logloss: 0.541235\n",
      "[130]\tvalid_0's binary_logloss: 0.538797\n",
      "[140]\tvalid_0's binary_logloss: 0.536954\n",
      "[150]\tvalid_0's binary_logloss: 0.535415\n",
      "[160]\tvalid_0's binary_logloss: 0.534074\n",
      "[170]\tvalid_0's binary_logloss: 0.532835\n",
      "[180]\tvalid_0's binary_logloss: 0.531817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:49:22,365] Trial 17 finished with value: 0.8032347755031319 and parameters: {'num_leaves': 68, 'learning_rate': 0.036100302942450695, 'n_estimators': 197}. Best is trial 14 with value: 0.8047220686734269.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[190]\tvalid_0's binary_logloss: 0.531303\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[197]\tvalid_0's binary_logloss: 0.530878\n",
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.675251\n",
      "[20]\tvalid_0's binary_logloss: 0.661211\n",
      "[30]\tvalid_0's binary_logloss: 0.649154\n",
      "[40]\tvalid_0's binary_logloss: 0.638517\n",
      "[50]\tvalid_0's binary_logloss: 0.629294\n",
      "[60]\tvalid_0's binary_logloss: 0.621087\n",
      "[70]\tvalid_0's binary_logloss: 0.613745\n",
      "[80]\tvalid_0's binary_logloss: 0.607263\n",
      "[90]\tvalid_0's binary_logloss: 0.601346\n",
      "[100]\tvalid_0's binary_logloss: 0.59595\n",
      "[110]\tvalid_0's binary_logloss: 0.591153\n",
      "[120]\tvalid_0's binary_logloss: 0.586909\n",
      "[130]\tvalid_0's binary_logloss: 0.582839\n",
      "[140]\tvalid_0's binary_logloss: 0.579159\n",
      "[150]\tvalid_0's binary_logloss: 0.575779\n",
      "[160]\tvalid_0's binary_logloss: 0.57243\n",
      "[170]\tvalid_0's binary_logloss: 0.569633\n",
      "[180]\tvalid_0's binary_logloss: 0.56689\n",
      "[190]\tvalid_0's binary_logloss: 0.564299\n",
      "[200]\tvalid_0's binary_logloss: 0.5619\n",
      "[210]\tvalid_0's binary_logloss: 0.559625\n",
      "[220]\tvalid_0's binary_logloss: 0.557823\n",
      "[230]\tvalid_0's binary_logloss: 0.555973\n",
      "[240]\tvalid_0's binary_logloss: 0.554029\n",
      "[250]\tvalid_0's binary_logloss: 0.552294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:49:27,760] Trial 18 finished with value: 0.794351983134585 and parameters: {'num_leaves': 128, 'learning_rate': 0.010859592972111374, 'n_estimators': 254}. Best is trial 14 with value: 0.8047220686734269.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[254]\tvalid_0's binary_logloss: 0.551637\n",
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.688847\n",
      "[20]\tvalid_0's binary_logloss: 0.6858\n",
      "[30]\tvalid_0's binary_logloss: 0.682854\n",
      "[40]\tvalid_0's binary_logloss: 0.680035\n",
      "[50]\tvalid_0's binary_logloss: 0.677308\n",
      "[60]\tvalid_0's binary_logloss: 0.674676\n",
      "[70]\tvalid_0's binary_logloss: 0.672121\n",
      "[80]\tvalid_0's binary_logloss: 0.669595\n",
      "[90]\tvalid_0's binary_logloss: 0.667148\n",
      "[100]\tvalid_0's binary_logloss: 0.664791\n",
      "[110]\tvalid_0's binary_logloss: 0.662486\n",
      "[120]\tvalid_0's binary_logloss: 0.660243\n",
      "[130]\tvalid_0's binary_logloss: 0.658061\n",
      "[140]\tvalid_0's binary_logloss: 0.655912\n",
      "[150]\tvalid_0's binary_logloss: 0.653804\n",
      "[160]\tvalid_0's binary_logloss: 0.651773\n",
      "[170]\tvalid_0's binary_logloss: 0.649789\n",
      "[180]\tvalid_0's binary_logloss: 0.64786\n",
      "[190]\tvalid_0's binary_logloss: 0.645958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:49:31,749] Trial 19 finished with value: 0.764956940757598 and parameters: {'num_leaves': 113, 'learning_rate': 0.001917379825764385, 'n_estimators': 195}. Best is trial 14 with value: 0.8047220686734269.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[195]\tvalid_0's binary_logloss: 0.645031\n",
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.628204\n",
      "[20]\tvalid_0's binary_logloss: 0.595246\n",
      "[30]\tvalid_0's binary_logloss: 0.575885\n",
      "[40]\tvalid_0's binary_logloss: 0.562926\n",
      "[50]\tvalid_0's binary_logloss: 0.554124\n",
      "[60]\tvalid_0's binary_logloss: 0.546946\n",
      "[70]\tvalid_0's binary_logloss: 0.542351\n",
      "[80]\tvalid_0's binary_logloss: 0.538439\n",
      "[90]\tvalid_0's binary_logloss: 0.536304\n",
      "[100]\tvalid_0's binary_logloss: 0.53453\n",
      "[110]\tvalid_0's binary_logloss: 0.533046\n",
      "[120]\tvalid_0's binary_logloss: 0.531954\n",
      "[130]\tvalid_0's binary_logloss: 0.530739\n",
      "[140]\tvalid_0's binary_logloss: 0.530855\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's binary_logloss: 0.530513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:49:34,657] Trial 20 finished with value: 0.8038114418530838 and parameters: {'num_leaves': 128, 'learning_rate': 0.05561109051139585, 'n_estimators': 251}. Best is trial 14 with value: 0.8047220686734269.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.630327\n",
      "[20]\tvalid_0's binary_logloss: 0.597925\n",
      "[30]\tvalid_0's binary_logloss: 0.577621\n",
      "[40]\tvalid_0's binary_logloss: 0.563816\n",
      "[50]\tvalid_0's binary_logloss: 0.553549\n",
      "[60]\tvalid_0's binary_logloss: 0.54613\n",
      "[70]\tvalid_0's binary_logloss: 0.541244\n",
      "[80]\tvalid_0's binary_logloss: 0.53747\n",
      "[90]\tvalid_0's binary_logloss: 0.534778\n",
      "[100]\tvalid_0's binary_logloss: 0.532846\n",
      "[110]\tvalid_0's binary_logloss: 0.531304\n",
      "[120]\tvalid_0's binary_logloss: 0.530275\n",
      "[130]\tvalid_0's binary_logloss: 0.529751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:49:37,958] Trial 21 finished with value: 0.8033686025146632 and parameters: {'num_leaves': 135, 'learning_rate': 0.05255744493969426, 'n_estimators': 249}. Best is trial 14 with value: 0.8047220686734269.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[140]\tvalid_0's binary_logloss: 0.529973\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's binary_logloss: 0.529721\n",
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023487 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.602911\n",
      "[20]\tvalid_0's binary_logloss: 0.569876\n",
      "[30]\tvalid_0's binary_logloss: 0.554313\n",
      "[40]\tvalid_0's binary_logloss: 0.545217\n",
      "[50]\tvalid_0's binary_logloss: 0.540476\n",
      "[60]\tvalid_0's binary_logloss: 0.539161\n",
      "[70]\tvalid_0's binary_logloss: 0.538457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:49:40,080] Trial 22 finished with value: 0.7958399812759679 and parameters: {'num_leaves': 125, 'learning_rate': 0.09630510808870135, 'n_estimators': 299}. Best is trial 14 with value: 0.8047220686734269.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80]\tvalid_0's binary_logloss: 0.539227\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's binary_logloss: 0.538385\n",
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.666328\n",
      "[20]\tvalid_0's binary_logloss: 0.646552\n",
      "[30]\tvalid_0's binary_logloss: 0.630568\n",
      "[40]\tvalid_0's binary_logloss: 0.617632\n",
      "[50]\tvalid_0's binary_logloss: 0.606801\n",
      "[60]\tvalid_0's binary_logloss: 0.597867\n",
      "[70]\tvalid_0's binary_logloss: 0.590115\n",
      "[80]\tvalid_0's binary_logloss: 0.583327\n",
      "[90]\tvalid_0's binary_logloss: 0.577238\n",
      "[100]\tvalid_0's binary_logloss: 0.572274\n",
      "[110]\tvalid_0's binary_logloss: 0.56762\n",
      "[120]\tvalid_0's binary_logloss: 0.563664\n",
      "[130]\tvalid_0's binary_logloss: 0.560043\n",
      "[140]\tvalid_0's binary_logloss: 0.55683\n",
      "[150]\tvalid_0's binary_logloss: 0.553763\n",
      "[160]\tvalid_0's binary_logloss: 0.551024\n",
      "[170]\tvalid_0's binary_logloss: 0.548578\n",
      "[180]\tvalid_0's binary_logloss: 0.546102\n",
      "[190]\tvalid_0's binary_logloss: 0.54389\n",
      "[200]\tvalid_0's binary_logloss: 0.542145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:49:45,852] Trial 23 finished with value: 0.799583612743402 and parameters: {'num_leaves': 138, 'learning_rate': 0.01733457284534685, 'n_estimators': 211}. Best is trial 14 with value: 0.8047220686734269.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[210]\tvalid_0's binary_logloss: 0.540426\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[211]\tvalid_0's binary_logloss: 0.540298\n",
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.663786\n",
      "[20]\tvalid_0's binary_logloss: 0.643008\n",
      "[30]\tvalid_0's binary_logloss: 0.62745\n",
      "[40]\tvalid_0's binary_logloss: 0.615095\n",
      "[50]\tvalid_0's binary_logloss: 0.605331\n",
      "[60]\tvalid_0's binary_logloss: 0.597279\n",
      "[70]\tvalid_0's binary_logloss: 0.590186\n",
      "[80]\tvalid_0's binary_logloss: 0.584274\n",
      "[90]\tvalid_0's binary_logloss: 0.578934\n",
      "[100]\tvalid_0's binary_logloss: 0.574311\n",
      "[110]\tvalid_0's binary_logloss: 0.570273\n",
      "[120]\tvalid_0's binary_logloss: 0.566539\n",
      "[130]\tvalid_0's binary_logloss: 0.563301\n",
      "[140]\tvalid_0's binary_logloss: 0.560376\n",
      "[150]\tvalid_0's binary_logloss: 0.557694\n",
      "[160]\tvalid_0's binary_logloss: 0.555481\n",
      "[170]\tvalid_0's binary_logloss: 0.55343\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[176]\tvalid_0's binary_logloss: 0.55217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:49:47,312] Trial 24 finished with value: 0.7915494097394575 and parameters: {'num_leaves': 20, 'learning_rate': 0.02602181204856427, 'n_estimators': 176}. Best is trial 14 with value: 0.8047220686734269.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.624948\n",
      "[20]\tvalid_0's binary_logloss: 0.592078\n",
      "[30]\tvalid_0's binary_logloss: 0.572357\n",
      "[40]\tvalid_0's binary_logloss: 0.55919\n",
      "[50]\tvalid_0's binary_logloss: 0.550232\n",
      "[60]\tvalid_0's binary_logloss: 0.544024\n",
      "[70]\tvalid_0's binary_logloss: 0.53985\n",
      "[80]\tvalid_0's binary_logloss: 0.537063\n",
      "[90]\tvalid_0's binary_logloss: 0.535258\n",
      "[100]\tvalid_0's binary_logloss: 0.533975\n",
      "[110]\tvalid_0's binary_logloss: 0.533549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:49:50,168] Trial 25 finished with value: 0.8007136813974031 and parameters: {'num_leaves': 150, 'learning_rate': 0.05896523448984188, 'n_estimators': 244}. Best is trial 14 with value: 0.8047220686734269.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's binary_logloss: 0.533408\n",
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.650003\n",
      "[20]\tvalid_0's binary_logloss: 0.622266\n",
      "[30]\tvalid_0's binary_logloss: 0.602826\n",
      "[40]\tvalid_0's binary_logloss: 0.588635\n",
      "[50]\tvalid_0's binary_logloss: 0.57763\n",
      "[60]\tvalid_0's binary_logloss: 0.569012\n",
      "[70]\tvalid_0's binary_logloss: 0.561432\n",
      "[80]\tvalid_0's binary_logloss: 0.555684\n",
      "[90]\tvalid_0's binary_logloss: 0.551199\n",
      "[100]\tvalid_0's binary_logloss: 0.546881\n",
      "[110]\tvalid_0's binary_logloss: 0.543973\n",
      "[120]\tvalid_0's binary_logloss: 0.541279\n",
      "[130]\tvalid_0's binary_logloss: 0.539113\n",
      "[140]\tvalid_0's binary_logloss: 0.537102\n",
      "[150]\tvalid_0's binary_logloss: 0.535607\n",
      "[160]\tvalid_0's binary_logloss: 0.534132\n",
      "[170]\tvalid_0's binary_logloss: 0.533131\n",
      "[180]\tvalid_0's binary_logloss: 0.532175\n",
      "[190]\tvalid_0's binary_logloss: 0.531503\n",
      "[200]\tvalid_0's binary_logloss: 0.531055\n",
      "[210]\tvalid_0's binary_logloss: 0.530832\n",
      "[220]\tvalid_0's binary_logloss: 0.530528\n",
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's binary_logloss: 0.530444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:49:55,190] Trial 26 finished with value: 0.8032837709937453 and parameters: {'num_leaves': 120, 'learning_rate': 0.03188311337952369, 'n_estimators': 273}. Best is trial 14 with value: 0.8047220686734269.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.630789\n",
      "[20]\tvalid_0's binary_logloss: 0.598317\n",
      "[30]\tvalid_0's binary_logloss: 0.579027\n",
      "[40]\tvalid_0's binary_logloss: 0.565111\n",
      "[50]\tvalid_0's binary_logloss: 0.555423\n",
      "[60]\tvalid_0's binary_logloss: 0.548509\n",
      "[70]\tvalid_0's binary_logloss: 0.543366\n",
      "[80]\tvalid_0's binary_logloss: 0.53991\n",
      "[90]\tvalid_0's binary_logloss: 0.536981\n",
      "[100]\tvalid_0's binary_logloss: 0.535047\n",
      "[110]\tvalid_0's binary_logloss: 0.53357\n",
      "[120]\tvalid_0's binary_logloss: 0.53297\n",
      "[130]\tvalid_0's binary_logloss: 0.532235\n",
      "[140]\tvalid_0's binary_logloss: 0.531973\n",
      "[150]\tvalid_0's binary_logloss: 0.531918\n",
      "[160]\tvalid_0's binary_logloss: 0.531717\n",
      "[170]\tvalid_0's binary_logloss: 0.531726\n",
      "Early stopping, best iteration is:\n",
      "[164]\tvalid_0's binary_logloss: 0.531545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:49:58,483] Trial 27 finished with value: 0.8025131592644833 and parameters: {'num_leaves': 105, 'learning_rate': 0.05357960616620918, 'n_estimators': 179}. Best is trial 14 with value: 0.8047220686734269.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.674184\n",
      "[20]\tvalid_0's binary_logloss: 0.659434\n",
      "[30]\tvalid_0's binary_logloss: 0.646674\n",
      "[40]\tvalid_0's binary_logloss: 0.63559\n",
      "[50]\tvalid_0's binary_logloss: 0.626017\n",
      "[60]\tvalid_0's binary_logloss: 0.617692\n",
      "[70]\tvalid_0's binary_logloss: 0.610369\n",
      "[80]\tvalid_0's binary_logloss: 0.603642\n",
      "[90]\tvalid_0's binary_logloss: 0.597782\n",
      "[100]\tvalid_0's binary_logloss: 0.592309\n",
      "[110]\tvalid_0's binary_logloss: 0.587496\n",
      "[120]\tvalid_0's binary_logloss: 0.583084\n",
      "[130]\tvalid_0's binary_logloss: 0.579019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:50:01,761] Trial 28 finished with value: 0.7871322567275978 and parameters: {'num_leaves': 137, 'learning_rate': 0.011547351685408293, 'n_estimators': 144}. Best is trial 14 with value: 0.8047220686734269.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[140]\tvalid_0's binary_logloss: 0.575247\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[144]\tvalid_0's binary_logloss: 0.573833\n",
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.635827\n",
      "[20]\tvalid_0's binary_logloss: 0.604168\n",
      "[30]\tvalid_0's binary_logloss: 0.58448\n",
      "[40]\tvalid_0's binary_logloss: 0.570354\n",
      "[50]\tvalid_0's binary_logloss: 0.559956\n",
      "[60]\tvalid_0's binary_logloss: 0.55225\n",
      "[70]\tvalid_0's binary_logloss: 0.546826\n",
      "[80]\tvalid_0's binary_logloss: 0.54278\n",
      "[90]\tvalid_0's binary_logloss: 0.539682\n",
      "[100]\tvalid_0's binary_logloss: 0.536868\n",
      "[110]\tvalid_0's binary_logloss: 0.535267\n",
      "[120]\tvalid_0's binary_logloss: 0.534338\n",
      "[130]\tvalid_0's binary_logloss: 0.533249\n",
      "[140]\tvalid_0's binary_logloss: 0.532331\n",
      "[150]\tvalid_0's binary_logloss: 0.531916\n",
      "[160]\tvalid_0's binary_logloss: 0.531271\n",
      "[170]\tvalid_0's binary_logloss: 0.530962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:50:05,058] Trial 29 finished with value: 0.8022784430572527 and parameters: {'num_leaves': 107, 'learning_rate': 0.04743709587437988, 'n_estimators': 237}. Best is trial 14 with value: 0.8047220686734269.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[180]\tvalid_0's binary_logloss: 0.530547\n",
      "Early stopping, best iteration is:\n",
      "[177]\tvalid_0's binary_logloss: 0.530359\n",
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021890 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.659339\n",
      "[20]\tvalid_0's binary_logloss: 0.635352\n",
      "[30]\tvalid_0's binary_logloss: 0.617569\n",
      "[40]\tvalid_0's binary_logloss: 0.603573\n",
      "[50]\tvalid_0's binary_logloss: 0.592613\n",
      "[60]\tvalid_0's binary_logloss: 0.583696\n",
      "[70]\tvalid_0's binary_logloss: 0.576555\n",
      "[80]\tvalid_0's binary_logloss: 0.570054\n",
      "[90]\tvalid_0's binary_logloss: 0.564521\n",
      "[100]\tvalid_0's binary_logloss: 0.559901\n",
      "[110]\tvalid_0's binary_logloss: 0.555742\n",
      "[120]\tvalid_0's binary_logloss: 0.551882\n",
      "[130]\tvalid_0's binary_logloss: 0.548697\n",
      "[140]\tvalid_0's binary_logloss: 0.545883\n",
      "[150]\tvalid_0's binary_logloss: 0.543714\n",
      "[160]\tvalid_0's binary_logloss: 0.541482\n",
      "[170]\tvalid_0's binary_logloss: 0.539652\n",
      "[180]\tvalid_0's binary_logloss: 0.538075\n",
      "[190]\tvalid_0's binary_logloss: 0.536546\n",
      "[200]\tvalid_0's binary_logloss: 0.535322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:50:09,098] Trial 30 finished with value: 0.802240648773926 and parameters: {'num_leaves': 97, 'learning_rate': 0.02425713006111659, 'n_estimators': 206}. Best is trial 14 with value: 0.8047220686734269.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[206]\tvalid_0's binary_logloss: 0.534504\n",
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023976 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.627678\n",
      "[20]\tvalid_0's binary_logloss: 0.594585\n",
      "[30]\tvalid_0's binary_logloss: 0.574431\n",
      "[40]\tvalid_0's binary_logloss: 0.561669\n",
      "[50]\tvalid_0's binary_logloss: 0.552656\n",
      "[60]\tvalid_0's binary_logloss: 0.54591\n",
      "[70]\tvalid_0's binary_logloss: 0.542078\n",
      "[80]\tvalid_0's binary_logloss: 0.538687\n",
      "[90]\tvalid_0's binary_logloss: 0.536857\n",
      "[100]\tvalid_0's binary_logloss: 0.534869\n",
      "[110]\tvalid_0's binary_logloss: 0.533679\n",
      "[120]\tvalid_0's binary_logloss: 0.533154\n",
      "[130]\tvalid_0's binary_logloss: 0.533106\n",
      "[140]\tvalid_0's binary_logloss: 0.532634\n",
      "[150]\tvalid_0's binary_logloss: 0.532256\n",
      "[160]\tvalid_0's binary_logloss: 0.532253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:50:12,654] Trial 31 finished with value: 0.8022352439955851 and parameters: {'num_leaves': 135, 'learning_rate': 0.056270134269015365, 'n_estimators': 251}. Best is trial 14 with value: 0.8047220686734269.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[153]\tvalid_0's binary_logloss: 0.532142\n",
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.645541\n",
      "[20]\tvalid_0's binary_logloss: 0.616498\n",
      "[30]\tvalid_0's binary_logloss: 0.596227\n",
      "[40]\tvalid_0's binary_logloss: 0.582086\n",
      "[50]\tvalid_0's binary_logloss: 0.571065\n",
      "[60]\tvalid_0's binary_logloss: 0.563081\n",
      "[70]\tvalid_0's binary_logloss: 0.556317\n",
      "[80]\tvalid_0's binary_logloss: 0.550572\n",
      "[90]\tvalid_0's binary_logloss: 0.546157\n",
      "[100]\tvalid_0's binary_logloss: 0.542848\n",
      "[110]\tvalid_0's binary_logloss: 0.539804\n",
      "[120]\tvalid_0's binary_logloss: 0.537513\n",
      "[130]\tvalid_0's binary_logloss: 0.535853\n",
      "[140]\tvalid_0's binary_logloss: 0.53449\n",
      "[150]\tvalid_0's binary_logloss: 0.533529\n",
      "[160]\tvalid_0's binary_logloss: 0.532363\n",
      "[170]\tvalid_0's binary_logloss: 0.531472\n",
      "[180]\tvalid_0's binary_logloss: 0.530606\n",
      "[190]\tvalid_0's binary_logloss: 0.530344\n",
      "[200]\tvalid_0's binary_logloss: 0.530009\n",
      "[210]\tvalid_0's binary_logloss: 0.529536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:50:17,325] Trial 32 finished with value: 0.8035701067506387 and parameters: {'num_leaves': 141, 'learning_rate': 0.03535806199431726, 'n_estimators': 262}. Best is trial 14 with value: 0.8047220686734269.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[209]\tvalid_0's binary_logloss: 0.529517\n",
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.638344\n",
      "[20]\tvalid_0's binary_logloss: 0.607374\n",
      "[30]\tvalid_0's binary_logloss: 0.587599\n",
      "[40]\tvalid_0's binary_logloss: 0.573725\n",
      "[50]\tvalid_0's binary_logloss: 0.563808\n",
      "[60]\tvalid_0's binary_logloss: 0.555978\n",
      "[70]\tvalid_0's binary_logloss: 0.549885\n",
      "[80]\tvalid_0's binary_logloss: 0.54485\n",
      "[90]\tvalid_0's binary_logloss: 0.540994\n",
      "[100]\tvalid_0's binary_logloss: 0.538318\n",
      "[110]\tvalid_0's binary_logloss: 0.536529\n",
      "[120]\tvalid_0's binary_logloss: 0.535219\n",
      "[130]\tvalid_0's binary_logloss: 0.534064\n",
      "[140]\tvalid_0's binary_logloss: 0.53297\n",
      "[150]\tvalid_0's binary_logloss: 0.532191\n",
      "[160]\tvalid_0's binary_logloss: 0.532093\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's binary_logloss: 0.531849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:50:22,049] Trial 33 finished with value: 0.8022018361990279 and parameters: {'num_leaves': 143, 'learning_rate': 0.04248726345736071, 'n_estimators': 269}. Best is trial 14 with value: 0.8047220686734269.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028353 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.652496\n",
      "[20]\tvalid_0's binary_logloss: 0.626025\n",
      "[30]\tvalid_0's binary_logloss: 0.606868\n",
      "[40]\tvalid_0's binary_logloss: 0.592616\n",
      "[50]\tvalid_0's binary_logloss: 0.581622\n",
      "[60]\tvalid_0's binary_logloss: 0.572648\n",
      "[70]\tvalid_0's binary_logloss: 0.565573\n",
      "[80]\tvalid_0's binary_logloss: 0.559278\n",
      "[90]\tvalid_0's binary_logloss: 0.554568\n",
      "[100]\tvalid_0's binary_logloss: 0.550125\n",
      "[110]\tvalid_0's binary_logloss: 0.546331\n",
      "[120]\tvalid_0's binary_logloss: 0.54293\n",
      "[130]\tvalid_0's binary_logloss: 0.540291\n",
      "[140]\tvalid_0's binary_logloss: 0.538166\n",
      "[150]\tvalid_0's binary_logloss: 0.536596\n",
      "[160]\tvalid_0's binary_logloss: 0.535164\n",
      "[170]\tvalid_0's binary_logloss: 0.533812\n",
      "[180]\tvalid_0's binary_logloss: 0.532817\n",
      "[190]\tvalid_0's binary_logloss: 0.531923\n",
      "[200]\tvalid_0's binary_logloss: 0.53098\n",
      "[210]\tvalid_0's binary_logloss: 0.530014\n",
      "[220]\tvalid_0's binary_logloss: 0.529341\n",
      "[230]\tvalid_0's binary_logloss: 0.529052\n",
      "[240]\tvalid_0's binary_logloss: 0.528706\n",
      "[250]\tvalid_0's binary_logloss: 0.528492\n",
      "[260]\tvalid_0's binary_logloss: 0.528286\n",
      "[270]\tvalid_0's binary_logloss: 0.528283\n",
      "[280]\tvalid_0's binary_logloss: 0.527781\n",
      "[290]\tvalid_0's binary_logloss: 0.527754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:50:28,183] Trial 34 finished with value: 0.8057254775219577 and parameters: {'num_leaves': 120, 'learning_rate': 0.02942573951400273, 'n_estimators': 300}. Best is trial 34 with value: 0.8057254775219577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\tvalid_0's binary_logloss: 0.527593\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's binary_logloss: 0.527593\n",
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020778 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.657405\n",
      "[20]\tvalid_0's binary_logloss: 0.632737\n",
      "[30]\tvalid_0's binary_logloss: 0.614469\n",
      "[40]\tvalid_0's binary_logloss: 0.600495\n",
      "[50]\tvalid_0's binary_logloss: 0.589275\n",
      "[60]\tvalid_0's binary_logloss: 0.580464\n",
      "[70]\tvalid_0's binary_logloss: 0.573018\n",
      "[80]\tvalid_0's binary_logloss: 0.566578\n",
      "[90]\tvalid_0's binary_logloss: 0.561213\n",
      "[100]\tvalid_0's binary_logloss: 0.556653\n",
      "[110]\tvalid_0's binary_logloss: 0.552626\n",
      "[120]\tvalid_0's binary_logloss: 0.549032\n",
      "[130]\tvalid_0's binary_logloss: 0.545853\n",
      "[140]\tvalid_0's binary_logloss: 0.542984\n",
      "[150]\tvalid_0's binary_logloss: 0.540924\n",
      "[160]\tvalid_0's binary_logloss: 0.539046\n",
      "[170]\tvalid_0's binary_logloss: 0.537331\n",
      "[180]\tvalid_0's binary_logloss: 0.535948\n",
      "[190]\tvalid_0's binary_logloss: 0.534594\n",
      "[200]\tvalid_0's binary_logloss: 0.533608\n",
      "[210]\tvalid_0's binary_logloss: 0.532628\n",
      "[220]\tvalid_0's binary_logloss: 0.53194\n",
      "[230]\tvalid_0's binary_logloss: 0.531126\n",
      "[240]\tvalid_0's binary_logloss: 0.530549\n",
      "[250]\tvalid_0's binary_logloss: 0.530111\n",
      "[260]\tvalid_0's binary_logloss: 0.52954\n",
      "[270]\tvalid_0's binary_logloss: 0.529304\n",
      "[280]\tvalid_0's binary_logloss: 0.528941\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[285]\tvalid_0's binary_logloss: 0.528851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:50:33,814] Trial 35 finished with value: 0.8043514105414014 and parameters: {'num_leaves': 122, 'learning_rate': 0.025124582796615284, 'n_estimators': 289}. Best is trial 34 with value: 0.8057254775219577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.65965\n",
      "[20]\tvalid_0's binary_logloss: 0.636166\n",
      "[30]\tvalid_0's binary_logloss: 0.61825\n",
      "[40]\tvalid_0's binary_logloss: 0.604543\n",
      "[50]\tvalid_0's binary_logloss: 0.593304\n",
      "[60]\tvalid_0's binary_logloss: 0.584104\n",
      "[70]\tvalid_0's binary_logloss: 0.576658\n",
      "[80]\tvalid_0's binary_logloss: 0.569904\n",
      "[90]\tvalid_0's binary_logloss: 0.564246\n",
      "[100]\tvalid_0's binary_logloss: 0.559368\n",
      "[110]\tvalid_0's binary_logloss: 0.555334\n",
      "[120]\tvalid_0's binary_logloss: 0.551654\n",
      "[130]\tvalid_0's binary_logloss: 0.548269\n",
      "[140]\tvalid_0's binary_logloss: 0.545557\n",
      "[150]\tvalid_0's binary_logloss: 0.543053\n",
      "[160]\tvalid_0's binary_logloss: 0.540845\n",
      "[170]\tvalid_0's binary_logloss: 0.538767\n",
      "[180]\tvalid_0's binary_logloss: 0.537192\n",
      "[190]\tvalid_0's binary_logloss: 0.536023\n",
      "[200]\tvalid_0's binary_logloss: 0.534762\n",
      "[210]\tvalid_0's binary_logloss: 0.53378\n",
      "[220]\tvalid_0's binary_logloss: 0.532648\n",
      "[230]\tvalid_0's binary_logloss: 0.531657\n",
      "[240]\tvalid_0's binary_logloss: 0.530894\n",
      "[250]\tvalid_0's binary_logloss: 0.530147\n",
      "[260]\tvalid_0's binary_logloss: 0.529619\n",
      "[270]\tvalid_0's binary_logloss: 0.529152\n",
      "[280]\tvalid_0's binary_logloss: 0.528595\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[287]\tvalid_0's binary_logloss: 0.528203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:50:40,118] Trial 36 finished with value: 0.8058418760815921 and parameters: {'num_leaves': 120, 'learning_rate': 0.023083103479452194, 'n_estimators': 287}. Best is trial 36 with value: 0.8058418760815921.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.66891\n",
      "[20]\tvalid_0's binary_logloss: 0.650629\n",
      "[30]\tvalid_0's binary_logloss: 0.635681\n",
      "[40]\tvalid_0's binary_logloss: 0.62323\n",
      "[50]\tvalid_0's binary_logloss: 0.612771\n",
      "[60]\tvalid_0's binary_logloss: 0.603916\n",
      "[70]\tvalid_0's binary_logloss: 0.596135\n",
      "[80]\tvalid_0's binary_logloss: 0.589388\n",
      "[90]\tvalid_0's binary_logloss: 0.583565\n",
      "[100]\tvalid_0's binary_logloss: 0.578397\n",
      "[110]\tvalid_0's binary_logloss: 0.574012\n",
      "[120]\tvalid_0's binary_logloss: 0.569722\n",
      "[130]\tvalid_0's binary_logloss: 0.565908\n",
      "[140]\tvalid_0's binary_logloss: 0.562444\n",
      "[150]\tvalid_0's binary_logloss: 0.559234\n",
      "[160]\tvalid_0's binary_logloss: 0.556454\n",
      "[170]\tvalid_0's binary_logloss: 0.553992\n",
      "[180]\tvalid_0's binary_logloss: 0.551594\n",
      "[190]\tvalid_0's binary_logloss: 0.549465\n",
      "[200]\tvalid_0's binary_logloss: 0.547361\n",
      "[210]\tvalid_0's binary_logloss: 0.545496\n",
      "[220]\tvalid_0's binary_logloss: 0.543851\n",
      "[230]\tvalid_0's binary_logloss: 0.542409\n",
      "[240]\tvalid_0's binary_logloss: 0.540993\n",
      "[250]\tvalid_0's binary_logloss: 0.539662\n",
      "[260]\tvalid_0's binary_logloss: 0.538576\n",
      "[270]\tvalid_0's binary_logloss: 0.537669\n",
      "[280]\tvalid_0's binary_logloss: 0.536917\n",
      "[290]\tvalid_0's binary_logloss: 0.536255\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[299]\tvalid_0's binary_logloss: 0.535434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:50:46,452] Trial 37 finished with value: 0.8011032954186827 and parameters: {'num_leaves': 111, 'learning_rate': 0.015805205410168395, 'n_estimators': 299}. Best is trial 36 with value: 0.8058418760815921.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024504 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.656932\n",
      "[20]\tvalid_0's binary_logloss: 0.632056\n",
      "[30]\tvalid_0's binary_logloss: 0.613735\n",
      "[40]\tvalid_0's binary_logloss: 0.599637\n",
      "[50]\tvalid_0's binary_logloss: 0.588318\n",
      "[60]\tvalid_0's binary_logloss: 0.579363\n",
      "[70]\tvalid_0's binary_logloss: 0.572094\n",
      "[80]\tvalid_0's binary_logloss: 0.565642\n",
      "[90]\tvalid_0's binary_logloss: 0.560312\n",
      "[100]\tvalid_0's binary_logloss: 0.555836\n",
      "[110]\tvalid_0's binary_logloss: 0.552144\n",
      "[120]\tvalid_0's binary_logloss: 0.548713\n",
      "[130]\tvalid_0's binary_logloss: 0.545732\n",
      "[140]\tvalid_0's binary_logloss: 0.543358\n",
      "[150]\tvalid_0's binary_logloss: 0.540905\n",
      "[160]\tvalid_0's binary_logloss: 0.538984\n",
      "[170]\tvalid_0's binary_logloss: 0.537348\n",
      "[180]\tvalid_0's binary_logloss: 0.535989\n",
      "[190]\tvalid_0's binary_logloss: 0.534753\n",
      "[200]\tvalid_0's binary_logloss: 0.533655\n",
      "[210]\tvalid_0's binary_logloss: 0.532848\n",
      "[220]\tvalid_0's binary_logloss: 0.532324\n",
      "[230]\tvalid_0's binary_logloss: 0.53144\n",
      "[240]\tvalid_0's binary_logloss: 0.530892\n",
      "[250]\tvalid_0's binary_logloss: 0.530377\n",
      "[260]\tvalid_0's binary_logloss: 0.529892\n",
      "[270]\tvalid_0's binary_logloss: 0.529493\n",
      "[280]\tvalid_0's binary_logloss: 0.529117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:50:52,615] Trial 38 finished with value: 0.8044975745469719 and parameters: {'num_leaves': 121, 'learning_rate': 0.025609567313742337, 'n_estimators': 284}. Best is trial 36 with value: 0.8058418760815921.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[279]\tvalid_0's binary_logloss: 0.529035\n",
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021554 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.670933\n",
      "[20]\tvalid_0's binary_logloss: 0.654083\n",
      "[30]\tvalid_0's binary_logloss: 0.640091\n",
      "[40]\tvalid_0's binary_logloss: 0.62835\n",
      "[50]\tvalid_0's binary_logloss: 0.618339\n",
      "[60]\tvalid_0's binary_logloss: 0.609755\n",
      "[70]\tvalid_0's binary_logloss: 0.602251\n",
      "[80]\tvalid_0's binary_logloss: 0.595709\n",
      "[90]\tvalid_0's binary_logloss: 0.590038\n",
      "[100]\tvalid_0's binary_logloss: 0.584901\n",
      "[110]\tvalid_0's binary_logloss: 0.580237\n",
      "[120]\tvalid_0's binary_logloss: 0.576049\n",
      "[130]\tvalid_0's binary_logloss: 0.572119\n",
      "[140]\tvalid_0's binary_logloss: 0.568574\n",
      "[150]\tvalid_0's binary_logloss: 0.565424\n",
      "[160]\tvalid_0's binary_logloss: 0.562356\n",
      "[170]\tvalid_0's binary_logloss: 0.559614\n",
      "[180]\tvalid_0's binary_logloss: 0.557077\n",
      "[190]\tvalid_0's binary_logloss: 0.554777\n",
      "[200]\tvalid_0's binary_logloss: 0.552705\n",
      "[210]\tvalid_0's binary_logloss: 0.550723\n",
      "[220]\tvalid_0's binary_logloss: 0.548958\n",
      "[230]\tvalid_0's binary_logloss: 0.547413\n",
      "[240]\tvalid_0's binary_logloss: 0.546011\n",
      "[250]\tvalid_0's binary_logloss: 0.544628\n",
      "[260]\tvalid_0's binary_logloss: 0.543278\n",
      "[270]\tvalid_0's binary_logloss: 0.54213\n",
      "[280]\tvalid_0's binary_logloss: 0.540982\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[281]\tvalid_0's binary_logloss: 0.540833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:50:57,254] Trial 39 finished with value: 0.7993725913977391 and parameters: {'num_leaves': 72, 'learning_rate': 0.014950515449747305, 'n_estimators': 281}. Best is trial 36 with value: 0.8058418760815921.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017996 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.657327\n",
      "[20]\tvalid_0's binary_logloss: 0.632734\n",
      "[30]\tvalid_0's binary_logloss: 0.614596\n",
      "[40]\tvalid_0's binary_logloss: 0.600372\n",
      "[50]\tvalid_0's binary_logloss: 0.589394\n",
      "[60]\tvalid_0's binary_logloss: 0.580501\n",
      "[70]\tvalid_0's binary_logloss: 0.573093\n",
      "[80]\tvalid_0's binary_logloss: 0.56673\n",
      "[90]\tvalid_0's binary_logloss: 0.561924\n",
      "[100]\tvalid_0's binary_logloss: 0.557397\n",
      "[110]\tvalid_0's binary_logloss: 0.553092\n",
      "[120]\tvalid_0's binary_logloss: 0.549924\n",
      "[130]\tvalid_0's binary_logloss: 0.546894\n",
      "[140]\tvalid_0's binary_logloss: 0.544238\n",
      "[150]\tvalid_0's binary_logloss: 0.542074\n",
      "[160]\tvalid_0's binary_logloss: 0.540469\n",
      "[170]\tvalid_0's binary_logloss: 0.538724\n",
      "[180]\tvalid_0's binary_logloss: 0.537234\n",
      "[190]\tvalid_0's binary_logloss: 0.535734\n",
      "[200]\tvalid_0's binary_logloss: 0.534661\n",
      "[210]\tvalid_0's binary_logloss: 0.533628\n",
      "[220]\tvalid_0's binary_logloss: 0.53257\n",
      "[230]\tvalid_0's binary_logloss: 0.53196\n",
      "[240]\tvalid_0's binary_logloss: 0.531358\n",
      "[250]\tvalid_0's binary_logloss: 0.53074\n",
      "[260]\tvalid_0's binary_logloss: 0.530149\n",
      "[270]\tvalid_0's binary_logloss: 0.529705\n",
      "[280]\tvalid_0's binary_logloss: 0.529425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:51:02,315] Trial 40 finished with value: 0.8039151117680746 and parameters: {'num_leaves': 98, 'learning_rate': 0.025839330701647754, 'n_estimators': 290}. Best is trial 36 with value: 0.8058418760815921.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290]\tvalid_0's binary_logloss: 0.529582\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[285]\tvalid_0's binary_logloss: 0.529408\n",
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025098 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.657215\n",
      "[20]\tvalid_0's binary_logloss: 0.632494\n",
      "[30]\tvalid_0's binary_logloss: 0.614163\n",
      "[40]\tvalid_0's binary_logloss: 0.600155\n",
      "[50]\tvalid_0's binary_logloss: 0.588797\n",
      "[60]\tvalid_0's binary_logloss: 0.579763\n",
      "[70]\tvalid_0's binary_logloss: 0.572639\n",
      "[80]\tvalid_0's binary_logloss: 0.565975\n",
      "[90]\tvalid_0's binary_logloss: 0.560335\n",
      "[100]\tvalid_0's binary_logloss: 0.555822\n",
      "[110]\tvalid_0's binary_logloss: 0.55175\n",
      "[120]\tvalid_0's binary_logloss: 0.548016\n",
      "[130]\tvalid_0's binary_logloss: 0.544705\n",
      "[140]\tvalid_0's binary_logloss: 0.542059\n",
      "[150]\tvalid_0's binary_logloss: 0.539603\n",
      "[160]\tvalid_0's binary_logloss: 0.538069\n",
      "[170]\tvalid_0's binary_logloss: 0.536389\n",
      "[180]\tvalid_0's binary_logloss: 0.534825\n",
      "[190]\tvalid_0's binary_logloss: 0.533586\n",
      "[200]\tvalid_0's binary_logloss: 0.532275\n",
      "[210]\tvalid_0's binary_logloss: 0.531461\n",
      "[220]\tvalid_0's binary_logloss: 0.530771\n",
      "[230]\tvalid_0's binary_logloss: 0.530183\n",
      "[240]\tvalid_0's binary_logloss: 0.529592\n",
      "[250]\tvalid_0's binary_logloss: 0.529341\n",
      "[260]\tvalid_0's binary_logloss: 0.528944\n",
      "[270]\tvalid_0's binary_logloss: 0.528558\n",
      "[280]\tvalid_0's binary_logloss: 0.52833\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[282]\tvalid_0's binary_logloss: 0.528278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:51:07,615] Trial 41 finished with value: 0.8054507737880157 and parameters: {'num_leaves': 122, 'learning_rate': 0.02526694474033188, 'n_estimators': 282}. Best is trial 36 with value: 0.8058418760815921.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031800 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.648057\n",
      "[20]\tvalid_0's binary_logloss: 0.620013\n",
      "[30]\tvalid_0's binary_logloss: 0.600209\n",
      "[40]\tvalid_0's binary_logloss: 0.586419\n",
      "[50]\tvalid_0's binary_logloss: 0.576026\n",
      "[60]\tvalid_0's binary_logloss: 0.567134\n",
      "[70]\tvalid_0's binary_logloss: 0.560604\n",
      "[80]\tvalid_0's binary_logloss: 0.55489\n",
      "[90]\tvalid_0's binary_logloss: 0.549973\n",
      "[100]\tvalid_0's binary_logloss: 0.546063\n",
      "[110]\tvalid_0's binary_logloss: 0.542869\n",
      "[120]\tvalid_0's binary_logloss: 0.540708\n",
      "[130]\tvalid_0's binary_logloss: 0.538737\n",
      "[140]\tvalid_0's binary_logloss: 0.537073\n",
      "[150]\tvalid_0's binary_logloss: 0.535356\n",
      "[160]\tvalid_0's binary_logloss: 0.534103\n",
      "[170]\tvalid_0's binary_logloss: 0.533102\n",
      "[180]\tvalid_0's binary_logloss: 0.532346\n",
      "[190]\tvalid_0's binary_logloss: 0.531862\n",
      "[200]\tvalid_0's binary_logloss: 0.531033\n",
      "[210]\tvalid_0's binary_logloss: 0.530533\n",
      "[220]\tvalid_0's binary_logloss: 0.529974\n",
      "[230]\tvalid_0's binary_logloss: 0.529713\n",
      "[240]\tvalid_0's binary_logloss: 0.529963\n",
      "Early stopping, best iteration is:\n",
      "[230]\tvalid_0's binary_logloss: 0.529713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:51:12,070] Trial 42 finished with value: 0.8035207979395418 and parameters: {'num_leaves': 118, 'learning_rate': 0.033666465311613075, 'n_estimators': 276}. Best is trial 36 with value: 0.8058418760815921.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.664657\n",
      "[20]\tvalid_0's binary_logloss: 0.644024\n",
      "[30]\tvalid_0's binary_logloss: 0.627549\n",
      "[40]\tvalid_0's binary_logloss: 0.61443\n",
      "[50]\tvalid_0's binary_logloss: 0.603403\n",
      "[60]\tvalid_0's binary_logloss: 0.594399\n",
      "[70]\tvalid_0's binary_logloss: 0.586643\n",
      "[80]\tvalid_0's binary_logloss: 0.580042\n",
      "[90]\tvalid_0's binary_logloss: 0.574488\n",
      "[100]\tvalid_0's binary_logloss: 0.569484\n",
      "[110]\tvalid_0's binary_logloss: 0.565052\n",
      "[120]\tvalid_0's binary_logloss: 0.560945\n",
      "[130]\tvalid_0's binary_logloss: 0.55728\n",
      "[140]\tvalid_0's binary_logloss: 0.554331\n",
      "[150]\tvalid_0's binary_logloss: 0.55151\n",
      "[160]\tvalid_0's binary_logloss: 0.54863\n",
      "[170]\tvalid_0's binary_logloss: 0.546293\n",
      "[180]\tvalid_0's binary_logloss: 0.544507\n",
      "[190]\tvalid_0's binary_logloss: 0.542933\n",
      "[200]\tvalid_0's binary_logloss: 0.541055\n",
      "[210]\tvalid_0's binary_logloss: 0.539457\n",
      "[220]\tvalid_0's binary_logloss: 0.538125\n",
      "[230]\tvalid_0's binary_logloss: 0.537192\n",
      "[240]\tvalid_0's binary_logloss: 0.536414\n",
      "[250]\tvalid_0's binary_logloss: 0.535383\n",
      "[260]\tvalid_0's binary_logloss: 0.534678\n",
      "[270]\tvalid_0's binary_logloss: 0.533869\n",
      "[280]\tvalid_0's binary_logloss: 0.533155\n",
      "[290]\tvalid_0's binary_logloss: 0.532472\n",
      "[300]\tvalid_0's binary_logloss: 0.53201\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's binary_logloss: 0.53201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:51:17,312] Trial 43 finished with value: 0.8026920652605836 and parameters: {'num_leaves': 112, 'learning_rate': 0.019119337450774713, 'n_estimators': 300}. Best is trial 36 with value: 0.8058418760815921.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.619693\n",
      "[20]\tvalid_0's binary_logloss: 0.586142\n",
      "[30]\tvalid_0's binary_logloss: 0.567676\n",
      "[40]\tvalid_0's binary_logloss: 0.555846\n",
      "[50]\tvalid_0's binary_logloss: 0.547942\n",
      "[60]\tvalid_0's binary_logloss: 0.542417\n",
      "[70]\tvalid_0's binary_logloss: 0.539335\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[76]\tvalid_0's binary_logloss: 0.537769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:51:18,609] Trial 44 finished with value: 0.7972749890905724 and parameters: {'num_leaves': 91, 'learning_rate': 0.07040632320619723, 'n_estimators': 76}. Best is trial 36 with value: 0.8058418760815921.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.679505\n",
      "[20]\tvalid_0's binary_logloss: 0.66868\n",
      "[30]\tvalid_0's binary_logloss: 0.659003\n",
      "[40]\tvalid_0's binary_logloss: 0.65016\n",
      "[50]\tvalid_0's binary_logloss: 0.642202\n",
      "[60]\tvalid_0's binary_logloss: 0.634968\n",
      "[70]\tvalid_0's binary_logloss: 0.628423\n",
      "[80]\tvalid_0's binary_logloss: 0.622334\n",
      "[90]\tvalid_0's binary_logloss: 0.616853\n",
      "[100]\tvalid_0's binary_logloss: 0.611776\n",
      "[110]\tvalid_0's binary_logloss: 0.607045\n",
      "[120]\tvalid_0's binary_logloss: 0.60269\n",
      "[130]\tvalid_0's binary_logloss: 0.598712\n",
      "[140]\tvalid_0's binary_logloss: 0.594886\n",
      "[150]\tvalid_0's binary_logloss: 0.591376\n",
      "[160]\tvalid_0's binary_logloss: 0.58819\n",
      "[170]\tvalid_0's binary_logloss: 0.585204\n",
      "[180]\tvalid_0's binary_logloss: 0.582401\n",
      "[190]\tvalid_0's binary_logloss: 0.579727\n",
      "[200]\tvalid_0's binary_logloss: 0.577115\n",
      "[210]\tvalid_0's binary_logloss: 0.574806\n",
      "[220]\tvalid_0's binary_logloss: 0.572499\n",
      "[230]\tvalid_0's binary_logloss: 0.570279\n",
      "[240]\tvalid_0's binary_logloss: 0.568244\n",
      "[250]\tvalid_0's binary_logloss: 0.566357\n",
      "[260]\tvalid_0's binary_logloss: 0.564571\n",
      "[270]\tvalid_0's binary_logloss: 0.562783\n",
      "[280]\tvalid_0's binary_logloss: 0.561021\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[285]\tvalid_0's binary_logloss: 0.560185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:51:24,256] Trial 45 finished with value: 0.7913747727349455 and parameters: {'num_leaves': 131, 'learning_rate': 0.007883696595396098, 'n_estimators': 285}. Best is trial 36 with value: 0.8058418760815921.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.642032\n",
      "[20]\tvalid_0's binary_logloss: 0.612042\n",
      "[30]\tvalid_0's binary_logloss: 0.591814\n",
      "[40]\tvalid_0's binary_logloss: 0.577921\n",
      "[50]\tvalid_0's binary_logloss: 0.567138\n",
      "[60]\tvalid_0's binary_logloss: 0.558622\n",
      "[70]\tvalid_0's binary_logloss: 0.552606\n",
      "[80]\tvalid_0's binary_logloss: 0.547396\n",
      "[90]\tvalid_0's binary_logloss: 0.543245\n",
      "[100]\tvalid_0's binary_logloss: 0.539883\n",
      "[110]\tvalid_0's binary_logloss: 0.537126\n",
      "[120]\tvalid_0's binary_logloss: 0.535532\n",
      "[130]\tvalid_0's binary_logloss: 0.53387\n",
      "[140]\tvalid_0's binary_logloss: 0.532575\n",
      "[150]\tvalid_0's binary_logloss: 0.531614\n",
      "[160]\tvalid_0's binary_logloss: 0.530999\n",
      "[170]\tvalid_0's binary_logloss: 0.530242\n",
      "[180]\tvalid_0's binary_logloss: 0.529607\n",
      "[190]\tvalid_0's binary_logloss: 0.529475\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's binary_logloss: 0.52934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:51:27,805] Trial 46 finished with value: 0.8044268032827526 and parameters: {'num_leaves': 120, 'learning_rate': 0.03991405374406164, 'n_estimators': 261}. Best is trial 36 with value: 0.8058418760815921.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.618959\n",
      "[20]\tvalid_0's binary_logloss: 0.588119\n",
      "[30]\tvalid_0's binary_logloss: 0.569578\n",
      "[40]\tvalid_0's binary_logloss: 0.557857\n",
      "[50]\tvalid_0's binary_logloss: 0.55012\n",
      "[60]\tvalid_0's binary_logloss: 0.545233\n",
      "[70]\tvalid_0's binary_logloss: 0.540947\n",
      "[80]\tvalid_0's binary_logloss: 0.537785\n",
      "[90]\tvalid_0's binary_logloss: 0.535568\n",
      "[100]\tvalid_0's binary_logloss: 0.534971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:51:29,169] Trial 47 finished with value: 0.7991632933147357 and parameters: {'num_leaves': 43, 'learning_rate': 0.07989291163035213, 'n_estimators': 229}. Best is trial 36 with value: 0.8058418760815921.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[110]\tvalid_0's binary_logloss: 0.534623\n",
      "[120]\tvalid_0's binary_logloss: 0.534176\n",
      "[130]\tvalid_0's binary_logloss: 0.534098\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's binary_logloss: 0.533917\n",
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019905 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.670781\n",
      "[20]\tvalid_0's binary_logloss: 0.653829\n",
      "[30]\tvalid_0's binary_logloss: 0.639643\n",
      "[40]\tvalid_0's binary_logloss: 0.627548\n",
      "[50]\tvalid_0's binary_logloss: 0.61746\n",
      "[60]\tvalid_0's binary_logloss: 0.608585\n",
      "[70]\tvalid_0's binary_logloss: 0.600989\n",
      "[80]\tvalid_0's binary_logloss: 0.59421\n",
      "[90]\tvalid_0's binary_logloss: 0.58836\n",
      "[100]\tvalid_0's binary_logloss: 0.583115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:51:31,483] Trial 48 finished with value: 0.7851442774246089 and parameters: {'num_leaves': 108, 'learning_rate': 0.01443296844961299, 'n_estimators': 115}. Best is trial 36 with value: 0.8058418760815921.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[110]\tvalid_0's binary_logloss: 0.578401\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[115]\tvalid_0's binary_logloss: 0.576324\n",
      "[LightGBM] [Info] Number of positive: 12354, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523342 -> initscore=0.093434\n",
      "[LightGBM] [Info] Start training from score 0.093434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's binary_logloss: 0.680365\n",
      "[20]\tvalid_0's binary_logloss: 0.670161\n",
      "[30]\tvalid_0's binary_logloss: 0.661075\n",
      "[40]\tvalid_0's binary_logloss: 0.652741\n",
      "[50]\tvalid_0's binary_logloss: 0.645222\n",
      "[60]\tvalid_0's binary_logloss: 0.638295\n",
      "[70]\tvalid_0's binary_logloss: 0.631924\n",
      "[80]\tvalid_0's binary_logloss: 0.626194\n",
      "[90]\tvalid_0's binary_logloss: 0.620812\n",
      "[100]\tvalid_0's binary_logloss: 0.61593\n",
      "[110]\tvalid_0's binary_logloss: 0.611468\n",
      "[120]\tvalid_0's binary_logloss: 0.607242\n",
      "[130]\tvalid_0's binary_logloss: 0.603362\n",
      "[140]\tvalid_0's binary_logloss: 0.599757\n",
      "[150]\tvalid_0's binary_logloss: 0.596288\n",
      "[160]\tvalid_0's binary_logloss: 0.593054\n",
      "[170]\tvalid_0's binary_logloss: 0.589991\n",
      "[180]\tvalid_0's binary_logloss: 0.587212\n",
      "[190]\tvalid_0's binary_logloss: 0.584567\n",
      "[200]\tvalid_0's binary_logloss: 0.581989\n",
      "[210]\tvalid_0's binary_logloss: 0.579609\n",
      "[220]\tvalid_0's binary_logloss: 0.577347\n",
      "[230]\tvalid_0's binary_logloss: 0.575133\n",
      "[240]\tvalid_0's binary_logloss: 0.573035\n",
      "[250]\tvalid_0's binary_logloss: 0.571035\n",
      "[260]\tvalid_0's binary_logloss: 0.569166\n",
      "[270]\tvalid_0's binary_logloss: 0.567373\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[278]\tvalid_0's binary_logloss: 0.566007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:51:35,526] Trial 49 finished with value: 0.7893837777223025 and parameters: {'num_leaves': 80, 'learning_rate': 0.007733554295549947, 'n_estimators': 278}. Best is trial 36 with value: 0.8058418760815921.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'num_leaves': 120, 'learning_rate': 0.023083103479452194, 'n_estimators': 287}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022537 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26553\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 245\n",
      "[LightGBM] [Info] Start training from score 0.523342\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's l2: 0.233384\n",
      "[20]\tvalid_0's l2: 0.221824\n",
      "[30]\tvalid_0's l2: 0.213557\n",
      "[40]\tvalid_0's l2: 0.207406\n",
      "[50]\tvalid_0's l2: 0.202582\n",
      "[60]\tvalid_0's l2: 0.198863\n",
      "[70]\tvalid_0's l2: 0.195924\n",
      "[80]\tvalid_0's l2: 0.193481\n",
      "[90]\tvalid_0's l2: 0.191462\n",
      "[100]\tvalid_0's l2: 0.189666\n",
      "[110]\tvalid_0's l2: 0.188341\n",
      "[120]\tvalid_0's l2: 0.18718\n",
      "[130]\tvalid_0's l2: 0.186208\n",
      "[140]\tvalid_0's l2: 0.185341\n",
      "[150]\tvalid_0's l2: 0.184655\n",
      "[160]\tvalid_0's l2: 0.184005\n",
      "[170]\tvalid_0's l2: 0.183428\n",
      "[180]\tvalid_0's l2: 0.182972\n",
      "[190]\tvalid_0's l2: 0.182692\n",
      "[200]\tvalid_0's l2: 0.182356\n",
      "[210]\tvalid_0's l2: 0.182025\n",
      "[220]\tvalid_0's l2: 0.181967\n",
      "[230]\tvalid_0's l2: 0.181818\n",
      "[240]\tvalid_0's l2: 0.18168\n",
      "[250]\tvalid_0's l2: 0.181594\n",
      "[260]\tvalid_0's l2: 0.181499\n",
      "[270]\tvalid_0's l2: 0.181463\n",
      "[280]\tvalid_0's l2: 0.181414\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[287]\tvalid_0's l2: 0.181383\n",
      "Validation ROC-AUC score: 0.8013861063201363\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Функция для оптимизации гиперпараметров\n",
    "def optimize_lgb(trial):\n",
    "    param = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "    }\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        param,\n",
    "        train_data,\n",
    "        valid_sets=[valid_data],\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=10), lgb.log_evaluation(period=10)]\n",
    "    )\n",
    "    \n",
    "    y_pred = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "    roc_auc = roc_auc_score(y_valid, y_pred)\n",
    "    return roc_auc\n",
    "\n",
    "# Оптимизация гиперпараметров\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(optimize_lgb, n_trials=50)\n",
    "\n",
    "# Обучение модели с лучшими параметрами\n",
    "best_params = study.best_params\n",
    "print(f\"Лучшие параметры: {best_params}\")\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n",
    "\n",
    "model_lgb = lgb.train(\n",
    "    best_params,\n",
    "    train_data,\n",
    "    valid_sets=[valid_data],\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=10), lgb.log_evaluation(period=10)]\n",
    ")\n",
    "\n",
    "# Предсказание и оценка модели\n",
    "y_pred_lgb = model_lgb.predict(X_valid, num_iteration=model_lgb.best_iteration)\n",
    "valid_score_lgb = roc_auc_score(y_valid, y_pred_lgb)\n",
    "print('Validation ROC-AUC score:', valid_score_lgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.copy()\n",
    "y_test_pred_ljb = model_lgb.predict(X_test, num_iteration=model_lgb.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission_ljb = pd.DataFrame({'ID' : df_test.index, 'Target': y_test_pred_ljb})\n",
    "df_submission_ljb.set_index('ID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to submission_lightgbm_2024-11-08.csv\n"
     ]
    }
   ],
   "source": [
    "submission_filename = 'submission_lightgbm_{}.csv'.format(\n",
    "    datetime.datetime.now().strftime('%Y-%m-%d'))\n",
    "df_submission_ljb.to_csv(submission_filename)\n",
    "print('Submission saved to {}'.format(submission_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ee84861e709fc9cf5d48ba0f04b7f43b</th>\n",
       "      <td>0.943062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a9475ee47c8a10d6cf37c1461814653e</th>\n",
       "      <td>0.370806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b56ea18db1408fc68263757232c1facb</th>\n",
       "      <td>0.780914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9587640246910f0e1b033a6c8f6d8211</th>\n",
       "      <td>0.406293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3eb93fbd9056ebdb52ffff84e6c3664a</th>\n",
       "      <td>0.312379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Target\n",
       "ID                                        \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b  0.943062\n",
       "a9475ee47c8a10d6cf37c1461814653e  0.370806\n",
       "b56ea18db1408fc68263757232c1facb  0.780914\n",
       "9587640246910f0e1b033a6c8f6d8211  0.406293\n",
       "3eb93fbd9056ebdb52ffff84e6c3664a  0.312379"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission_ljb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:51:41,052] A new study created in memory with name: no-name-3901f0ce-7693-4c6d-84dc-c28d2b154f50\n",
      "[I 2024-11-08 13:51:51,915] Trial 0 finished with value: 0.7921682176944453 and parameters: {'iterations': 656, 'depth': 6, 'learning_rate': 0.009550167058006168, 'l2_leaf_reg': 8.590686894358699, 'border_count': 130}. Best is trial 0 with value: 0.7921682176944453.\n",
      "[I 2024-11-08 13:52:05,970] Trial 1 finished with value: 0.7850400983638326 and parameters: {'iterations': 809, 'depth': 6, 'learning_rate': 0.004583732281904796, 'l2_leaf_reg': 1.3425348965150832, 'border_count': 222}. Best is trial 0 with value: 0.7921682176944453.\n",
      "[I 2024-11-08 13:52:12,001] Trial 2 finished with value: 0.8025205222958464 and parameters: {'iterations': 649, 'depth': 4, 'learning_rate': 0.036810270392374264, 'l2_leaf_reg': 3.297953034227244, 'border_count': 52}. Best is trial 2 with value: 0.8025205222958464.\n",
      "[I 2024-11-08 13:52:24,745] Trial 3 finished with value: 0.7821203039428015 and parameters: {'iterations': 100, 'depth': 10, 'learning_rate': 0.02171302623026925, 'l2_leaf_reg': 7.6960212791533085, 'border_count': 171}. Best is trial 2 with value: 0.8025205222958464.\n",
      "[I 2024-11-08 13:52:41,691] Trial 4 finished with value: 0.7594102086549928 and parameters: {'iterations': 764, 'depth': 7, 'learning_rate': 0.0002787315862494152, 'l2_leaf_reg': 9.171645613396546, 'border_count': 171}. Best is trial 2 with value: 0.8025205222958464.\n",
      "[I 2024-11-08 13:53:25,770] Trial 5 finished with value: 0.8008226777606139 and parameters: {'iterations': 704, 'depth': 9, 'learning_rate': 0.014894768804397251, 'l2_leaf_reg': 5.4435856402492675, 'border_count': 213}. Best is trial 2 with value: 0.8025205222958464.\n",
      "[I 2024-11-08 13:53:31,483] Trial 6 finished with value: 0.8029401367534249 and parameters: {'iterations': 342, 'depth': 7, 'learning_rate': 0.07289530897226905, 'l2_leaf_reg': 3.5084958997894167, 'border_count': 51}. Best is trial 6 with value: 0.8029401367534249.\n",
      "[I 2024-11-08 13:53:38,662] Trial 7 finished with value: 0.7922589239744295 and parameters: {'iterations': 560, 'depth': 5, 'learning_rate': 0.01309398472137602, 'l2_leaf_reg': 9.034766957205905, 'border_count': 198}. Best is trial 6 with value: 0.8029401367534249.\n",
      "[I 2024-11-08 13:53:42,336] Trial 8 finished with value: 0.7971654444165154 and parameters: {'iterations': 157, 'depth': 7, 'learning_rate': 0.05805688971466082, 'l2_leaf_reg': 6.729991555908263, 'border_count': 207}. Best is trial 6 with value: 0.8029401367534249.\n",
      "[I 2024-11-08 13:53:56,731] Trial 9 finished with value: 0.79897682846197 and parameters: {'iterations': 578, 'depth': 8, 'learning_rate': 0.014625530212370104, 'l2_leaf_reg': 7.102963979762627, 'border_count': 78}. Best is trial 6 with value: 0.8029401367534249.\n",
      "[I 2024-11-08 13:54:14,343] Trial 10 finished with value: 0.7673246840691652 and parameters: {'iterations': 389, 'depth': 9, 'learning_rate': 0.0010722800505882405, 'l2_leaf_reg': 4.431718984233808, 'border_count': 103}. Best is trial 6 with value: 0.8029401367534249.\n",
      "[I 2024-11-08 13:54:20,259] Trial 11 finished with value: 0.8020438051801433 and parameters: {'iterations': 958, 'depth': 4, 'learning_rate': 0.06377600990407116, 'l2_leaf_reg': 3.419764087791156, 'border_count': 34}. Best is trial 6 with value: 0.8029401367534249.\n",
      "[I 2024-11-08 13:54:23,728] Trial 12 finished with value: 0.8015704562596381 and parameters: {'iterations': 370, 'depth': 4, 'learning_rate': 0.09339612255113881, 'l2_leaf_reg': 2.9372893748361193, 'border_count': 33}. Best is trial 6 with value: 0.8029401367534249.\n",
      "[I 2024-11-08 13:54:26,796] Trial 13 finished with value: 0.8022761714837471 and parameters: {'iterations': 385, 'depth': 5, 'learning_rate': 0.09908844051863944, 'l2_leaf_reg': 2.2908018509795376, 'border_count': 80}. Best is trial 6 with value: 0.8029401367534249.\n",
      "[I 2024-11-08 13:54:30,879] Trial 14 finished with value: 0.7992431508729775 and parameters: {'iterations': 301, 'depth': 6, 'learning_rate': 0.04002699867864334, 'l2_leaf_reg': 4.106228107075782, 'border_count': 63}. Best is trial 6 with value: 0.8029401367534249.\n",
      "[I 2024-11-08 13:54:33,839] Trial 15 finished with value: 0.7921085301423313 and parameters: {'iterations': 246, 'depth': 5, 'learning_rate': 0.030354198261641107, 'l2_leaf_reg': 1.1050623889816404, 'border_count': 119}. Best is trial 6 with value: 0.8029401367534249.\n",
      "[I 2024-11-08 13:54:45,280] Trial 16 finished with value: 0.7826884714746373 and parameters: {'iterations': 485, 'depth': 8, 'learning_rate': 0.005087740509492839, 'l2_leaf_reg': 5.1045980997421, 'border_count': 58}. Best is trial 6 with value: 0.8029401367534249.\n",
      "[I 2024-11-08 13:54:54,611] Trial 17 finished with value: 0.8043715413824688 and parameters: {'iterations': 894, 'depth': 4, 'learning_rate': 0.03398507158484823, 'l2_leaf_reg': 2.7653939375329553, 'border_count': 253}. Best is trial 17 with value: 0.8043715413824688.\n",
      "[I 2024-11-08 13:55:34,030] Trial 18 finished with value: 0.7806426453773753 and parameters: {'iterations': 995, 'depth': 8, 'learning_rate': 0.0020680665949477754, 'l2_leaf_reg': 2.300147761141707, 'border_count': 254}. Best is trial 17 with value: 0.8043715413824688.\n",
      "[I 2024-11-08 13:56:20,720] Trial 19 finished with value: 0.8050805856367154 and parameters: {'iterations': 867, 'depth': 9, 'learning_rate': 0.0326805041968812, 'l2_leaf_reg': 4.2944561285971234, 'border_count': 255}. Best is trial 19 with value: 0.8050805856367154.\n",
      "[I 2024-11-08 13:58:10,688] Trial 20 finished with value: 0.8037802272999115 and parameters: {'iterations': 874, 'depth': 10, 'learning_rate': 0.025594048061771766, 'l2_leaf_reg': 6.130166156598896, 'border_count': 251}. Best is trial 19 with value: 0.8050805856367154.\n",
      "[I 2024-11-08 13:59:33,036] Trial 21 finished with value: 0.8028553443975673 and parameters: {'iterations': 878, 'depth': 10, 'learning_rate': 0.02551061177945682, 'l2_leaf_reg': 5.966343131548942, 'border_count': 254}. Best is trial 19 with value: 0.8050805856367154.\n",
      "[I 2024-11-08 14:00:04,026] Trial 22 finished with value: 0.8042734329060608 and parameters: {'iterations': 875, 'depth': 9, 'learning_rate': 0.03883299248804425, 'l2_leaf_reg': 4.7257335727488226, 'border_count': 237}. Best is trial 19 with value: 0.8050805856367154.\n",
      "[I 2024-11-08 14:00:28,958] Trial 23 finished with value: 0.8024875061498936 and parameters: {'iterations': 906, 'depth': 9, 'learning_rate': 0.04527288707608038, 'l2_leaf_reg': 4.700366296567042, 'border_count': 232}. Best is trial 19 with value: 0.8050805856367154.\n",
      "[I 2024-11-08 14:01:16,795] Trial 24 finished with value: 0.7990188134067642 and parameters: {'iterations': 816, 'depth': 9, 'learning_rate': 0.009894029206149116, 'l2_leaf_reg': 4.187581474467812, 'border_count': 187}. Best is trial 19 with value: 0.8050805856367154.\n",
      "[I 2024-11-08 14:01:33,209] Trial 25 finished with value: 0.8037532034082062 and parameters: {'iterations': 716, 'depth': 8, 'learning_rate': 0.050207349383428274, 'l2_leaf_reg': 4.918809102500148, 'border_count': 236}. Best is trial 19 with value: 0.8050805856367154.\n",
      "[I 2024-11-08 14:02:24,927] Trial 26 finished with value: 0.8042566702601914 and parameters: {'iterations': 804, 'depth': 9, 'learning_rate': 0.020810281565885734, 'l2_leaf_reg': 3.998407147668976, 'border_count': 237}. Best is trial 19 with value: 0.8050805856367154.\n",
      "[I 2024-11-08 14:04:09,900] Trial 27 finished with value: 0.7969695799492436 and parameters: {'iterations': 915, 'depth': 10, 'learning_rate': 0.006705666330855929, 'l2_leaf_reg': 5.570491245321844, 'border_count': 150}. Best is trial 19 with value: 0.8050805856367154.\n",
      "[I 2024-11-08 14:04:28,340] Trial 28 finished with value: 0.8028658797988263 and parameters: {'iterations': 982, 'depth': 8, 'learning_rate': 0.03472846361150384, 'l2_leaf_reg': 4.739699252180355, 'border_count': 223}. Best is trial 19 with value: 0.8050805856367154.\n",
      "[I 2024-11-08 14:04:40,029] Trial 29 finished with value: 0.7904258424854899 and parameters: {'iterations': 628, 'depth': 6, 'learning_rate': 0.008504832695946271, 'l2_leaf_reg': 2.6515214342974773, 'border_count': 189}. Best is trial 19 with value: 0.8050805856367154.\n",
      "[I 2024-11-08 14:05:31,168] Trial 30 finished with value: 0.8028106178985424 and parameters: {'iterations': 730, 'depth': 9, 'learning_rate': 0.017524917638535187, 'l2_leaf_reg': 3.7295016864282737, 'border_count': 238}. Best is trial 19 with value: 0.8050805856367154.\n",
      "[I 2024-11-08 14:06:12,503] Trial 31 finished with value: 0.8034479117620589 and parameters: {'iterations': 820, 'depth': 9, 'learning_rate': 0.0296193010572342, 'l2_leaf_reg': 4.237300879395789, 'border_count': 240}. Best is trial 19 with value: 0.8050805856367154.\n",
      "[I 2024-11-08 14:08:01,455] Trial 32 finished with value: 0.8015331319570367 and parameters: {'iterations': 837, 'depth': 10, 'learning_rate': 0.019545929437022526, 'l2_leaf_reg': 3.957336971588191, 'border_count': 218}. Best is trial 19 with value: 0.8050805856367154.\n",
      "[I 2024-11-08 14:08:17,959] Trial 33 finished with value: 0.8029102929773679 and parameters: {'iterations': 763, 'depth': 8, 'learning_rate': 0.04369081793266236, 'l2_leaf_reg': 2.9996498540954963, 'border_count': 227}. Best is trial 19 with value: 0.8050805856367154.\n",
      "[I 2024-11-08 14:09:22,069] Trial 34 finished with value: 0.8009433453118365 and parameters: {'iterations': 909, 'depth': 9, 'learning_rate': 0.011274950433322972, 'l2_leaf_reg': 1.821519578069296, 'border_count': 244}. Best is trial 19 with value: 0.8050805856367154.\n",
      "[I 2024-11-08 14:09:40,961] Trial 35 finished with value: 0.8041722695549385 and parameters: {'iterations': 784, 'depth': 7, 'learning_rate': 0.019324266656908104, 'l2_leaf_reg': 3.45085966212805, 'border_count': 205}. Best is trial 19 with value: 0.8050805856367154.\n",
      "[I 2024-11-08 14:10:05,799] Trial 36 finished with value: 0.7994088582437088 and parameters: {'iterations': 940, 'depth': 10, 'learning_rate': 0.056505549853604876, 'l2_leaf_reg': 3.1011198911605984, 'border_count': 153}. Best is trial 19 with value: 0.8050805856367154.\n",
      "[I 2024-11-08 14:10:48,419] Trial 37 finished with value: 0.8037762716288067 and parameters: {'iterations': 655, 'depth': 9, 'learning_rate': 0.02316526663089718, 'l2_leaf_reg': 9.881999915650638, 'border_count': 224}. Best is trial 19 with value: 0.8050805856367154.\n",
      "[I 2024-11-08 14:11:04,255] Trial 38 finished with value: 0.8064906453078183 and parameters: {'iterations': 858, 'depth': 7, 'learning_rate': 0.03350675324056129, 'l2_leaf_reg': 3.7324438661185613, 'border_count': 169}. Best is trial 38 with value: 0.8064906453078183.\n",
      "[I 2024-11-08 14:11:08,901] Trial 39 finished with value: 0.8035399496540981 and parameters: {'iterations': 863, 'depth': 5, 'learning_rate': 0.0788596774606641, 'l2_leaf_reg': 1.5827385360870647, 'border_count': 175}. Best is trial 38 with value: 0.8064906453078183.\n",
      "[I 2024-11-08 14:11:14,748] Trial 40 finished with value: 0.8025347000477265 and parameters: {'iterations': 485, 'depth': 7, 'learning_rate': 0.07026073089937275, 'l2_leaf_reg': 3.7057631501222033, 'border_count': 137}. Best is trial 38 with value: 0.8064906453078183.\n",
      "[I 2024-11-08 14:11:26,545] Trial 41 finished with value: 0.8041996067671271 and parameters: {'iterations': 765, 'depth': 6, 'learning_rate': 0.036601502767640216, 'l2_leaf_reg': 4.370972261405022, 'border_count': 245}. Best is trial 38 with value: 0.8064906453078183.\n",
      "[I 2024-11-08 14:11:36,212] Trial 42 finished with value: 0.7973249245426361 and parameters: {'iterations': 857, 'depth': 4, 'learning_rate': 0.015038378030021622, 'l2_leaf_reg': 3.716680829924608, 'border_count': 215}. Best is trial 38 with value: 0.8064906453078183.\n",
      "[I 2024-11-08 14:11:47,302] Trial 43 finished with value: 0.8012458562386926 and parameters: {'iterations': 931, 'depth': 7, 'learning_rate': 0.03150264909855034, 'l2_leaf_reg': 5.209425075334055, 'border_count': 199}. Best is trial 38 with value: 0.8064906453078183.\n",
      "[I 2024-11-08 14:11:58,417] Trial 44 finished with value: 0.8025512668682936 and parameters: {'iterations': 693, 'depth': 8, 'learning_rate': 0.04906246865934577, 'l2_leaf_reg': 4.518913045017972, 'border_count': 163}. Best is trial 38 with value: 0.8064906453078183.\n",
      "[I 2024-11-08 14:12:34,194] Trial 45 finished with value: 0.8007690607928684 and parameters: {'iterations': 798, 'depth': 9, 'learning_rate': 0.012936147556059008, 'l2_leaf_reg': 3.22177943143243, 'border_count': 109}. Best is trial 38 with value: 0.8064906453078183.\n",
      "[I 2024-11-08 14:14:15,752] Trial 46 finished with value: 0.8021085841901148 and parameters: {'iterations': 997, 'depth': 10, 'learning_rate': 0.02171136683999155, 'l2_leaf_reg': 3.940103684910614, 'border_count': 231}. Best is trial 38 with value: 0.8064906453078183.\n",
      "[I 2024-11-08 14:14:24,584] Trial 47 finished with value: 0.7993618210061176 and parameters: {'iterations': 892, 'depth': 8, 'learning_rate': 0.06931722947306285, 'l2_leaf_reg': 2.595435591738454, 'border_count': 190}. Best is trial 38 with value: 0.8064906453078183.\n",
      "[I 2024-11-08 14:14:53,801] Trial 48 finished with value: 0.8040796441869925 and parameters: {'iterations': 957, 'depth': 9, 'learning_rate': 0.04129070231691715, 'l2_leaf_reg': 3.457711334611779, 'border_count': 210}. Best is trial 38 with value: 0.8064906453078183.\n",
      "[I 2024-11-08 14:15:05,762] Trial 49 finished with value: 0.7987890319971495 and parameters: {'iterations': 744, 'depth': 5, 'learning_rate': 0.017160677638276337, 'l2_leaf_reg': 4.545503110647504, 'border_count': 246}. Best is trial 38 with value: 0.8064906453078183.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'iterations': 858, 'depth': 7, 'learning_rate': 0.03350675324056129, 'l2_leaf_reg': 3.7324438661185613, 'border_count': 169}\n",
      "0:\tlearn: 0.6876141\ttest: 0.6878263\tbest: 0.6878263 (0)\ttotal: 25.8ms\tremaining: 22.1s\n",
      "1:\tlearn: 0.6821805\ttest: 0.6825555\tbest: 0.6825555 (1)\ttotal: 50.4ms\tremaining: 21.6s\n",
      "2:\tlearn: 0.6775968\ttest: 0.6781654\tbest: 0.6781654 (2)\ttotal: 73.9ms\tremaining: 21.1s\n",
      "3:\tlearn: 0.6728753\ttest: 0.6735111\tbest: 0.6735111 (3)\ttotal: 98ms\tremaining: 20.9s\n",
      "4:\tlearn: 0.6682640\ttest: 0.6692257\tbest: 0.6692257 (4)\ttotal: 122ms\tremaining: 20.8s\n",
      "5:\tlearn: 0.6643819\ttest: 0.6655167\tbest: 0.6655167 (5)\ttotal: 146ms\tremaining: 20.7s\n",
      "6:\tlearn: 0.6604024\ttest: 0.6617360\tbest: 0.6617360 (6)\ttotal: 172ms\tremaining: 21s\n",
      "7:\tlearn: 0.6565936\ttest: 0.6581088\tbest: 0.6581088 (7)\ttotal: 198ms\tremaining: 21s\n",
      "8:\tlearn: 0.6533322\ttest: 0.6549223\tbest: 0.6549223 (8)\ttotal: 222ms\tremaining: 20.9s\n",
      "9:\tlearn: 0.6499745\ttest: 0.6515968\tbest: 0.6515968 (9)\ttotal: 245ms\tremaining: 20.8s\n",
      "10:\tlearn: 0.6467569\ttest: 0.6485447\tbest: 0.6485447 (10)\ttotal: 268ms\tremaining: 20.6s\n",
      "11:\tlearn: 0.6438107\ttest: 0.6456586\tbest: 0.6456586 (11)\ttotal: 291ms\tremaining: 20.5s\n",
      "12:\tlearn: 0.6405817\ttest: 0.6427862\tbest: 0.6427862 (12)\ttotal: 314ms\tremaining: 20.4s\n",
      "13:\tlearn: 0.6378976\ttest: 0.6403090\tbest: 0.6403090 (13)\ttotal: 338ms\tremaining: 20.4s\n",
      "14:\tlearn: 0.6352272\ttest: 0.6378048\tbest: 0.6378048 (14)\ttotal: 364ms\tremaining: 20.5s\n",
      "15:\tlearn: 0.6321102\ttest: 0.6347250\tbest: 0.6347250 (15)\ttotal: 397ms\tremaining: 20.9s\n",
      "16:\tlearn: 0.6295103\ttest: 0.6323078\tbest: 0.6323078 (16)\ttotal: 432ms\tremaining: 21.4s\n",
      "17:\tlearn: 0.6271138\ttest: 0.6300958\tbest: 0.6300958 (17)\ttotal: 462ms\tremaining: 21.6s\n",
      "18:\tlearn: 0.6249092\ttest: 0.6280464\tbest: 0.6280464 (18)\ttotal: 487ms\tremaining: 21.5s\n",
      "19:\tlearn: 0.6226538\ttest: 0.6257190\tbest: 0.6257190 (19)\ttotal: 512ms\tremaining: 21.5s\n",
      "20:\tlearn: 0.6205470\ttest: 0.6237652\tbest: 0.6237652 (20)\ttotal: 537ms\tremaining: 21.4s\n",
      "21:\tlearn: 0.6183763\ttest: 0.6217832\tbest: 0.6217832 (21)\ttotal: 563ms\tremaining: 21.4s\n",
      "22:\tlearn: 0.6163555\ttest: 0.6199996\tbest: 0.6199996 (22)\ttotal: 590ms\tremaining: 21.4s\n",
      "23:\tlearn: 0.6144203\ttest: 0.6181443\tbest: 0.6181443 (23)\ttotal: 615ms\tremaining: 21.4s\n",
      "24:\tlearn: 0.6123474\ttest: 0.6161817\tbest: 0.6161817 (24)\ttotal: 638ms\tremaining: 21.3s\n",
      "25:\tlearn: 0.6105195\ttest: 0.6145091\tbest: 0.6145091 (25)\ttotal: 662ms\tremaining: 21.2s\n",
      "26:\tlearn: 0.6087937\ttest: 0.6128756\tbest: 0.6128756 (26)\ttotal: 686ms\tremaining: 21.1s\n",
      "27:\tlearn: 0.6070870\ttest: 0.6113945\tbest: 0.6113945 (27)\ttotal: 708ms\tremaining: 21s\n",
      "28:\tlearn: 0.6052417\ttest: 0.6096357\tbest: 0.6096357 (28)\ttotal: 732ms\tremaining: 20.9s\n",
      "29:\tlearn: 0.6038825\ttest: 0.6083762\tbest: 0.6083762 (29)\ttotal: 754ms\tremaining: 20.8s\n",
      "30:\tlearn: 0.6022060\ttest: 0.6068306\tbest: 0.6068306 (30)\ttotal: 778ms\tremaining: 20.8s\n",
      "31:\tlearn: 0.6006126\ttest: 0.6054498\tbest: 0.6054498 (31)\ttotal: 809ms\tremaining: 20.9s\n",
      "32:\tlearn: 0.5991759\ttest: 0.6041877\tbest: 0.6041877 (32)\ttotal: 839ms\tremaining: 21s\n",
      "33:\tlearn: 0.5978914\ttest: 0.6029777\tbest: 0.6029777 (33)\ttotal: 863ms\tremaining: 20.9s\n",
      "34:\tlearn: 0.5965227\ttest: 0.6018099\tbest: 0.6018099 (34)\ttotal: 888ms\tremaining: 20.9s\n",
      "35:\tlearn: 0.5952121\ttest: 0.6006211\tbest: 0.6006211 (35)\ttotal: 912ms\tremaining: 20.8s\n",
      "36:\tlearn: 0.5938726\ttest: 0.5995412\tbest: 0.5995412 (36)\ttotal: 937ms\tremaining: 20.8s\n",
      "37:\tlearn: 0.5925946\ttest: 0.5984547\tbest: 0.5984547 (37)\ttotal: 959ms\tremaining: 20.7s\n",
      "38:\tlearn: 0.5913511\ttest: 0.5973634\tbest: 0.5973634 (38)\ttotal: 983ms\tremaining: 20.6s\n",
      "39:\tlearn: 0.5902257\ttest: 0.5964121\tbest: 0.5964121 (39)\ttotal: 1.01s\tremaining: 20.6s\n",
      "40:\tlearn: 0.5890294\ttest: 0.5954166\tbest: 0.5954166 (40)\ttotal: 1.03s\tremaining: 20.6s\n",
      "41:\tlearn: 0.5879564\ttest: 0.5944605\tbest: 0.5944605 (41)\ttotal: 1.06s\tremaining: 20.6s\n",
      "42:\tlearn: 0.5867584\ttest: 0.5934133\tbest: 0.5934133 (42)\ttotal: 1.08s\tremaining: 20.5s\n",
      "43:\tlearn: 0.5857319\ttest: 0.5926242\tbest: 0.5926242 (43)\ttotal: 1.1s\tremaining: 20.4s\n",
      "44:\tlearn: 0.5846419\ttest: 0.5917315\tbest: 0.5917315 (44)\ttotal: 1.13s\tremaining: 20.4s\n",
      "45:\tlearn: 0.5837238\ttest: 0.5910510\tbest: 0.5910510 (45)\ttotal: 1.15s\tremaining: 20.3s\n",
      "46:\tlearn: 0.5826461\ttest: 0.5900979\tbest: 0.5900979 (46)\ttotal: 1.17s\tremaining: 20.3s\n",
      "47:\tlearn: 0.5815423\ttest: 0.5891543\tbest: 0.5891543 (47)\ttotal: 1.2s\tremaining: 20.2s\n",
      "48:\tlearn: 0.5805449\ttest: 0.5883462\tbest: 0.5883462 (48)\ttotal: 1.22s\tremaining: 20.1s\n",
      "49:\tlearn: 0.5797165\ttest: 0.5876528\tbest: 0.5876528 (49)\ttotal: 1.24s\tremaining: 20.1s\n",
      "50:\tlearn: 0.5787133\ttest: 0.5868324\tbest: 0.5868324 (50)\ttotal: 1.27s\tremaining: 20.1s\n",
      "51:\tlearn: 0.5778648\ttest: 0.5860941\tbest: 0.5860941 (51)\ttotal: 1.29s\tremaining: 20s\n",
      "52:\tlearn: 0.5769559\ttest: 0.5853170\tbest: 0.5853170 (52)\ttotal: 1.31s\tremaining: 20s\n",
      "53:\tlearn: 0.5762838\ttest: 0.5847969\tbest: 0.5847969 (53)\ttotal: 1.34s\tremaining: 19.9s\n",
      "54:\tlearn: 0.5754317\ttest: 0.5840925\tbest: 0.5840925 (54)\ttotal: 1.36s\tremaining: 19.9s\n",
      "55:\tlearn: 0.5746791\ttest: 0.5835564\tbest: 0.5835564 (55)\ttotal: 1.39s\tremaining: 19.8s\n",
      "56:\tlearn: 0.5742051\ttest: 0.5832478\tbest: 0.5832478 (56)\ttotal: 1.41s\tremaining: 19.8s\n",
      "57:\tlearn: 0.5734018\ttest: 0.5825329\tbest: 0.5825329 (57)\ttotal: 1.43s\tremaining: 19.7s\n",
      "58:\tlearn: 0.5726906\ttest: 0.5819810\tbest: 0.5819810 (58)\ttotal: 1.46s\tremaining: 19.7s\n",
      "59:\tlearn: 0.5719926\ttest: 0.5814334\tbest: 0.5814334 (59)\ttotal: 1.5s\tremaining: 19.9s\n",
      "60:\tlearn: 0.5712141\ttest: 0.5808417\tbest: 0.5808417 (60)\ttotal: 1.53s\tremaining: 20s\n",
      "61:\tlearn: 0.5703150\ttest: 0.5800895\tbest: 0.5800895 (61)\ttotal: 1.56s\tremaining: 20s\n",
      "62:\tlearn: 0.5695060\ttest: 0.5794753\tbest: 0.5794753 (62)\ttotal: 1.58s\tremaining: 20s\n",
      "63:\tlearn: 0.5688558\ttest: 0.5789436\tbest: 0.5789436 (63)\ttotal: 1.6s\tremaining: 19.9s\n",
      "64:\tlearn: 0.5682844\ttest: 0.5785232\tbest: 0.5785232 (64)\ttotal: 1.63s\tremaining: 19.9s\n",
      "65:\tlearn: 0.5675846\ttest: 0.5780015\tbest: 0.5780015 (65)\ttotal: 1.65s\tremaining: 19.8s\n",
      "66:\tlearn: 0.5669064\ttest: 0.5774609\tbest: 0.5774609 (66)\ttotal: 1.67s\tremaining: 19.8s\n",
      "67:\tlearn: 0.5661980\ttest: 0.5768538\tbest: 0.5768538 (67)\ttotal: 1.7s\tremaining: 19.8s\n",
      "68:\tlearn: 0.5655581\ttest: 0.5763783\tbest: 0.5763783 (68)\ttotal: 1.72s\tremaining: 19.7s\n",
      "69:\tlearn: 0.5649329\ttest: 0.5758548\tbest: 0.5758548 (69)\ttotal: 1.75s\tremaining: 19.7s\n",
      "70:\tlearn: 0.5642593\ttest: 0.5752862\tbest: 0.5752862 (70)\ttotal: 1.77s\tremaining: 19.6s\n",
      "71:\tlearn: 0.5636430\ttest: 0.5748263\tbest: 0.5748263 (71)\ttotal: 1.79s\tremaining: 19.6s\n",
      "72:\tlearn: 0.5630324\ttest: 0.5744142\tbest: 0.5744142 (72)\ttotal: 1.82s\tremaining: 19.6s\n",
      "73:\tlearn: 0.5624571\ttest: 0.5740503\tbest: 0.5740503 (73)\ttotal: 1.84s\tremaining: 19.5s\n",
      "74:\tlearn: 0.5619334\ttest: 0.5736438\tbest: 0.5736438 (74)\ttotal: 1.87s\tremaining: 19.5s\n",
      "75:\tlearn: 0.5613858\ttest: 0.5733047\tbest: 0.5733047 (75)\ttotal: 1.9s\tremaining: 19.6s\n",
      "76:\tlearn: 0.5607440\ttest: 0.5727763\tbest: 0.5727763 (76)\ttotal: 1.93s\tremaining: 19.6s\n",
      "77:\tlearn: 0.5601642\ttest: 0.5723763\tbest: 0.5723763 (77)\ttotal: 1.96s\tremaining: 19.6s\n",
      "78:\tlearn: 0.5595541\ttest: 0.5719373\tbest: 0.5719373 (78)\ttotal: 1.98s\tremaining: 19.5s\n",
      "79:\tlearn: 0.5588936\ttest: 0.5715593\tbest: 0.5715593 (79)\ttotal: 2.01s\tremaining: 19.5s\n",
      "80:\tlearn: 0.5584572\ttest: 0.5712929\tbest: 0.5712929 (80)\ttotal: 2.03s\tremaining: 19.5s\n",
      "81:\tlearn: 0.5578590\ttest: 0.5709023\tbest: 0.5709023 (81)\ttotal: 2.06s\tremaining: 19.5s\n",
      "82:\tlearn: 0.5572801\ttest: 0.5705797\tbest: 0.5705797 (82)\ttotal: 2.08s\tremaining: 19.4s\n",
      "83:\tlearn: 0.5567185\ttest: 0.5702015\tbest: 0.5702015 (83)\ttotal: 2.1s\tremaining: 19.4s\n",
      "84:\tlearn: 0.5562474\ttest: 0.5699152\tbest: 0.5699152 (84)\ttotal: 2.13s\tremaining: 19.4s\n",
      "85:\tlearn: 0.5557903\ttest: 0.5695489\tbest: 0.5695489 (85)\ttotal: 2.15s\tremaining: 19.3s\n",
      "86:\tlearn: 0.5552748\ttest: 0.5691589\tbest: 0.5691589 (86)\ttotal: 2.17s\tremaining: 19.3s\n",
      "87:\tlearn: 0.5547657\ttest: 0.5687669\tbest: 0.5687669 (87)\ttotal: 2.2s\tremaining: 19.2s\n",
      "88:\tlearn: 0.5542163\ttest: 0.5684553\tbest: 0.5684553 (88)\ttotal: 2.22s\tremaining: 19.2s\n",
      "89:\tlearn: 0.5537079\ttest: 0.5681614\tbest: 0.5681614 (89)\ttotal: 2.24s\tremaining: 19.1s\n",
      "90:\tlearn: 0.5532046\ttest: 0.5678481\tbest: 0.5678481 (90)\ttotal: 2.27s\tremaining: 19.1s\n",
      "91:\tlearn: 0.5526909\ttest: 0.5674975\tbest: 0.5674975 (91)\ttotal: 2.29s\tremaining: 19.1s\n",
      "92:\tlearn: 0.5522230\ttest: 0.5671362\tbest: 0.5671362 (92)\ttotal: 2.31s\tremaining: 19s\n",
      "93:\tlearn: 0.5518289\ttest: 0.5669255\tbest: 0.5669255 (93)\ttotal: 2.34s\tremaining: 19s\n",
      "94:\tlearn: 0.5513568\ttest: 0.5665686\tbest: 0.5665686 (94)\ttotal: 2.36s\tremaining: 19s\n",
      "95:\tlearn: 0.5508740\ttest: 0.5662628\tbest: 0.5662628 (95)\ttotal: 2.39s\tremaining: 18.9s\n",
      "96:\tlearn: 0.5503486\ttest: 0.5658959\tbest: 0.5658959 (96)\ttotal: 2.41s\tremaining: 18.9s\n",
      "97:\tlearn: 0.5496595\ttest: 0.5654995\tbest: 0.5654995 (97)\ttotal: 2.43s\tremaining: 18.9s\n",
      "98:\tlearn: 0.5492268\ttest: 0.5652645\tbest: 0.5652645 (98)\ttotal: 2.46s\tremaining: 18.8s\n",
      "99:\tlearn: 0.5488224\ttest: 0.5649928\tbest: 0.5649928 (99)\ttotal: 2.48s\tremaining: 18.8s\n",
      "100:\tlearn: 0.5483810\ttest: 0.5646783\tbest: 0.5646783 (100)\ttotal: 2.5s\tremaining: 18.7s\n",
      "101:\tlearn: 0.5479452\ttest: 0.5644347\tbest: 0.5644347 (101)\ttotal: 2.52s\tremaining: 18.7s\n",
      "102:\tlearn: 0.5475539\ttest: 0.5641886\tbest: 0.5641886 (102)\ttotal: 2.54s\tremaining: 18.7s\n",
      "103:\tlearn: 0.5472621\ttest: 0.5640037\tbest: 0.5640037 (103)\ttotal: 2.57s\tremaining: 18.6s\n",
      "104:\tlearn: 0.5468585\ttest: 0.5637487\tbest: 0.5637487 (104)\ttotal: 2.59s\tremaining: 18.6s\n",
      "105:\tlearn: 0.5465623\ttest: 0.5635956\tbest: 0.5635956 (105)\ttotal: 2.62s\tremaining: 18.6s\n",
      "106:\tlearn: 0.5461961\ttest: 0.5633963\tbest: 0.5633963 (106)\ttotal: 2.64s\tremaining: 18.5s\n",
      "107:\tlearn: 0.5458326\ttest: 0.5631068\tbest: 0.5631068 (107)\ttotal: 2.66s\tremaining: 18.5s\n",
      "108:\tlearn: 0.5454669\ttest: 0.5628424\tbest: 0.5628424 (108)\ttotal: 2.68s\tremaining: 18.4s\n",
      "109:\tlearn: 0.5450259\ttest: 0.5625056\tbest: 0.5625056 (109)\ttotal: 2.71s\tremaining: 18.4s\n",
      "110:\tlearn: 0.5446966\ttest: 0.5623502\tbest: 0.5623502 (110)\ttotal: 2.73s\tremaining: 18.4s\n",
      "111:\tlearn: 0.5442705\ttest: 0.5620465\tbest: 0.5620465 (111)\ttotal: 2.75s\tremaining: 18.3s\n",
      "112:\tlearn: 0.5437586\ttest: 0.5617793\tbest: 0.5617793 (112)\ttotal: 2.78s\tremaining: 18.3s\n",
      "113:\tlearn: 0.5433059\ttest: 0.5615340\tbest: 0.5615340 (113)\ttotal: 2.8s\tremaining: 18.3s\n",
      "114:\tlearn: 0.5428491\ttest: 0.5612506\tbest: 0.5612506 (114)\ttotal: 2.82s\tremaining: 18.3s\n",
      "115:\tlearn: 0.5425083\ttest: 0.5609800\tbest: 0.5609800 (115)\ttotal: 2.85s\tremaining: 18.2s\n",
      "116:\tlearn: 0.5420980\ttest: 0.5607339\tbest: 0.5607339 (116)\ttotal: 2.87s\tremaining: 18.2s\n",
      "117:\tlearn: 0.5417066\ttest: 0.5604383\tbest: 0.5604383 (117)\ttotal: 2.89s\tremaining: 18.1s\n",
      "118:\tlearn: 0.5412602\ttest: 0.5602917\tbest: 0.5602917 (118)\ttotal: 2.92s\tremaining: 18.1s\n",
      "119:\tlearn: 0.5408394\ttest: 0.5601195\tbest: 0.5601195 (119)\ttotal: 2.94s\tremaining: 18.1s\n",
      "120:\tlearn: 0.5405442\ttest: 0.5599430\tbest: 0.5599430 (120)\ttotal: 2.96s\tremaining: 18.1s\n",
      "121:\tlearn: 0.5402075\ttest: 0.5596870\tbest: 0.5596870 (121)\ttotal: 2.99s\tremaining: 18s\n",
      "122:\tlearn: 0.5398780\ttest: 0.5594692\tbest: 0.5594692 (122)\ttotal: 3.01s\tremaining: 18s\n",
      "123:\tlearn: 0.5395095\ttest: 0.5593728\tbest: 0.5593728 (123)\ttotal: 3.03s\tremaining: 18s\n",
      "124:\tlearn: 0.5391005\ttest: 0.5590565\tbest: 0.5590565 (124)\ttotal: 3.05s\tremaining: 17.9s\n",
      "125:\tlearn: 0.5387265\ttest: 0.5588513\tbest: 0.5588513 (125)\ttotal: 3.08s\tremaining: 17.9s\n",
      "126:\tlearn: 0.5384126\ttest: 0.5586404\tbest: 0.5586404 (126)\ttotal: 3.1s\tremaining: 17.9s\n",
      "127:\tlearn: 0.5381120\ttest: 0.5584460\tbest: 0.5584460 (127)\ttotal: 3.12s\tremaining: 17.8s\n",
      "128:\tlearn: 0.5377188\ttest: 0.5582375\tbest: 0.5582375 (128)\ttotal: 3.15s\tremaining: 17.8s\n",
      "129:\tlearn: 0.5373425\ttest: 0.5580726\tbest: 0.5580726 (129)\ttotal: 3.17s\tremaining: 17.7s\n",
      "130:\tlearn: 0.5369550\ttest: 0.5579495\tbest: 0.5579495 (130)\ttotal: 3.19s\tremaining: 17.7s\n",
      "131:\tlearn: 0.5366122\ttest: 0.5578342\tbest: 0.5578342 (131)\ttotal: 3.22s\tremaining: 17.7s\n",
      "132:\tlearn: 0.5362016\ttest: 0.5577072\tbest: 0.5577072 (132)\ttotal: 3.24s\tremaining: 17.7s\n",
      "133:\tlearn: 0.5358684\ttest: 0.5575684\tbest: 0.5575684 (133)\ttotal: 3.26s\tremaining: 17.6s\n",
      "134:\tlearn: 0.5355412\ttest: 0.5573643\tbest: 0.5573643 (134)\ttotal: 3.29s\tremaining: 17.6s\n",
      "135:\tlearn: 0.5351339\ttest: 0.5571808\tbest: 0.5571808 (135)\ttotal: 3.31s\tremaining: 17.6s\n",
      "136:\tlearn: 0.5348200\ttest: 0.5570219\tbest: 0.5570219 (136)\ttotal: 3.33s\tremaining: 17.5s\n",
      "137:\tlearn: 0.5344695\ttest: 0.5568409\tbest: 0.5568409 (137)\ttotal: 3.35s\tremaining: 17.5s\n",
      "138:\tlearn: 0.5341413\ttest: 0.5566421\tbest: 0.5566421 (138)\ttotal: 3.38s\tremaining: 17.5s\n",
      "139:\tlearn: 0.5337815\ttest: 0.5563932\tbest: 0.5563932 (139)\ttotal: 3.4s\tremaining: 17.4s\n",
      "140:\tlearn: 0.5333986\ttest: 0.5561667\tbest: 0.5561667 (140)\ttotal: 3.42s\tremaining: 17.4s\n",
      "141:\tlearn: 0.5330106\ttest: 0.5559540\tbest: 0.5559540 (141)\ttotal: 3.45s\tremaining: 17.4s\n",
      "142:\tlearn: 0.5326653\ttest: 0.5557899\tbest: 0.5557899 (142)\ttotal: 3.47s\tremaining: 17.4s\n",
      "143:\tlearn: 0.5323227\ttest: 0.5556114\tbest: 0.5556114 (143)\ttotal: 3.49s\tremaining: 17.3s\n",
      "144:\tlearn: 0.5320529\ttest: 0.5555283\tbest: 0.5555283 (144)\ttotal: 3.51s\tremaining: 17.3s\n",
      "145:\tlearn: 0.5316740\ttest: 0.5552729\tbest: 0.5552729 (145)\ttotal: 3.54s\tremaining: 17.3s\n",
      "146:\tlearn: 0.5313318\ttest: 0.5550907\tbest: 0.5550907 (146)\ttotal: 3.56s\tremaining: 17.2s\n",
      "147:\tlearn: 0.5309867\ttest: 0.5549555\tbest: 0.5549555 (147)\ttotal: 3.58s\tremaining: 17.2s\n",
      "148:\tlearn: 0.5307183\ttest: 0.5548742\tbest: 0.5548742 (148)\ttotal: 3.6s\tremaining: 17.2s\n",
      "149:\tlearn: 0.5303566\ttest: 0.5546924\tbest: 0.5546924 (149)\ttotal: 3.63s\tremaining: 17.1s\n",
      "150:\tlearn: 0.5300795\ttest: 0.5545332\tbest: 0.5545332 (150)\ttotal: 3.65s\tremaining: 17.1s\n",
      "151:\tlearn: 0.5297638\ttest: 0.5543762\tbest: 0.5543762 (151)\ttotal: 3.68s\tremaining: 17.1s\n",
      "152:\tlearn: 0.5294615\ttest: 0.5541991\tbest: 0.5541991 (152)\ttotal: 3.7s\tremaining: 17s\n",
      "153:\tlearn: 0.5291114\ttest: 0.5540391\tbest: 0.5540391 (153)\ttotal: 3.72s\tremaining: 17s\n",
      "154:\tlearn: 0.5287379\ttest: 0.5538055\tbest: 0.5538055 (154)\ttotal: 3.75s\tremaining: 17s\n",
      "155:\tlearn: 0.5283850\ttest: 0.5536438\tbest: 0.5536438 (155)\ttotal: 3.77s\tremaining: 17s\n",
      "156:\tlearn: 0.5280627\ttest: 0.5535013\tbest: 0.5535013 (156)\ttotal: 3.79s\tremaining: 16.9s\n",
      "157:\tlearn: 0.5277555\ttest: 0.5533393\tbest: 0.5533393 (157)\ttotal: 3.81s\tremaining: 16.9s\n",
      "158:\tlearn: 0.5274574\ttest: 0.5531284\tbest: 0.5531284 (158)\ttotal: 3.83s\tremaining: 16.9s\n",
      "159:\tlearn: 0.5271642\ttest: 0.5529647\tbest: 0.5529647 (159)\ttotal: 3.86s\tremaining: 16.8s\n",
      "160:\tlearn: 0.5268534\ttest: 0.5528193\tbest: 0.5528193 (160)\ttotal: 3.88s\tremaining: 16.8s\n",
      "161:\tlearn: 0.5265190\ttest: 0.5526473\tbest: 0.5526473 (161)\ttotal: 3.9s\tremaining: 16.8s\n",
      "162:\tlearn: 0.5261607\ttest: 0.5525024\tbest: 0.5525024 (162)\ttotal: 3.92s\tremaining: 16.7s\n",
      "163:\tlearn: 0.5257171\ttest: 0.5522537\tbest: 0.5522537 (163)\ttotal: 3.96s\tremaining: 16.7s\n",
      "164:\tlearn: 0.5253729\ttest: 0.5520684\tbest: 0.5520684 (164)\ttotal: 3.99s\tremaining: 16.8s\n",
      "165:\tlearn: 0.5250426\ttest: 0.5518403\tbest: 0.5518403 (165)\ttotal: 4.01s\tremaining: 16.7s\n",
      "166:\tlearn: 0.5247156\ttest: 0.5517260\tbest: 0.5517260 (166)\ttotal: 4.04s\tremaining: 16.7s\n",
      "167:\tlearn: 0.5244288\ttest: 0.5516139\tbest: 0.5516139 (167)\ttotal: 4.06s\tremaining: 16.7s\n",
      "168:\tlearn: 0.5241269\ttest: 0.5514642\tbest: 0.5514642 (168)\ttotal: 4.08s\tremaining: 16.6s\n",
      "169:\tlearn: 0.5238561\ttest: 0.5513259\tbest: 0.5513259 (169)\ttotal: 4.12s\tremaining: 16.7s\n",
      "170:\tlearn: 0.5236511\ttest: 0.5511832\tbest: 0.5511832 (170)\ttotal: 4.14s\tremaining: 16.6s\n",
      "171:\tlearn: 0.5233718\ttest: 0.5510711\tbest: 0.5510711 (171)\ttotal: 4.16s\tremaining: 16.6s\n",
      "172:\tlearn: 0.5230961\ttest: 0.5508775\tbest: 0.5508775 (172)\ttotal: 4.18s\tremaining: 16.6s\n",
      "173:\tlearn: 0.5228036\ttest: 0.5507708\tbest: 0.5507708 (173)\ttotal: 4.21s\tremaining: 16.5s\n",
      "174:\tlearn: 0.5225724\ttest: 0.5506457\tbest: 0.5506457 (174)\ttotal: 4.23s\tremaining: 16.5s\n",
      "175:\tlearn: 0.5223597\ttest: 0.5505076\tbest: 0.5505076 (175)\ttotal: 4.25s\tremaining: 16.5s\n",
      "176:\tlearn: 0.5221319\ttest: 0.5503906\tbest: 0.5503906 (176)\ttotal: 4.27s\tremaining: 16.4s\n",
      "177:\tlearn: 0.5218679\ttest: 0.5503465\tbest: 0.5503465 (177)\ttotal: 4.3s\tremaining: 16.4s\n",
      "178:\tlearn: 0.5215519\ttest: 0.5501857\tbest: 0.5501857 (178)\ttotal: 4.32s\tremaining: 16.4s\n",
      "179:\tlearn: 0.5212538\ttest: 0.5500924\tbest: 0.5500924 (179)\ttotal: 4.34s\tremaining: 16.4s\n",
      "180:\tlearn: 0.5209514\ttest: 0.5499173\tbest: 0.5499173 (180)\ttotal: 4.36s\tremaining: 16.3s\n",
      "181:\tlearn: 0.5206010\ttest: 0.5497763\tbest: 0.5497763 (181)\ttotal: 4.39s\tremaining: 16.3s\n",
      "182:\tlearn: 0.5203107\ttest: 0.5496320\tbest: 0.5496320 (182)\ttotal: 4.41s\tremaining: 16.3s\n",
      "183:\tlearn: 0.5200930\ttest: 0.5495524\tbest: 0.5495524 (183)\ttotal: 4.43s\tremaining: 16.2s\n",
      "184:\tlearn: 0.5198337\ttest: 0.5494435\tbest: 0.5494435 (184)\ttotal: 4.45s\tremaining: 16.2s\n",
      "185:\tlearn: 0.5195911\ttest: 0.5492865\tbest: 0.5492865 (185)\ttotal: 4.47s\tremaining: 16.2s\n",
      "186:\tlearn: 0.5193238\ttest: 0.5491534\tbest: 0.5491534 (186)\ttotal: 4.5s\tremaining: 16.1s\n",
      "187:\tlearn: 0.5191140\ttest: 0.5490422\tbest: 0.5490422 (187)\ttotal: 4.52s\tremaining: 16.1s\n",
      "188:\tlearn: 0.5188193\ttest: 0.5489475\tbest: 0.5489475 (188)\ttotal: 4.54s\tremaining: 16.1s\n",
      "189:\tlearn: 0.5185545\ttest: 0.5488506\tbest: 0.5488506 (189)\ttotal: 4.57s\tremaining: 16.1s\n",
      "190:\tlearn: 0.5182284\ttest: 0.5487274\tbest: 0.5487274 (190)\ttotal: 4.59s\tremaining: 16s\n",
      "191:\tlearn: 0.5179451\ttest: 0.5485893\tbest: 0.5485893 (191)\ttotal: 4.61s\tremaining: 16s\n",
      "192:\tlearn: 0.5177294\ttest: 0.5484783\tbest: 0.5484783 (192)\ttotal: 4.63s\tremaining: 16s\n",
      "193:\tlearn: 0.5174848\ttest: 0.5483949\tbest: 0.5483949 (193)\ttotal: 4.66s\tremaining: 15.9s\n",
      "194:\tlearn: 0.5171839\ttest: 0.5483139\tbest: 0.5483139 (194)\ttotal: 4.68s\tremaining: 15.9s\n",
      "195:\tlearn: 0.5169343\ttest: 0.5482097\tbest: 0.5482097 (195)\ttotal: 4.7s\tremaining: 15.9s\n",
      "196:\tlearn: 0.5167142\ttest: 0.5481263\tbest: 0.5481263 (196)\ttotal: 4.74s\tremaining: 15.9s\n",
      "197:\tlearn: 0.5164576\ttest: 0.5480391\tbest: 0.5480391 (197)\ttotal: 4.76s\tremaining: 15.9s\n",
      "198:\tlearn: 0.5161914\ttest: 0.5479552\tbest: 0.5479552 (198)\ttotal: 4.78s\tremaining: 15.8s\n",
      "199:\tlearn: 0.5159529\ttest: 0.5478885\tbest: 0.5478885 (199)\ttotal: 4.8s\tremaining: 15.8s\n",
      "200:\tlearn: 0.5156266\ttest: 0.5477688\tbest: 0.5477688 (200)\ttotal: 4.83s\tremaining: 15.8s\n",
      "201:\tlearn: 0.5153874\ttest: 0.5476912\tbest: 0.5476912 (201)\ttotal: 4.85s\tremaining: 15.7s\n",
      "202:\tlearn: 0.5151755\ttest: 0.5476015\tbest: 0.5476015 (202)\ttotal: 4.87s\tremaining: 15.7s\n",
      "203:\tlearn: 0.5149059\ttest: 0.5474956\tbest: 0.5474956 (203)\ttotal: 4.89s\tremaining: 15.7s\n",
      "204:\tlearn: 0.5146690\ttest: 0.5473727\tbest: 0.5473727 (204)\ttotal: 4.92s\tremaining: 15.7s\n",
      "205:\tlearn: 0.5143247\ttest: 0.5471883\tbest: 0.5471883 (205)\ttotal: 4.96s\tremaining: 15.7s\n",
      "206:\tlearn: 0.5140200\ttest: 0.5470871\tbest: 0.5470871 (206)\ttotal: 4.98s\tremaining: 15.7s\n",
      "207:\tlearn: 0.5136980\ttest: 0.5470379\tbest: 0.5470379 (207)\ttotal: 5s\tremaining: 15.6s\n",
      "208:\tlearn: 0.5134435\ttest: 0.5469314\tbest: 0.5469314 (208)\ttotal: 5.03s\tremaining: 15.6s\n",
      "209:\tlearn: 0.5131844\ttest: 0.5468325\tbest: 0.5468325 (209)\ttotal: 5.05s\tremaining: 15.6s\n",
      "210:\tlearn: 0.5129013\ttest: 0.5467009\tbest: 0.5467009 (210)\ttotal: 5.09s\tremaining: 15.6s\n",
      "211:\tlearn: 0.5126718\ttest: 0.5466514\tbest: 0.5466514 (211)\ttotal: 5.12s\tremaining: 15.6s\n",
      "212:\tlearn: 0.5123466\ttest: 0.5465921\tbest: 0.5465921 (212)\ttotal: 5.14s\tremaining: 15.6s\n",
      "213:\tlearn: 0.5121314\ttest: 0.5464425\tbest: 0.5464425 (213)\ttotal: 5.16s\tremaining: 15.5s\n",
      "214:\tlearn: 0.5119159\ttest: 0.5463460\tbest: 0.5463460 (214)\ttotal: 5.19s\tremaining: 15.5s\n",
      "215:\tlearn: 0.5116516\ttest: 0.5462813\tbest: 0.5462813 (215)\ttotal: 5.21s\tremaining: 15.5s\n",
      "216:\tlearn: 0.5113441\ttest: 0.5461639\tbest: 0.5461639 (216)\ttotal: 5.23s\tremaining: 15.5s\n",
      "217:\tlearn: 0.5111409\ttest: 0.5460878\tbest: 0.5460878 (217)\ttotal: 5.25s\tremaining: 15.4s\n",
      "218:\tlearn: 0.5109163\ttest: 0.5459864\tbest: 0.5459864 (218)\ttotal: 5.28s\tremaining: 15.4s\n",
      "219:\tlearn: 0.5106066\ttest: 0.5458640\tbest: 0.5458640 (219)\ttotal: 5.3s\tremaining: 15.4s\n",
      "220:\tlearn: 0.5103872\ttest: 0.5457920\tbest: 0.5457920 (220)\ttotal: 5.32s\tremaining: 15.3s\n",
      "221:\tlearn: 0.5102466\ttest: 0.5457402\tbest: 0.5457402 (221)\ttotal: 5.34s\tremaining: 15.3s\n",
      "222:\tlearn: 0.5100296\ttest: 0.5456171\tbest: 0.5456171 (222)\ttotal: 5.37s\tremaining: 15.3s\n",
      "223:\tlearn: 0.5096707\ttest: 0.5454814\tbest: 0.5454814 (223)\ttotal: 5.39s\tremaining: 15.3s\n",
      "224:\tlearn: 0.5094817\ttest: 0.5454249\tbest: 0.5454249 (224)\ttotal: 5.41s\tremaining: 15.2s\n",
      "225:\tlearn: 0.5092769\ttest: 0.5453262\tbest: 0.5453262 (225)\ttotal: 5.43s\tremaining: 15.2s\n",
      "226:\tlearn: 0.5090918\ttest: 0.5452411\tbest: 0.5452411 (226)\ttotal: 5.46s\tremaining: 15.2s\n",
      "227:\tlearn: 0.5088584\ttest: 0.5451653\tbest: 0.5451653 (227)\ttotal: 5.48s\tremaining: 15.1s\n",
      "228:\tlearn: 0.5085834\ttest: 0.5450731\tbest: 0.5450731 (228)\ttotal: 5.5s\tremaining: 15.1s\n",
      "229:\tlearn: 0.5084034\ttest: 0.5449429\tbest: 0.5449429 (229)\ttotal: 5.53s\tremaining: 15.1s\n",
      "230:\tlearn: 0.5082293\ttest: 0.5448689\tbest: 0.5448689 (230)\ttotal: 5.55s\tremaining: 15.1s\n",
      "231:\tlearn: 0.5078953\ttest: 0.5447807\tbest: 0.5447807 (231)\ttotal: 5.57s\tremaining: 15s\n",
      "232:\tlearn: 0.5076319\ttest: 0.5446892\tbest: 0.5446892 (232)\ttotal: 5.59s\tremaining: 15s\n",
      "233:\tlearn: 0.5073632\ttest: 0.5445530\tbest: 0.5445530 (233)\ttotal: 5.62s\tremaining: 15s\n",
      "234:\tlearn: 0.5071577\ttest: 0.5443963\tbest: 0.5443963 (234)\ttotal: 5.64s\tremaining: 15s\n",
      "235:\tlearn: 0.5069215\ttest: 0.5443477\tbest: 0.5443477 (235)\ttotal: 5.66s\tremaining: 14.9s\n",
      "236:\tlearn: 0.5067033\ttest: 0.5442636\tbest: 0.5442636 (236)\ttotal: 5.68s\tremaining: 14.9s\n",
      "237:\tlearn: 0.5064647\ttest: 0.5442205\tbest: 0.5442205 (237)\ttotal: 5.71s\tremaining: 14.9s\n",
      "238:\tlearn: 0.5062426\ttest: 0.5441219\tbest: 0.5441219 (238)\ttotal: 5.73s\tremaining: 14.8s\n",
      "239:\tlearn: 0.5059477\ttest: 0.5440394\tbest: 0.5440394 (239)\ttotal: 5.75s\tremaining: 14.8s\n",
      "240:\tlearn: 0.5056277\ttest: 0.5439067\tbest: 0.5439067 (240)\ttotal: 5.78s\tremaining: 14.8s\n",
      "241:\tlearn: 0.5053901\ttest: 0.5438468\tbest: 0.5438468 (241)\ttotal: 5.8s\tremaining: 14.8s\n",
      "242:\tlearn: 0.5050821\ttest: 0.5438254\tbest: 0.5438254 (242)\ttotal: 5.82s\tremaining: 14.7s\n",
      "243:\tlearn: 0.5048551\ttest: 0.5437378\tbest: 0.5437378 (243)\ttotal: 5.85s\tremaining: 14.7s\n",
      "244:\tlearn: 0.5045890\ttest: 0.5436736\tbest: 0.5436736 (244)\ttotal: 5.87s\tremaining: 14.7s\n",
      "245:\tlearn: 0.5042621\ttest: 0.5435951\tbest: 0.5435951 (245)\ttotal: 5.89s\tremaining: 14.7s\n",
      "246:\tlearn: 0.5040599\ttest: 0.5435810\tbest: 0.5435810 (246)\ttotal: 5.92s\tremaining: 14.6s\n",
      "247:\tlearn: 0.5038383\ttest: 0.5434737\tbest: 0.5434737 (247)\ttotal: 5.94s\tremaining: 14.6s\n",
      "248:\tlearn: 0.5035500\ttest: 0.5433231\tbest: 0.5433231 (248)\ttotal: 5.96s\tremaining: 14.6s\n",
      "249:\tlearn: 0.5032993\ttest: 0.5432499\tbest: 0.5432499 (249)\ttotal: 5.99s\tremaining: 14.6s\n",
      "250:\tlearn: 0.5031139\ttest: 0.5432076\tbest: 0.5432076 (250)\ttotal: 6.01s\tremaining: 14.5s\n",
      "251:\tlearn: 0.5029041\ttest: 0.5431805\tbest: 0.5431805 (251)\ttotal: 6.03s\tremaining: 14.5s\n",
      "252:\tlearn: 0.5027131\ttest: 0.5431005\tbest: 0.5431005 (252)\ttotal: 6.05s\tremaining: 14.5s\n",
      "253:\tlearn: 0.5025042\ttest: 0.5430419\tbest: 0.5430419 (253)\ttotal: 6.08s\tremaining: 14.5s\n",
      "254:\tlearn: 0.5022222\ttest: 0.5429137\tbest: 0.5429137 (254)\ttotal: 6.1s\tremaining: 14.4s\n",
      "255:\tlearn: 0.5020390\ttest: 0.5429266\tbest: 0.5429137 (254)\ttotal: 6.12s\tremaining: 14.4s\n",
      "256:\tlearn: 0.5018668\ttest: 0.5428697\tbest: 0.5428697 (256)\ttotal: 6.14s\tremaining: 14.4s\n",
      "257:\tlearn: 0.5017013\ttest: 0.5428557\tbest: 0.5428557 (257)\ttotal: 6.17s\tremaining: 14.3s\n",
      "258:\tlearn: 0.5014364\ttest: 0.5427965\tbest: 0.5427965 (258)\ttotal: 6.19s\tremaining: 14.3s\n",
      "259:\tlearn: 0.5012229\ttest: 0.5427102\tbest: 0.5427102 (259)\ttotal: 6.21s\tremaining: 14.3s\n",
      "260:\tlearn: 0.5009798\ttest: 0.5426384\tbest: 0.5426384 (260)\ttotal: 6.23s\tremaining: 14.3s\n",
      "261:\tlearn: 0.5007886\ttest: 0.5426041\tbest: 0.5426041 (261)\ttotal: 6.25s\tremaining: 14.2s\n",
      "262:\tlearn: 0.5005886\ttest: 0.5425144\tbest: 0.5425144 (262)\ttotal: 6.28s\tremaining: 14.2s\n",
      "263:\tlearn: 0.5003040\ttest: 0.5423894\tbest: 0.5423894 (263)\ttotal: 6.3s\tremaining: 14.2s\n",
      "264:\tlearn: 0.5000238\ttest: 0.5423260\tbest: 0.5423260 (264)\ttotal: 6.32s\tremaining: 14.1s\n",
      "265:\tlearn: 0.4998332\ttest: 0.5422639\tbest: 0.5422639 (265)\ttotal: 6.34s\tremaining: 14.1s\n",
      "266:\tlearn: 0.4996512\ttest: 0.5421976\tbest: 0.5421976 (266)\ttotal: 6.36s\tremaining: 14.1s\n",
      "267:\tlearn: 0.4994778\ttest: 0.5421457\tbest: 0.5421457 (267)\ttotal: 6.39s\tremaining: 14.1s\n",
      "268:\tlearn: 0.4992666\ttest: 0.5421198\tbest: 0.5421198 (268)\ttotal: 6.41s\tremaining: 14s\n",
      "269:\tlearn: 0.4990636\ttest: 0.5420234\tbest: 0.5420234 (269)\ttotal: 6.43s\tremaining: 14s\n",
      "270:\tlearn: 0.4987785\ttest: 0.5419680\tbest: 0.5419680 (270)\ttotal: 6.45s\tremaining: 14s\n",
      "271:\tlearn: 0.4985653\ttest: 0.5418761\tbest: 0.5418761 (271)\ttotal: 6.48s\tremaining: 14s\n",
      "272:\tlearn: 0.4983324\ttest: 0.5418215\tbest: 0.5418215 (272)\ttotal: 6.5s\tremaining: 13.9s\n",
      "273:\tlearn: 0.4980292\ttest: 0.5417529\tbest: 0.5417529 (273)\ttotal: 6.53s\tremaining: 13.9s\n",
      "274:\tlearn: 0.4977906\ttest: 0.5416996\tbest: 0.5416996 (274)\ttotal: 6.55s\tremaining: 13.9s\n",
      "275:\tlearn: 0.4975583\ttest: 0.5416100\tbest: 0.5416100 (275)\ttotal: 6.57s\tremaining: 13.9s\n",
      "276:\tlearn: 0.4972573\ttest: 0.5415436\tbest: 0.5415436 (276)\ttotal: 6.59s\tremaining: 13.8s\n",
      "277:\tlearn: 0.4970198\ttest: 0.5414404\tbest: 0.5414404 (277)\ttotal: 6.61s\tremaining: 13.8s\n",
      "278:\tlearn: 0.4968902\ttest: 0.5414005\tbest: 0.5414005 (278)\ttotal: 6.63s\tremaining: 13.8s\n",
      "279:\tlearn: 0.4967024\ttest: 0.5413647\tbest: 0.5413647 (279)\ttotal: 6.66s\tremaining: 13.7s\n",
      "280:\tlearn: 0.4964458\ttest: 0.5412822\tbest: 0.5412822 (280)\ttotal: 6.68s\tremaining: 13.7s\n",
      "281:\tlearn: 0.4962583\ttest: 0.5412151\tbest: 0.5412151 (281)\ttotal: 6.7s\tremaining: 13.7s\n",
      "282:\tlearn: 0.4960105\ttest: 0.5411592\tbest: 0.5411592 (282)\ttotal: 6.73s\tremaining: 13.7s\n",
      "283:\tlearn: 0.4957337\ttest: 0.5411069\tbest: 0.5411069 (283)\ttotal: 6.76s\tremaining: 13.7s\n",
      "284:\tlearn: 0.4954740\ttest: 0.5409989\tbest: 0.5409989 (284)\ttotal: 6.78s\tremaining: 13.6s\n",
      "285:\tlearn: 0.4951852\ttest: 0.5409613\tbest: 0.5409613 (285)\ttotal: 6.8s\tremaining: 13.6s\n",
      "286:\tlearn: 0.4949266\ttest: 0.5409253\tbest: 0.5409253 (286)\ttotal: 6.83s\tremaining: 13.6s\n",
      "287:\tlearn: 0.4946634\ttest: 0.5408732\tbest: 0.5408732 (287)\ttotal: 6.85s\tremaining: 13.6s\n",
      "288:\tlearn: 0.4943642\ttest: 0.5408012\tbest: 0.5408012 (288)\ttotal: 6.87s\tremaining: 13.5s\n",
      "289:\tlearn: 0.4941258\ttest: 0.5407270\tbest: 0.5407270 (289)\ttotal: 6.89s\tremaining: 13.5s\n",
      "290:\tlearn: 0.4939599\ttest: 0.5406926\tbest: 0.5406926 (290)\ttotal: 6.92s\tremaining: 13.5s\n",
      "291:\tlearn: 0.4937842\ttest: 0.5406564\tbest: 0.5406564 (291)\ttotal: 6.94s\tremaining: 13.5s\n",
      "292:\tlearn: 0.4935111\ttest: 0.5405649\tbest: 0.5405649 (292)\ttotal: 6.96s\tremaining: 13.4s\n",
      "293:\tlearn: 0.4932776\ttest: 0.5404986\tbest: 0.5404986 (293)\ttotal: 6.99s\tremaining: 13.4s\n",
      "294:\tlearn: 0.4930797\ttest: 0.5404634\tbest: 0.5404634 (294)\ttotal: 7.01s\tremaining: 13.4s\n",
      "295:\tlearn: 0.4928312\ttest: 0.5403922\tbest: 0.5403922 (295)\ttotal: 7.03s\tremaining: 13.4s\n",
      "296:\tlearn: 0.4926164\ttest: 0.5403048\tbest: 0.5403048 (296)\ttotal: 7.05s\tremaining: 13.3s\n",
      "297:\tlearn: 0.4923330\ttest: 0.5402290\tbest: 0.5402290 (297)\ttotal: 7.08s\tremaining: 13.3s\n",
      "298:\tlearn: 0.4920333\ttest: 0.5402592\tbest: 0.5402290 (297)\ttotal: 7.1s\tremaining: 13.3s\n",
      "299:\tlearn: 0.4917612\ttest: 0.5401727\tbest: 0.5401727 (299)\ttotal: 7.12s\tremaining: 13.2s\n",
      "300:\tlearn: 0.4914193\ttest: 0.5400804\tbest: 0.5400804 (300)\ttotal: 7.15s\tremaining: 13.2s\n",
      "301:\tlearn: 0.4911828\ttest: 0.5400215\tbest: 0.5400215 (301)\ttotal: 7.17s\tremaining: 13.2s\n",
      "302:\tlearn: 0.4909837\ttest: 0.5399313\tbest: 0.5399313 (302)\ttotal: 7.2s\tremaining: 13.2s\n",
      "303:\tlearn: 0.4907695\ttest: 0.5399061\tbest: 0.5399061 (303)\ttotal: 7.22s\tremaining: 13.2s\n",
      "304:\tlearn: 0.4904944\ttest: 0.5398099\tbest: 0.5398099 (304)\ttotal: 7.25s\tremaining: 13.1s\n",
      "305:\tlearn: 0.4902764\ttest: 0.5398128\tbest: 0.5398099 (304)\ttotal: 7.27s\tremaining: 13.1s\n",
      "306:\tlearn: 0.4900748\ttest: 0.5398120\tbest: 0.5398099 (304)\ttotal: 7.3s\tremaining: 13.1s\n",
      "307:\tlearn: 0.4897641\ttest: 0.5397066\tbest: 0.5397066 (307)\ttotal: 7.32s\tremaining: 13.1s\n",
      "308:\tlearn: 0.4895061\ttest: 0.5396412\tbest: 0.5396412 (308)\ttotal: 7.35s\tremaining: 13.1s\n",
      "309:\tlearn: 0.4892510\ttest: 0.5395916\tbest: 0.5395916 (309)\ttotal: 7.37s\tremaining: 13s\n",
      "310:\tlearn: 0.4890447\ttest: 0.5395022\tbest: 0.5395022 (310)\ttotal: 7.4s\tremaining: 13s\n",
      "311:\tlearn: 0.4887618\ttest: 0.5394215\tbest: 0.5394215 (311)\ttotal: 7.42s\tremaining: 13s\n",
      "312:\tlearn: 0.4884677\ttest: 0.5393597\tbest: 0.5393597 (312)\ttotal: 7.44s\tremaining: 13s\n",
      "313:\tlearn: 0.4882077\ttest: 0.5393076\tbest: 0.5393076 (313)\ttotal: 7.46s\tremaining: 12.9s\n",
      "314:\tlearn: 0.4879690\ttest: 0.5392753\tbest: 0.5392753 (314)\ttotal: 7.49s\tremaining: 12.9s\n",
      "315:\tlearn: 0.4876972\ttest: 0.5392712\tbest: 0.5392712 (315)\ttotal: 7.51s\tremaining: 12.9s\n",
      "316:\tlearn: 0.4874685\ttest: 0.5391683\tbest: 0.5391683 (316)\ttotal: 7.53s\tremaining: 12.9s\n",
      "317:\tlearn: 0.4872257\ttest: 0.5391024\tbest: 0.5391024 (317)\ttotal: 7.55s\tremaining: 12.8s\n",
      "318:\tlearn: 0.4869367\ttest: 0.5391098\tbest: 0.5391024 (317)\ttotal: 7.58s\tremaining: 12.8s\n",
      "319:\tlearn: 0.4866308\ttest: 0.5390551\tbest: 0.5390551 (319)\ttotal: 7.6s\tremaining: 12.8s\n",
      "320:\tlearn: 0.4863909\ttest: 0.5389677\tbest: 0.5389677 (320)\ttotal: 7.62s\tremaining: 12.8s\n",
      "321:\tlearn: 0.4861076\ttest: 0.5388820\tbest: 0.5388820 (321)\ttotal: 7.64s\tremaining: 12.7s\n",
      "322:\tlearn: 0.4858291\ttest: 0.5388362\tbest: 0.5388362 (322)\ttotal: 7.67s\tremaining: 12.7s\n",
      "323:\tlearn: 0.4855956\ttest: 0.5387658\tbest: 0.5387658 (323)\ttotal: 7.69s\tremaining: 12.7s\n",
      "324:\tlearn: 0.4852704\ttest: 0.5386940\tbest: 0.5386940 (324)\ttotal: 7.71s\tremaining: 12.6s\n",
      "325:\tlearn: 0.4849865\ttest: 0.5385881\tbest: 0.5385881 (325)\ttotal: 7.74s\tremaining: 12.6s\n",
      "326:\tlearn: 0.4847838\ttest: 0.5385602\tbest: 0.5385602 (326)\ttotal: 7.76s\tremaining: 12.6s\n",
      "327:\tlearn: 0.4844828\ttest: 0.5384690\tbest: 0.5384690 (327)\ttotal: 7.78s\tremaining: 12.6s\n",
      "328:\tlearn: 0.4842201\ttest: 0.5384476\tbest: 0.5384476 (328)\ttotal: 7.8s\tremaining: 12.5s\n",
      "329:\tlearn: 0.4838595\ttest: 0.5383516\tbest: 0.5383516 (329)\ttotal: 7.83s\tremaining: 12.5s\n",
      "330:\tlearn: 0.4836098\ttest: 0.5383438\tbest: 0.5383438 (330)\ttotal: 7.85s\tremaining: 12.5s\n",
      "331:\tlearn: 0.4833213\ttest: 0.5383183\tbest: 0.5383183 (331)\ttotal: 7.87s\tremaining: 12.5s\n",
      "332:\tlearn: 0.4829753\ttest: 0.5382390\tbest: 0.5382390 (332)\ttotal: 7.89s\tremaining: 12.4s\n",
      "333:\tlearn: 0.4827213\ttest: 0.5381966\tbest: 0.5381966 (333)\ttotal: 7.92s\tremaining: 12.4s\n",
      "334:\tlearn: 0.4825487\ttest: 0.5382281\tbest: 0.5381966 (333)\ttotal: 7.94s\tremaining: 12.4s\n",
      "335:\tlearn: 0.4822248\ttest: 0.5382458\tbest: 0.5381966 (333)\ttotal: 7.96s\tremaining: 12.4s\n",
      "336:\tlearn: 0.4819520\ttest: 0.5381375\tbest: 0.5381375 (336)\ttotal: 7.98s\tremaining: 12.3s\n",
      "337:\tlearn: 0.4817000\ttest: 0.5381077\tbest: 0.5381077 (337)\ttotal: 8.01s\tremaining: 12.3s\n",
      "338:\tlearn: 0.4814063\ttest: 0.5380204\tbest: 0.5380204 (338)\ttotal: 8.03s\tremaining: 12.3s\n",
      "339:\tlearn: 0.4812156\ttest: 0.5379824\tbest: 0.5379824 (339)\ttotal: 8.05s\tremaining: 12.3s\n",
      "340:\tlearn: 0.4810185\ttest: 0.5379724\tbest: 0.5379724 (340)\ttotal: 8.07s\tremaining: 12.2s\n",
      "341:\tlearn: 0.4807766\ttest: 0.5379362\tbest: 0.5379362 (341)\ttotal: 8.09s\tremaining: 12.2s\n",
      "342:\tlearn: 0.4804065\ttest: 0.5379014\tbest: 0.5379014 (342)\ttotal: 8.12s\tremaining: 12.2s\n",
      "343:\tlearn: 0.4800526\ttest: 0.5379293\tbest: 0.5379014 (342)\ttotal: 8.14s\tremaining: 12.2s\n",
      "344:\tlearn: 0.4797994\ttest: 0.5379355\tbest: 0.5379014 (342)\ttotal: 8.16s\tremaining: 12.1s\n",
      "345:\tlearn: 0.4795054\ttest: 0.5378934\tbest: 0.5378934 (345)\ttotal: 8.18s\tremaining: 12.1s\n",
      "346:\tlearn: 0.4793002\ttest: 0.5379012\tbest: 0.5378934 (345)\ttotal: 8.2s\tremaining: 12.1s\n",
      "347:\tlearn: 0.4789930\ttest: 0.5378528\tbest: 0.5378528 (347)\ttotal: 8.23s\tremaining: 12.1s\n",
      "348:\tlearn: 0.4786506\ttest: 0.5377344\tbest: 0.5377344 (348)\ttotal: 8.25s\tremaining: 12s\n",
      "349:\tlearn: 0.4783502\ttest: 0.5377260\tbest: 0.5377260 (349)\ttotal: 8.27s\tremaining: 12s\n",
      "350:\tlearn: 0.4780557\ttest: 0.5377191\tbest: 0.5377191 (350)\ttotal: 8.3s\tremaining: 12s\n",
      "351:\tlearn: 0.4778571\ttest: 0.5376480\tbest: 0.5376480 (351)\ttotal: 8.32s\tremaining: 12s\n",
      "352:\tlearn: 0.4775460\ttest: 0.5376251\tbest: 0.5376251 (352)\ttotal: 8.34s\tremaining: 11.9s\n",
      "353:\tlearn: 0.4772626\ttest: 0.5375707\tbest: 0.5375707 (353)\ttotal: 8.36s\tremaining: 11.9s\n",
      "354:\tlearn: 0.4769537\ttest: 0.5376009\tbest: 0.5375707 (353)\ttotal: 8.39s\tremaining: 11.9s\n",
      "355:\tlearn: 0.4765919\ttest: 0.5375183\tbest: 0.5375183 (355)\ttotal: 8.41s\tremaining: 11.9s\n",
      "356:\tlearn: 0.4762692\ttest: 0.5374434\tbest: 0.5374434 (356)\ttotal: 8.43s\tremaining: 11.8s\n",
      "357:\tlearn: 0.4760648\ttest: 0.5374235\tbest: 0.5374235 (357)\ttotal: 8.46s\tremaining: 11.8s\n",
      "358:\tlearn: 0.4757220\ttest: 0.5372896\tbest: 0.5372896 (358)\ttotal: 8.48s\tremaining: 11.8s\n",
      "359:\tlearn: 0.4755508\ttest: 0.5372645\tbest: 0.5372645 (359)\ttotal: 8.5s\tremaining: 11.8s\n",
      "360:\tlearn: 0.4752528\ttest: 0.5372222\tbest: 0.5372222 (360)\ttotal: 8.52s\tremaining: 11.7s\n",
      "361:\tlearn: 0.4750545\ttest: 0.5372269\tbest: 0.5372222 (360)\ttotal: 8.55s\tremaining: 11.7s\n",
      "362:\tlearn: 0.4747929\ttest: 0.5371380\tbest: 0.5371380 (362)\ttotal: 8.57s\tremaining: 11.7s\n",
      "363:\tlearn: 0.4745704\ttest: 0.5370523\tbest: 0.5370523 (363)\ttotal: 8.59s\tremaining: 11.7s\n",
      "364:\tlearn: 0.4743395\ttest: 0.5369957\tbest: 0.5369957 (364)\ttotal: 8.61s\tremaining: 11.6s\n",
      "365:\tlearn: 0.4741488\ttest: 0.5370040\tbest: 0.5369957 (364)\ttotal: 8.63s\tremaining: 11.6s\n",
      "366:\tlearn: 0.4738027\ttest: 0.5369187\tbest: 0.5369187 (366)\ttotal: 8.66s\tremaining: 11.6s\n",
      "367:\tlearn: 0.4735127\ttest: 0.5368447\tbest: 0.5368447 (367)\ttotal: 8.68s\tremaining: 11.6s\n",
      "368:\tlearn: 0.4732177\ttest: 0.5368003\tbest: 0.5368003 (368)\ttotal: 8.7s\tremaining: 11.5s\n",
      "369:\tlearn: 0.4729953\ttest: 0.5367632\tbest: 0.5367632 (369)\ttotal: 8.73s\tremaining: 11.5s\n",
      "370:\tlearn: 0.4726683\ttest: 0.5367297\tbest: 0.5367297 (370)\ttotal: 8.75s\tremaining: 11.5s\n",
      "371:\tlearn: 0.4723801\ttest: 0.5366039\tbest: 0.5366039 (371)\ttotal: 8.77s\tremaining: 11.5s\n",
      "372:\tlearn: 0.4720413\ttest: 0.5365594\tbest: 0.5365594 (372)\ttotal: 8.79s\tremaining: 11.4s\n",
      "373:\tlearn: 0.4717494\ttest: 0.5365099\tbest: 0.5365099 (373)\ttotal: 8.82s\tremaining: 11.4s\n",
      "374:\tlearn: 0.4715277\ttest: 0.5363894\tbest: 0.5363894 (374)\ttotal: 8.84s\tremaining: 11.4s\n",
      "375:\tlearn: 0.4712716\ttest: 0.5363764\tbest: 0.5363764 (375)\ttotal: 8.86s\tremaining: 11.4s\n",
      "376:\tlearn: 0.4709853\ttest: 0.5363058\tbest: 0.5363058 (376)\ttotal: 8.88s\tremaining: 11.3s\n",
      "377:\tlearn: 0.4706675\ttest: 0.5362864\tbest: 0.5362864 (377)\ttotal: 8.91s\tremaining: 11.3s\n",
      "378:\tlearn: 0.4703837\ttest: 0.5362347\tbest: 0.5362347 (378)\ttotal: 8.93s\tremaining: 11.3s\n",
      "379:\tlearn: 0.4700725\ttest: 0.5361214\tbest: 0.5361214 (379)\ttotal: 8.96s\tremaining: 11.3s\n",
      "380:\tlearn: 0.4698991\ttest: 0.5361056\tbest: 0.5361056 (380)\ttotal: 8.98s\tremaining: 11.2s\n",
      "381:\tlearn: 0.4696155\ttest: 0.5360093\tbest: 0.5360093 (381)\ttotal: 9s\tremaining: 11.2s\n",
      "382:\tlearn: 0.4693632\ttest: 0.5359200\tbest: 0.5359200 (382)\ttotal: 9.02s\tremaining: 11.2s\n",
      "383:\tlearn: 0.4691283\ttest: 0.5358924\tbest: 0.5358924 (383)\ttotal: 9.04s\tremaining: 11.2s\n",
      "384:\tlearn: 0.4688519\ttest: 0.5359394\tbest: 0.5358924 (383)\ttotal: 9.07s\tremaining: 11.1s\n",
      "385:\tlearn: 0.4685312\ttest: 0.5358831\tbest: 0.5358831 (385)\ttotal: 9.09s\tremaining: 11.1s\n",
      "386:\tlearn: 0.4682595\ttest: 0.5357938\tbest: 0.5357938 (386)\ttotal: 9.11s\tremaining: 11.1s\n",
      "387:\tlearn: 0.4679408\ttest: 0.5357493\tbest: 0.5357493 (387)\ttotal: 9.14s\tremaining: 11.1s\n",
      "388:\tlearn: 0.4676258\ttest: 0.5356743\tbest: 0.5356743 (388)\ttotal: 9.16s\tremaining: 11s\n",
      "389:\tlearn: 0.4673338\ttest: 0.5356399\tbest: 0.5356399 (389)\ttotal: 9.18s\tremaining: 11s\n",
      "390:\tlearn: 0.4672030\ttest: 0.5356451\tbest: 0.5356399 (389)\ttotal: 9.2s\tremaining: 11s\n",
      "391:\tlearn: 0.4669259\ttest: 0.5355657\tbest: 0.5355657 (391)\ttotal: 9.22s\tremaining: 11s\n",
      "392:\tlearn: 0.4665672\ttest: 0.5354379\tbest: 0.5354379 (392)\ttotal: 9.25s\tremaining: 10.9s\n",
      "393:\tlearn: 0.4662412\ttest: 0.5354180\tbest: 0.5354180 (393)\ttotal: 9.27s\tremaining: 10.9s\n",
      "394:\tlearn: 0.4659736\ttest: 0.5354088\tbest: 0.5354088 (394)\ttotal: 9.29s\tremaining: 10.9s\n",
      "395:\tlearn: 0.4657175\ttest: 0.5354283\tbest: 0.5354088 (394)\ttotal: 9.32s\tremaining: 10.9s\n",
      "396:\tlearn: 0.4655201\ttest: 0.5353430\tbest: 0.5353430 (396)\ttotal: 9.34s\tremaining: 10.8s\n",
      "397:\tlearn: 0.4652823\ttest: 0.5352891\tbest: 0.5352891 (397)\ttotal: 9.37s\tremaining: 10.8s\n",
      "398:\tlearn: 0.4650122\ttest: 0.5352526\tbest: 0.5352526 (398)\ttotal: 9.39s\tremaining: 10.8s\n",
      "399:\tlearn: 0.4648032\ttest: 0.5352162\tbest: 0.5352162 (399)\ttotal: 9.41s\tremaining: 10.8s\n",
      "400:\tlearn: 0.4645239\ttest: 0.5351408\tbest: 0.5351408 (400)\ttotal: 9.43s\tremaining: 10.8s\n",
      "401:\tlearn: 0.4642209\ttest: 0.5350989\tbest: 0.5350989 (401)\ttotal: 9.46s\tremaining: 10.7s\n",
      "402:\tlearn: 0.4640311\ttest: 0.5350523\tbest: 0.5350523 (402)\ttotal: 9.48s\tremaining: 10.7s\n",
      "403:\tlearn: 0.4638384\ttest: 0.5350378\tbest: 0.5350378 (403)\ttotal: 9.5s\tremaining: 10.7s\n",
      "404:\tlearn: 0.4635423\ttest: 0.5350676\tbest: 0.5350378 (403)\ttotal: 9.52s\tremaining: 10.7s\n",
      "405:\tlearn: 0.4634193\ttest: 0.5350707\tbest: 0.5350378 (403)\ttotal: 9.54s\tremaining: 10.6s\n",
      "406:\tlearn: 0.4632335\ttest: 0.5350780\tbest: 0.5350378 (403)\ttotal: 9.57s\tremaining: 10.6s\n",
      "407:\tlearn: 0.4629120\ttest: 0.5350732\tbest: 0.5350378 (403)\ttotal: 9.59s\tremaining: 10.6s\n",
      "408:\tlearn: 0.4627117\ttest: 0.5350081\tbest: 0.5350081 (408)\ttotal: 9.61s\tremaining: 10.6s\n",
      "409:\tlearn: 0.4624047\ttest: 0.5348999\tbest: 0.5348999 (409)\ttotal: 9.63s\tremaining: 10.5s\n",
      "410:\tlearn: 0.4620847\ttest: 0.5348774\tbest: 0.5348774 (410)\ttotal: 9.66s\tremaining: 10.5s\n",
      "411:\tlearn: 0.4618437\ttest: 0.5349060\tbest: 0.5348774 (410)\ttotal: 9.68s\tremaining: 10.5s\n",
      "412:\tlearn: 0.4615643\ttest: 0.5348621\tbest: 0.5348621 (412)\ttotal: 9.7s\tremaining: 10.5s\n",
      "413:\tlearn: 0.4613042\ttest: 0.5347940\tbest: 0.5347940 (413)\ttotal: 9.73s\tremaining: 10.4s\n",
      "414:\tlearn: 0.4610776\ttest: 0.5347895\tbest: 0.5347895 (414)\ttotal: 9.75s\tremaining: 10.4s\n",
      "415:\tlearn: 0.4607969\ttest: 0.5347342\tbest: 0.5347342 (415)\ttotal: 9.79s\tremaining: 10.4s\n",
      "416:\tlearn: 0.4605923\ttest: 0.5347148\tbest: 0.5347148 (416)\ttotal: 9.81s\tremaining: 10.4s\n",
      "417:\tlearn: 0.4603798\ttest: 0.5347108\tbest: 0.5347108 (417)\ttotal: 9.83s\tremaining: 10.3s\n",
      "418:\tlearn: 0.4601020\ttest: 0.5346476\tbest: 0.5346476 (418)\ttotal: 9.85s\tremaining: 10.3s\n",
      "419:\tlearn: 0.4598030\ttest: 0.5346014\tbest: 0.5346014 (419)\ttotal: 9.88s\tremaining: 10.3s\n",
      "420:\tlearn: 0.4595084\ttest: 0.5345202\tbest: 0.5345202 (420)\ttotal: 9.9s\tremaining: 10.3s\n",
      "421:\tlearn: 0.4592732\ttest: 0.5344886\tbest: 0.5344886 (421)\ttotal: 9.94s\tremaining: 10.3s\n",
      "422:\tlearn: 0.4589573\ttest: 0.5343459\tbest: 0.5343459 (422)\ttotal: 9.96s\tremaining: 10.2s\n",
      "423:\tlearn: 0.4587483\ttest: 0.5342659\tbest: 0.5342659 (423)\ttotal: 9.98s\tremaining: 10.2s\n",
      "424:\tlearn: 0.4585134\ttest: 0.5341892\tbest: 0.5341892 (424)\ttotal: 10s\tremaining: 10.2s\n",
      "425:\tlearn: 0.4583186\ttest: 0.5341649\tbest: 0.5341649 (425)\ttotal: 10s\tremaining: 10.2s\n",
      "426:\tlearn: 0.4580991\ttest: 0.5341207\tbest: 0.5341207 (426)\ttotal: 10s\tremaining: 10.1s\n",
      "427:\tlearn: 0.4579273\ttest: 0.5341079\tbest: 0.5341079 (427)\ttotal: 10.1s\tremaining: 10.1s\n",
      "428:\tlearn: 0.4576937\ttest: 0.5340967\tbest: 0.5340967 (428)\ttotal: 10.1s\tremaining: 10.1s\n",
      "429:\tlearn: 0.4574428\ttest: 0.5340702\tbest: 0.5340702 (429)\ttotal: 10.1s\tremaining: 10.1s\n",
      "430:\tlearn: 0.4571866\ttest: 0.5340279\tbest: 0.5340279 (430)\ttotal: 10.1s\tremaining: 10s\n",
      "431:\tlearn: 0.4569752\ttest: 0.5339685\tbest: 0.5339685 (431)\ttotal: 10.2s\tremaining: 10s\n",
      "432:\tlearn: 0.4567431\ttest: 0.5339428\tbest: 0.5339428 (432)\ttotal: 10.2s\tremaining: 9.99s\n",
      "433:\tlearn: 0.4564824\ttest: 0.5338561\tbest: 0.5338561 (433)\ttotal: 10.2s\tremaining: 9.97s\n",
      "434:\tlearn: 0.4561561\ttest: 0.5337242\tbest: 0.5337242 (434)\ttotal: 10.2s\tremaining: 9.95s\n",
      "435:\tlearn: 0.4559566\ttest: 0.5337238\tbest: 0.5337238 (435)\ttotal: 10.3s\tremaining: 9.92s\n",
      "436:\tlearn: 0.4556257\ttest: 0.5337328\tbest: 0.5337238 (435)\ttotal: 10.3s\tremaining: 9.9s\n",
      "437:\tlearn: 0.4553068\ttest: 0.5336708\tbest: 0.5336708 (437)\ttotal: 10.3s\tremaining: 9.88s\n",
      "438:\tlearn: 0.4550020\ttest: 0.5336025\tbest: 0.5336025 (438)\ttotal: 10.3s\tremaining: 9.86s\n",
      "439:\tlearn: 0.4547851\ttest: 0.5335580\tbest: 0.5335580 (439)\ttotal: 10.4s\tremaining: 9.84s\n",
      "440:\tlearn: 0.4545164\ttest: 0.5335045\tbest: 0.5335045 (440)\ttotal: 10.4s\tremaining: 9.82s\n",
      "441:\tlearn: 0.4542521\ttest: 0.5334905\tbest: 0.5334905 (441)\ttotal: 10.4s\tremaining: 9.79s\n",
      "442:\tlearn: 0.4540305\ttest: 0.5334958\tbest: 0.5334905 (441)\ttotal: 10.4s\tremaining: 9.77s\n",
      "443:\tlearn: 0.4538071\ttest: 0.5334814\tbest: 0.5334814 (443)\ttotal: 10.5s\tremaining: 9.75s\n",
      "444:\tlearn: 0.4535169\ttest: 0.5334140\tbest: 0.5334140 (444)\ttotal: 10.5s\tremaining: 9.72s\n",
      "445:\tlearn: 0.4532049\ttest: 0.5334345\tbest: 0.5334140 (444)\ttotal: 10.5s\tremaining: 9.7s\n",
      "446:\tlearn: 0.4530964\ttest: 0.5333871\tbest: 0.5333871 (446)\ttotal: 10.5s\tremaining: 9.67s\n",
      "447:\tlearn: 0.4527970\ttest: 0.5333755\tbest: 0.5333755 (447)\ttotal: 10.5s\tremaining: 9.65s\n",
      "448:\tlearn: 0.4525292\ttest: 0.5333071\tbest: 0.5333071 (448)\ttotal: 10.6s\tremaining: 9.62s\n",
      "449:\tlearn: 0.4522804\ttest: 0.5333057\tbest: 0.5333057 (449)\ttotal: 10.6s\tremaining: 9.6s\n",
      "450:\tlearn: 0.4521847\ttest: 0.5333038\tbest: 0.5333038 (450)\ttotal: 10.6s\tremaining: 9.57s\n",
      "451:\tlearn: 0.4519762\ttest: 0.5332076\tbest: 0.5332076 (451)\ttotal: 10.6s\tremaining: 9.55s\n",
      "452:\tlearn: 0.4517702\ttest: 0.5331512\tbest: 0.5331512 (452)\ttotal: 10.7s\tremaining: 9.52s\n",
      "453:\tlearn: 0.4515581\ttest: 0.5331214\tbest: 0.5331214 (453)\ttotal: 10.7s\tremaining: 9.5s\n",
      "454:\tlearn: 0.4513374\ttest: 0.5331494\tbest: 0.5331214 (453)\ttotal: 10.7s\tremaining: 9.47s\n",
      "455:\tlearn: 0.4510325\ttest: 0.5330786\tbest: 0.5330786 (455)\ttotal: 10.7s\tremaining: 9.45s\n",
      "456:\tlearn: 0.4507954\ttest: 0.5330617\tbest: 0.5330617 (456)\ttotal: 10.7s\tremaining: 9.43s\n",
      "457:\tlearn: 0.4505639\ttest: 0.5330651\tbest: 0.5330617 (456)\ttotal: 10.8s\tremaining: 9.4s\n",
      "458:\tlearn: 0.4502829\ttest: 0.5330489\tbest: 0.5330489 (458)\ttotal: 10.8s\tremaining: 9.38s\n",
      "459:\tlearn: 0.4499771\ttest: 0.5329907\tbest: 0.5329907 (459)\ttotal: 10.8s\tremaining: 9.37s\n",
      "460:\tlearn: 0.4497273\ttest: 0.5329631\tbest: 0.5329631 (460)\ttotal: 10.8s\tremaining: 9.34s\n",
      "461:\tlearn: 0.4495407\ttest: 0.5329378\tbest: 0.5329378 (461)\ttotal: 10.9s\tremaining: 9.32s\n",
      "462:\tlearn: 0.4493846\ttest: 0.5329068\tbest: 0.5329068 (462)\ttotal: 10.9s\tremaining: 9.29s\n",
      "463:\tlearn: 0.4491860\ttest: 0.5328443\tbest: 0.5328443 (463)\ttotal: 10.9s\tremaining: 9.27s\n",
      "464:\tlearn: 0.4489402\ttest: 0.5328483\tbest: 0.5328443 (463)\ttotal: 10.9s\tremaining: 9.24s\n",
      "465:\tlearn: 0.4486655\ttest: 0.5328135\tbest: 0.5328135 (465)\ttotal: 11s\tremaining: 9.22s\n",
      "466:\tlearn: 0.4483830\ttest: 0.5328289\tbest: 0.5328135 (465)\ttotal: 11s\tremaining: 9.19s\n",
      "467:\tlearn: 0.4481861\ttest: 0.5328509\tbest: 0.5328135 (465)\ttotal: 11s\tremaining: 9.17s\n",
      "468:\tlearn: 0.4480265\ttest: 0.5328062\tbest: 0.5328062 (468)\ttotal: 11s\tremaining: 9.14s\n",
      "469:\tlearn: 0.4479097\ttest: 0.5327717\tbest: 0.5327717 (469)\ttotal: 11s\tremaining: 9.12s\n",
      "470:\tlearn: 0.4476799\ttest: 0.5327272\tbest: 0.5327272 (470)\ttotal: 11.1s\tremaining: 9.09s\n",
      "471:\tlearn: 0.4474889\ttest: 0.5326832\tbest: 0.5326832 (471)\ttotal: 11.1s\tremaining: 9.07s\n",
      "472:\tlearn: 0.4471827\ttest: 0.5327119\tbest: 0.5326832 (471)\ttotal: 11.1s\tremaining: 9.04s\n",
      "473:\tlearn: 0.4469897\ttest: 0.5326459\tbest: 0.5326459 (473)\ttotal: 11.1s\tremaining: 9.03s\n",
      "474:\tlearn: 0.4466928\ttest: 0.5326694\tbest: 0.5326459 (473)\ttotal: 11.2s\tremaining: 9.01s\n",
      "475:\tlearn: 0.4465504\ttest: 0.5326146\tbest: 0.5326146 (475)\ttotal: 11.2s\tremaining: 8.99s\n",
      "476:\tlearn: 0.4463173\ttest: 0.5325322\tbest: 0.5325322 (476)\ttotal: 11.2s\tremaining: 8.96s\n",
      "477:\tlearn: 0.4460067\ttest: 0.5325236\tbest: 0.5325236 (477)\ttotal: 11.2s\tremaining: 8.94s\n",
      "478:\tlearn: 0.4457655\ttest: 0.5325071\tbest: 0.5325071 (478)\ttotal: 11.3s\tremaining: 8.92s\n",
      "479:\tlearn: 0.4454511\ttest: 0.5325257\tbest: 0.5325071 (478)\ttotal: 11.3s\tremaining: 8.89s\n",
      "480:\tlearn: 0.4452584\ttest: 0.5325061\tbest: 0.5325061 (480)\ttotal: 11.3s\tremaining: 8.87s\n",
      "481:\tlearn: 0.4449393\ttest: 0.5324985\tbest: 0.5324985 (481)\ttotal: 11.3s\tremaining: 8.85s\n",
      "482:\tlearn: 0.4447126\ttest: 0.5325606\tbest: 0.5324985 (481)\ttotal: 11.4s\tremaining: 8.82s\n",
      "483:\tlearn: 0.4445013\ttest: 0.5325884\tbest: 0.5324985 (481)\ttotal: 11.4s\tremaining: 8.8s\n",
      "484:\tlearn: 0.4443120\ttest: 0.5326031\tbest: 0.5324985 (481)\ttotal: 11.4s\tremaining: 8.77s\n",
      "485:\tlearn: 0.4441772\ttest: 0.5325973\tbest: 0.5324985 (481)\ttotal: 11.4s\tremaining: 8.75s\n",
      "486:\tlearn: 0.4439365\ttest: 0.5325516\tbest: 0.5324985 (481)\ttotal: 11.5s\tremaining: 8.72s\n",
      "487:\tlearn: 0.4437191\ttest: 0.5325200\tbest: 0.5324985 (481)\ttotal: 11.5s\tremaining: 8.7s\n",
      "488:\tlearn: 0.4434531\ttest: 0.5325334\tbest: 0.5324985 (481)\ttotal: 11.5s\tremaining: 8.68s\n",
      "489:\tlearn: 0.4432598\ttest: 0.5325243\tbest: 0.5324985 (481)\ttotal: 11.5s\tremaining: 8.65s\n",
      "490:\tlearn: 0.4429720\ttest: 0.5325338\tbest: 0.5324985 (481)\ttotal: 11.6s\tremaining: 8.63s\n",
      "491:\tlearn: 0.4427983\ttest: 0.5325015\tbest: 0.5324985 (481)\ttotal: 11.6s\tremaining: 8.62s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.5324984543\n",
      "bestIteration = 481\n",
      "\n",
      "Shrink model to first 482 iterations.\n",
      "Validation ROC-AUC score: 0.8033517223736125\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Функция для оптимизации гиперпараметров\n",
    "def optimize_cb(trial):\n",
    "    param = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
    "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
    "        'loss_function': 'Logloss',\n",
    "        'verbose': False\n",
    "    }\n",
    "    \n",
    "    model = CatBoostClassifier(**param, random_state=42)\n",
    "    \n",
    "    model.fit(X_train, y_train, eval_set=(X_valid, y_valid), early_stopping_rounds=10, verbose=False)\n",
    "    \n",
    "    y_pred = model.predict_proba(X_valid)[:, 1]\n",
    "    roc_auc = roc_auc_score(y_valid, y_pred)\n",
    "    return roc_auc\n",
    "\n",
    "# Оптимизация гиперпараметров\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(optimize_cb, n_trials=50)\n",
    "\n",
    "# Обучение модели с лучшими параметрами\n",
    "best_params = study.best_params\n",
    "print(f\"Лучшие параметры: {best_params}\")\n",
    "\n",
    "model_CB = CatBoostClassifier(**best_params)\n",
    "model_CB.fit(X_train, y_train, eval_set=(X_valid, y_valid), early_stopping_rounds=10, verbose=True)\n",
    "\n",
    "# Предсказание и оценка модели\n",
    "y_pred_CB = model_CB.predict_proba(X_valid)[:, 1]\n",
    "valid_score_CB = roc_auc_score(y_valid, y_pred_CB)\n",
    "print('Validation ROC-AUC score:', valid_score_CB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_CB = model_CB.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission_CB = pd.DataFrame({'ID' : df_test.index, 'Target': y_test_pred_CB})\n",
    "df_submission_CB.set_index('ID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ee84861e709fc9cf5d48ba0f04b7f43b</th>\n",
       "      <td>0.958469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a9475ee47c8a10d6cf37c1461814653e</th>\n",
       "      <td>0.304328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b56ea18db1408fc68263757232c1facb</th>\n",
       "      <td>0.674468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9587640246910f0e1b033a6c8f6d8211</th>\n",
       "      <td>0.462415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3eb93fbd9056ebdb52ffff84e6c3664a</th>\n",
       "      <td>0.452484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Target\n",
       "ID                                        \n",
       "ee84861e709fc9cf5d48ba0f04b7f43b  0.958469\n",
       "a9475ee47c8a10d6cf37c1461814653e  0.304328\n",
       "b56ea18db1408fc68263757232c1facb  0.674468\n",
       "9587640246910f0e1b033a6c8f6d8211  0.462415\n",
       "3eb93fbd9056ebdb52ffff84e6c3664a  0.452484"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission_CB.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to submission_CB_2024-11-08.csv\n"
     ]
    }
   ],
   "source": [
    "submission_filename = 'submission_CB_{}.csv'.format(\n",
    "    datetime.datetime.now().strftime('%Y-%m-%d'))\n",
    "df_submission_CB.to_csv(submission_filename)\n",
    "print('Submission saved to {}'.format(submission_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод.   \n",
    "Проведен небальшой EDA анализ.  \n",
    "Было обучены четрые модели XGboost, RFC, kightgbm и CatBoost.   \n",
    "Лучшее значение показала модель CatBoost 0,806 на трейне на тесте 0.79907 на 40% данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
